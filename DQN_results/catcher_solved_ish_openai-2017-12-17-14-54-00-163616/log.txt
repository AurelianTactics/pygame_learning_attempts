Logging to /tmp/openai-2017-12-17-14-54-00-163616
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 100      |
| mean 100 episode reward | -0.6     |
| steps                   | 1677     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 200      |
| mean 100 episode reward | -0.7     |
| steps                   | 3283     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 300      |
| mean 100 episode reward | -0.5     |
| steps                   | 5011     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 400      |
| mean 100 episode reward | -0.6     |
| steps                   | 6716     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 500      |
| mean 100 episode reward | -0.5     |
| steps                   | 8526     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 600      |
| mean 100 episode reward | -0.6     |
| steps                   | 10206    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 700      |
| mean 100 episode reward | -0.5     |
| steps                   | 11999    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 800      |
| mean 100 episode reward | -0.6     |
| steps                   | 13712    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 900      |
| mean 100 episode reward | -0.3     |
| steps                   | 15744    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 1000     |
| mean 100 episode reward | -0.4     |
| steps                   | 17580    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 1100     |
| mean 100 episode reward | -0       |
| steps                   | 19924    |
--------------------------------------
Saving model due to mean reward increase: None -> -0.0
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 1200     |
| mean 100 episode reward | -0.4     |
| steps                   | 21862    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 1300     |
| mean 100 episode reward | -0.2     |
| steps                   | 23944    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 1400     |
| mean 100 episode reward | -0       |
| steps                   | 26291    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 1500     |
| mean 100 episode reward | -0.2     |
| steps                   | 28405    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 1600     |
| mean 100 episode reward | 0.2      |
| steps                   | 30934    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 1700     |
| mean 100 episode reward | 0.4      |
| steps                   | 33783    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 1800     |
| mean 100 episode reward | -0.1     |
| steps                   | 36088    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 1900     |
| mean 100 episode reward | 0.2      |
| steps                   | 38683    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 2000     |
| mean 100 episode reward | 0        |
| steps                   | 41050    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 2100     |
| mean 100 episode reward | 0.4      |
| steps                   | 43871    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 2200     |
| mean 100 episode reward | 0.6      |
| steps                   | 46874    |
--------------------------------------
Saving model due to mean reward increase: -0.0 -> 1.2
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 2300     |
| mean 100 episode reward | 1.1      |
| steps                   | 50404    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 2400     |
| mean 100 episode reward | 0.4      |
| steps                   | 53204    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 2500     |
| mean 100 episode reward | 0.8      |
| steps                   | 56474    |
--------------------------------------
Saving model due to mean reward increase: 1.2 -> 1.4
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 2600     |
| mean 100 episode reward | 1.5      |
| steps                   | 60518    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 2700     |
| mean 100 episode reward | 2        |
| steps                   | 65157    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 2800     |
| mean 100 episode reward | 2.2      |
| steps                   | 69999    |
--------------------------------------
Saving model due to mean reward increase: 1.4 -> 2.2
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 2900     |
| mean 100 episode reward | 2.9      |
| steps                   | 75716    |
--------------------------------------
Saving model due to mean reward increase: 2.2 -> 4.4
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 3000     |
| mean 100 episode reward | 5.8      |
| steps                   | 84627    |
--------------------------------------
Saving model due to mean reward increase: 4.4 -> 7.8
Saving model due to mean reward increase: 7.8 -> 11.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3100     |
| mean 100 episode reward | 19.4     |
| steps                   | 109122   |
--------------------------------------
Saving model due to mean reward increase: 11.6 -> 19.4
Saving model due to mean reward increase: 19.4 -> 27.8
Saving model due to mean reward increase: 27.8 -> 36.4
Saving model due to mean reward increase: 36.4 -> 44.1
Saving model due to mean reward increase: 44.1 -> 50.2
Saving model due to mean reward increase: 50.2 -> 60.1
Saving model due to mean reward increase: 60.1 -> 68.2
Saving model due to mean reward increase: 68.2 -> 75.4
Saving model due to mean reward increase: 75.4 -> 85.3
Saving model due to mean reward increase: 85.3 -> 94.0
Saving model due to mean reward increase: 94.0 -> 101.8
Saving model due to mean reward increase: 101.8 -> 107.6
Saving model due to mean reward increase: 107.6 -> 117.9
Saving model due to mean reward increase: 117.9 -> 120.4
Saving model due to mean reward increase: 120.4 -> 133.9
Saving model due to mean reward increase: 133.9 -> 139.9
Saving model due to mean reward increase: 139.9 -> 150.3
Saving model due to mean reward increase: 150.3 -> 153.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3200     |
| mean 100 episode reward | 156      |
| steps                   | 289026   |
--------------------------------------
Saving model due to mean reward increase: 153.7 -> 155.6
Saving model due to mean reward increase: 155.6 -> 159.8
Saving model due to mean reward increase: 159.8 -> 166.6
Saving model due to mean reward increase: 166.6 -> 167.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3300     |
| mean 100 episode reward | 170      |
| steps                   | 485148   |
--------------------------------------
Saving model due to mean reward increase: 167.4 -> 167.7
Saving model due to mean reward increase: 167.7 -> 169.7
Saving model due to mean reward increase: 169.7 -> 173.6
Saving model due to mean reward increase: 173.6 -> 175.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3400     |
| mean 100 episode reward | 120      |
| steps                   | 624266   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3500     |
| mean 100 episode reward | 157      |
| steps                   | 805592   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3600     |
| mean 100 episode reward | 110      |
| steps                   | 934048   |
--------------------------------------
Restored model with mean reward: 175.2
