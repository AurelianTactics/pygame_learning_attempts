{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation of a DQN\n",
    "\n",
    "Trained on the game catcher. Dependencies:\n",
    "* Keras\n",
    "* TensorFlow\n",
    "* Pygame Learning Environment: https://github.com/ntasfi/PyGame-Learning-Environment\n",
    "* numpy\n",
    "\n",
    "Code used from:\n",
    "* Using Keras to solve FlappyBird: https://github.com/yanpanlau/Keras-FlappyBird\n",
    "* Denny Britz's DQN implementation: https://github.com/dennybritz/reinforcement-learning/tree/master/DQN\n",
    "* Udacity's RL Implementation: https://github.com/udacity/deep-learning/tree/master/reinforcement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ple import PLE\n",
    "from ple.games.catcher import Catcher\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras import initializers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "ACTIONS = 2 #right, left\n",
    "action_list = [97,100]\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "EXPLORE = 4000000. #3000000. # frames over which to anneal epsilon, \n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.95 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 32 #32 # size of minibatch\n",
    "#FRAME_PER_ACTION = 1 #set in PLE environement\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "img_rows , img_cols = 64, 64 #default size of catcher\n",
    "#Convert image into Black and white\n",
    "img_channels = 4 #stacking 4 frames\n",
    "\n",
    "#DQN (https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf 2015, Minh) has different architecture\n",
    "#using slight modifications from denny britz and flappy bird code\n",
    "#modifying it with action length for this game\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(8,8),strides=(4, 4), padding='same',\n",
    "                     activation='relu', input_shape=(img_rows,img_cols,img_channels), \n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31))) \n",
    "    model.add(Conv2D(64,kernel_size=(4,4),strides=(2,2),padding='same',activation='relu', \n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu', \n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', \n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31)))\n",
    "    model.add(Dense(ACTIONS, \n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31)))\n",
    "    \n",
    "    adam = Adam(lr=LEARNING_RATE,clipvalue=1.0)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(model,target_model):\n",
    "    \n",
    "    REPORT_EVERY = 2000 #report results this often\n",
    "    UPDATE_EVERY = 10000 #update target_model after this many training steps\n",
    "    \n",
    "    # store the previous observations in replay memory\n",
    "    exp_replay = deque()\n",
    "    \n",
    "    #stop training after hitting max loops\n",
    "    train_loops = 0\n",
    "    train_loops_max = 10\n",
    "    \n",
    "    loss = 0\n",
    "    Q_sa = 0\n",
    "    action_index = 0 #action index stored in experience replay\n",
    "    action_command = action_list[action_index] #actual command given to the environment\n",
    "    r_t = 0 #reward\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    s_t = None #state\n",
    "    s_t1 = None #resulting state\n",
    "    skip_append = True\n",
    "\n",
    "    ti_tuple = tuple([i for i in range(BATCH)]) #used for indexing a np array down below, probably a better way to do this\n",
    "    \n",
    "    EPISODE_DONE = 0 #0 if done, 1 if continuing makes math easier when making targets\n",
    "    EPISODE_NOT_DONE = 1 #makes math easier\n",
    "    EPISODE_START = -1\n",
    "    episode_length = 0.\n",
    "    episode_reward = 0.\n",
    "    stats_episode_avg_reward = 0.\n",
    "    stats_episode_avg_length = 0.\n",
    "    stats_episode = 0\n",
    "    episode = 1\n",
    "    turn = 0\n",
    "    \n",
    "    game = Catcher() # create our game\n",
    "\n",
    "    fps = 30  # fps we want to run at\n",
    "    frame_skip = 2\n",
    "    num_steps = 2\n",
    "    force_fps = True #True # false for slower speed\n",
    "    display_screen = False\n",
    "\n",
    "    # make a PLE instance.\n",
    "    ple_env = PLE(game, fps=fps, frame_skip=frame_skip, num_steps=num_steps,\n",
    "            force_fps=force_fps, display_screen=display_screen)\n",
    "\n",
    "    # init agent and game.\n",
    "    ple_env.init()\n",
    "    done_check = ple_env.lives() #resetting episode on loss of life, not on game over\n",
    "    ple_env.act(action_list[np.random.randint(0,2)]) #need to take an action to initialize, screen starts out as black\n",
    "    \n",
    "    #start of an episode is a stack of four of the same observation\n",
    "    #subsequent time steps removes the first frame adds current frame to the end\n",
    "    x_t = ple_env.getScreenGrayscale()/255. \n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "\n",
    "    while train_loops < EXPLORE:\n",
    "        train_loops += 1\n",
    "        \n",
    "        #get action\n",
    "        #action_command used to actually input the command\n",
    "        #a_t is used in the experience replay/training\n",
    "        if random.random() <= epsilon:\n",
    "            action_index = np.random.randint(0,ACTIONS)\n",
    "            action_command = action_list[action_index]\n",
    "        else:\n",
    "            q = model.predict(s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])) \n",
    "            max_Q = np.argmax(q)\n",
    "            action_index = max_Q\n",
    "            action_command = action_list[action_index]\n",
    "            \n",
    "        #reduce exploration rate epsilon\n",
    "        if epsilon > FINAL_EPSILON:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "        \n",
    "        #do action\n",
    "        r_t = ple_env.act(action_command)\n",
    "        episode_reward += r_t\n",
    "        episode_length += 1\n",
    "        \n",
    "        #get next state\n",
    "        x_t1 = ple_env.getScreenGrayscale()/255.\n",
    "        x_t1 = x_t1.reshape(x_t1.shape[0], x_t1.shape[1], 1) #1x64x64x1\n",
    "        s_t1 = np.append(x_t1, s_t[ :, :, :3], axis=2)\n",
    "\n",
    "        if ple_env.lives() != done_check:\n",
    "            done = EPISODE_DONE\n",
    "        else:\n",
    "            done = EPISODE_NOT_DONE\n",
    "        \n",
    "        #adding to experience replay\n",
    "        if len(exp_replay) == REPLAY_MEMORY:\n",
    "            exp_replay.popleft()\n",
    "        exp_replay.append((s_t, action_index, r_t, s_t1, done))\n",
    "        \n",
    "        #check if life is lost, if so episode is done and we reset\n",
    "        if done == EPISODE_DONE:\n",
    "            episode += 1\n",
    "            stats_episode += 1\n",
    "            turn = 0\n",
    "            stats_episode_avg_reward = stats_episode_avg_reward + (episode_reward - stats_episode_avg_reward)/stats_episode\n",
    "            stats_episode_avg_length = stats_episode_avg_length + (episode_length - stats_episode_avg_length)/stats_episode\n",
    "            episode_reward = 0.\n",
    "            episode_length = 0.\n",
    "\n",
    "            #reset the environment, get the current state\n",
    "            ple_env.reset_game()\n",
    "            ple_env.act(action_list[np.random.randint(0,2)]) #take action to initialize, screen starts out as black\n",
    "            x_t = ple_env.getScreenGrayscale()/255.\n",
    "            s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "        else:\n",
    "            s_t = s_t1 #resulting state becomes the current state\n",
    "        \n",
    "        #train the network using the experience replay\n",
    "        #modified heavily from FlappyBird implementation\n",
    "            #better way from dennybritz design\n",
    "                #used a fixed Q target network\n",
    "                #only predicts on the next values, flappy bird predicts on current values which I don't think the paper does\n",
    "                #removes a for loop\n",
    "                \n",
    "        if len(exp_replay) > BATCH:\n",
    "            #print(\"training\")\n",
    "            #minibatch = exp_replay.sample(BATCHD)\n",
    "            minibatch = random.sample(exp_replay,BATCH)\n",
    "            \n",
    "            #modified heavily from flapply bird way which I believe is incorrect\n",
    "            #better way from dennybritz design\n",
    "                #uses a fixed Q target network\n",
    "                #only predicts on the next states values\n",
    "                    #flappy bird predicts on current values which I don't think the DQN paper does\n",
    "                #removes a for loop\n",
    "\n",
    "            states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*minibatch))        \n",
    "            \n",
    "            q_values_next = target_model.predict(next_states_batch,batch_size=BATCH)\n",
    "            targets = np.zeros((BATCH,ACTIONS)) #BATCHxACTIONS\n",
    "            targets[ti_tuple,action_batch] = reward_batch + done_batch * GAMMA * np.amax(q_values_next,axis=1)\n",
    "            loss += model.train_on_batch(states_batch, targets)\n",
    "        \n",
    "        #save model weights and update target model\n",
    "        if train_loops % UPDATE_EVERY == 0:\n",
    "            print(\"Saving model weights\")\n",
    "            zString = \"catcher_training_weights/model_{}.h5\".format(train_loops)\n",
    "            model.save_weights(zString, overwrite=True)\n",
    "            #updating fixed Q network weights\n",
    "            target_model.load_weights(zString)\n",
    "\n",
    "        #print info\n",
    "        if train_loops % REPORT_EVERY == 0:\n",
    "            print(\"Loop {} / Episode {} / Epsilon {:6.4f} / Avg. Reward {:6.3f} / Avg. Length {:6.3f} / Loss {:6.4f} \"\n",
    "                              .format(train_loops,episode,epsilon,stats_episode_avg_reward,stats_episode_avg_length,loss) )\n",
    "            stats_episode_avg_reward = 0.\n",
    "            stats_episode_avg_length = 0.\n",
    "            stats_episode = 0.\n",
    "            loss = 0.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2000 / Episode 156 / Epsilon 0.9495 / Avg. Reward -0.548 / Avg. Length 12.884 / Loss 21.7476 \n",
      "Loop 4000 / Episode 304 / Epsilon 0.9491 / Avg. Reward -0.480 / Avg. Length 13.486 / Loss 19.8332 \n",
      "Loop 6000 / Episode 459 / Epsilon 0.9486 / Avg. Reward -0.542 / Avg. Length 12.897 / Loss 21.2444 \n",
      "Loop 8000 / Episode 625 / Epsilon 0.9481 / Avg. Reward -0.651 / Avg. Length 12.054 / Loss 21.3462 \n",
      "Saving model weights\n",
      "Loop 10000 / Episode 790 / Epsilon 0.9476 / Avg. Reward -0.624 / Avg. Length 12.121 / Loss 20.8022 \n",
      "Loop 12000 / Episode 940 / Epsilon 0.9472 / Avg. Reward -0.480 / Avg. Length 13.340 / Loss 35.8715 \n",
      "Loop 14000 / Episode 1091 / Epsilon 0.9467 / Avg. Reward -0.497 / Avg. Length 13.245 / Loss 29.2353 \n",
      "Loop 16000 / Episode 1230 / Epsilon 0.9462 / Avg. Reward -0.367 / Avg. Length 14.410 / Loss 29.5682 \n",
      "Loop 18000 / Episode 1387 / Epsilon 0.9458 / Avg. Reward -0.567 / Avg. Length 12.732 / Loss 27.6158 \n",
      "Saving model weights\n",
      "Loop 20000 / Episode 1553 / Epsilon 0.9453 / Avg. Reward -0.657 / Avg. Length 12.024 / Loss 27.8539 \n",
      "Loop 22000 / Episode 1707 / Epsilon 0.9448 / Avg. Reward -0.526 / Avg. Length 13.019 / Loss 42.5699 \n",
      "Loop 24000 / Episode 1865 / Epsilon 0.9444 / Avg. Reward -0.570 / Avg. Length 12.589 / Loss 39.0614 \n",
      "Loop 26000 / Episode 2028 / Epsilon 0.9439 / Avg. Reward -0.601 / Avg. Length 12.313 / Loss 37.9624 \n",
      "Loop 28000 / Episode 2183 / Epsilon 0.9434 / Avg. Reward -0.548 / Avg. Length 12.794 / Loss 37.5290 \n",
      "Saving model weights\n",
      "Loop 30000 / Episode 2340 / Epsilon 0.9429 / Avg. Reward -0.541 / Avg. Length 12.892 / Loss 36.5570 \n",
      "Loop 32000 / Episode 2496 / Epsilon 0.9425 / Avg. Reward -0.538 / Avg. Length 12.769 / Loss 46.3283 \n",
      "Loop 34000 / Episode 2655 / Epsilon 0.9420 / Avg. Reward -0.572 / Avg. Length 12.623 / Loss 45.4109 \n",
      "Loop 36000 / Episode 2812 / Epsilon 0.9415 / Avg. Reward -0.561 / Avg. Length 12.732 / Loss 43.0734 \n",
      "Loop 38000 / Episode 2965 / Epsilon 0.9411 / Avg. Reward -0.523 / Avg. Length 13.039 / Loss 43.1584 \n",
      "Saving model weights\n",
      "Loop 40000 / Episode 3122 / Epsilon 0.9406 / Avg. Reward -0.567 / Avg. Length 12.688 / Loss 42.7771 \n",
      "Loop 42000 / Episode 3279 / Epsilon 0.9401 / Avg. Reward -0.541 / Avg. Length 12.834 / Loss 50.2219 \n",
      "Loop 44000 / Episode 3428 / Epsilon 0.9397 / Avg. Reward -0.490 / Avg. Length 13.423 / Loss 48.6607 \n",
      "Loop 46000 / Episode 3585 / Epsilon 0.9392 / Avg. Reward -0.567 / Avg. Length 12.637 / Loss 47.7775 \n",
      "Loop 48000 / Episode 3747 / Epsilon 0.9387 / Avg. Reward -0.593 / Avg. Length 12.420 / Loss 47.1109 \n",
      "Saving model weights\n",
      "Loop 50000 / Episode 3908 / Epsilon 0.9382 / Avg. Reward -0.609 / Avg. Length 12.292 / Loss 46.7246 \n",
      "Loop 52000 / Episode 4069 / Epsilon 0.9378 / Avg. Reward -0.596 / Avg. Length 12.447 / Loss 54.3138 \n",
      "Loop 54000 / Episode 4225 / Epsilon 0.9373 / Avg. Reward -0.551 / Avg. Length 12.808 / Loss 52.9520 \n",
      "Loop 56000 / Episode 4379 / Epsilon 0.9368 / Avg. Reward -0.513 / Avg. Length 13.123 / Loss 52.1983 \n",
      "Loop 58000 / Episode 4539 / Epsilon 0.9364 / Avg. Reward -0.588 / Avg. Length 12.494 / Loss 50.0093 \n",
      "Saving model weights\n",
      "Loop 60000 / Episode 4693 / Epsilon 0.9359 / Avg. Reward -0.558 / Avg. Length 12.883 / Loss 50.5315 \n",
      "Loop 62000 / Episode 4853 / Epsilon 0.9354 / Avg. Reward -0.581 / Avg. Length 12.606 / Loss 52.7103 \n",
      "Loop 64000 / Episode 4993 / Epsilon 0.9350 / Avg. Reward -0.386 / Avg. Length 14.279 / Loss 51.3092 \n",
      "Loop 66000 / Episode 5144 / Epsilon 0.9345 / Avg. Reward -0.523 / Avg. Length 13.252 / Loss 48.4281 \n",
      "Loop 68000 / Episode 5303 / Epsilon 0.9340 / Avg. Reward -0.585 / Avg. Length 12.522 / Loss 47.9569 \n",
      "Saving model weights\n",
      "Loop 70000 / Episode 5447 / Epsilon 0.9335 / Avg. Reward -0.438 / Avg. Length 13.938 / Loss 47.8399 \n",
      "Loop 72000 / Episode 5598 / Epsilon 0.9331 / Avg. Reward -0.490 / Avg. Length 13.265 / Loss 51.1151 \n",
      "Loop 74000 / Episode 5748 / Epsilon 0.9326 / Avg. Reward -0.493 / Avg. Length 13.293 / Loss 48.3975 \n",
      "Loop 76000 / Episode 5906 / Epsilon 0.9321 / Avg. Reward -0.563 / Avg. Length 12.658 / Loss 46.7926 \n",
      "Loop 78000 / Episode 6073 / Epsilon 0.9317 / Avg. Reward -0.653 / Avg. Length 11.922 / Loss 46.1778 \n",
      "Saving model weights\n",
      "Loop 80000 / Episode 6216 / Epsilon 0.9312 / Avg. Reward -0.420 / Avg. Length 14.063 / Loss 46.3251 \n",
      "Loop 82000 / Episode 6368 / Epsilon 0.9307 / Avg. Reward -0.520 / Avg. Length 13.158 / Loss 51.5967 \n",
      "Loop 84000 / Episode 6540 / Epsilon 0.9303 / Avg. Reward -0.686 / Avg. Length 11.628 / Loss 49.4333 \n",
      "Loop 86000 / Episode 6694 / Epsilon 0.9298 / Avg. Reward -0.532 / Avg. Length 13.019 / Loss 46.9170 \n",
      "Loop 88000 / Episode 6848 / Epsilon 0.9293 / Avg. Reward -0.539 / Avg. Length 12.909 / Loss 48.0482 \n",
      "Saving model weights\n",
      "Loop 90000 / Episode 6996 / Epsilon 0.9288 / Avg. Reward -0.473 / Avg. Length 13.514 / Loss 45.5730 \n",
      "Loop 92000 / Episode 7163 / Epsilon 0.9284 / Avg. Reward -0.629 / Avg. Length 12.006 / Loss 52.2421 \n",
      "Loop 94000 / Episode 7310 / Epsilon 0.9279 / Avg. Reward -0.456 / Avg. Length 13.619 / Loss 48.2675 \n",
      "Loop 96000 / Episode 7464 / Epsilon 0.9274 / Avg. Reward -0.539 / Avg. Length 12.929 / Loss 47.3562 \n",
      "Loop 98000 / Episode 7613 / Epsilon 0.9270 / Avg. Reward -0.490 / Avg. Length 13.477 / Loss 46.9794 \n",
      "Saving model weights\n",
      "Loop 100000 / Episode 7758 / Epsilon 0.9265 / Avg. Reward -0.428 / Avg. Length 13.821 / Loss 45.9643 \n",
      "Loop 102000 / Episode 7919 / Epsilon 0.9260 / Avg. Reward -0.602 / Avg. Length 12.323 / Loss 52.3771 \n",
      "Loop 104000 / Episode 8068 / Epsilon 0.9256 / Avg. Reward -0.463 / Avg. Length 13.517 / Loss 49.6271 \n",
      "Loop 106000 / Episode 8227 / Epsilon 0.9251 / Avg. Reward -0.579 / Avg. Length 12.604 / Loss 48.2347 \n",
      "Loop 108000 / Episode 8372 / Epsilon 0.9246 / Avg. Reward -0.441 / Avg. Length 13.752 / Loss 46.3298 \n",
      "Saving model weights\n",
      "Loop 110000 / Episode 8522 / Epsilon 0.9241 / Avg. Reward -0.487 / Avg. Length 13.327 / Loss 46.2800 \n",
      "Loop 112000 / Episode 8683 / Epsilon 0.9237 / Avg. Reward -0.602 / Avg. Length 12.466 / Loss 55.1389 \n",
      "Loop 114000 / Episode 8845 / Epsilon 0.9232 / Avg. Reward -0.617 / Avg. Length 12.321 / Loss 50.4701 \n",
      "Loop 116000 / Episode 9003 / Epsilon 0.9227 / Avg. Reward -0.563 / Avg. Length 12.671 / Loss 49.5477 \n",
      "Loop 118000 / Episode 9159 / Epsilon 0.9223 / Avg. Reward -0.551 / Avg. Length 12.788 / Loss 48.9846 \n",
      "Saving model weights\n",
      "Loop 120000 / Episode 9306 / Epsilon 0.9218 / Avg. Reward -0.469 / Avg. Length 13.612 / Loss 47.9198 \n",
      "Loop 122000 / Episode 9447 / Epsilon 0.9213 / Avg. Reward -0.390 / Avg. Length 14.184 / Loss 53.8286 \n",
      "Loop 124000 / Episode 9588 / Epsilon 0.9209 / Avg. Reward -0.397 / Avg. Length 14.184 / Loss 51.0152 \n",
      "Loop 126000 / Episode 9751 / Epsilon 0.9204 / Avg. Reward -0.613 / Avg. Length 12.166 / Loss 49.8689 \n",
      "Loop 128000 / Episode 9904 / Epsilon 0.9199 / Avg. Reward -0.510 / Avg. Length 13.176 / Loss 49.9306 \n",
      "Saving model weights\n",
      "Loop 130000 / Episode 10066 / Epsilon 0.9194 / Avg. Reward -0.605 / Avg. Length 12.383 / Loss 48.1851 \n",
      "Loop 132000 / Episode 10216 / Epsilon 0.9190 / Avg. Reward -0.507 / Avg. Length 13.273 / Loss 54.5464 \n",
      "Loop 134000 / Episode 10377 / Epsilon 0.9185 / Avg. Reward -0.590 / Avg. Length 12.404 / Loss 51.5113 \n",
      "Loop 136000 / Episode 10528 / Epsilon 0.9180 / Avg. Reward -0.490 / Avg. Length 13.305 / Loss 49.8504 \n",
      "Loop 138000 / Episode 10681 / Epsilon 0.9176 / Avg. Reward -0.510 / Avg. Length 13.085 / Loss 48.9230 \n",
      "Saving model weights\n",
      "Loop 140000 / Episode 10837 / Epsilon 0.9171 / Avg. Reward -0.564 / Avg. Length 12.763 / Loss 47.2205 \n",
      "Loop 142000 / Episode 10990 / Epsilon 0.9166 / Avg. Reward -0.523 / Avg. Length 13.137 / Loss 52.7803 \n",
      "Loop 144000 / Episode 11151 / Epsilon 0.9162 / Avg. Reward -0.596 / Avg. Length 12.429 / Loss 50.8208 \n",
      "Loop 146000 / Episode 11308 / Epsilon 0.9157 / Avg. Reward -0.561 / Avg. Length 12.707 / Loss 47.9753 \n",
      "Loop 148000 / Episode 11458 / Epsilon 0.9152 / Avg. Reward -0.507 / Avg. Length 13.247 / Loss 46.8380 \n",
      "Saving model weights\n",
      "Loop 150000 / Episode 11609 / Epsilon 0.9147 / Avg. Reward -0.503 / Avg. Length 13.311 / Loss 47.0620 \n",
      "Loop 152000 / Episode 11767 / Epsilon 0.9143 / Avg. Reward -0.570 / Avg. Length 12.639 / Loss 51.7938 \n",
      "Loop 154000 / Episode 11926 / Epsilon 0.9138 / Avg. Reward -0.585 / Avg. Length 12.635 / Loss 48.4137 \n",
      "Loop 156000 / Episode 12078 / Epsilon 0.9133 / Avg. Reward -0.546 / Avg. Length 13.013 / Loss 47.9956 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 158000 / Episode 12224 / Epsilon 0.9129 / Avg. Reward -0.452 / Avg. Length 13.733 / Loss 47.2238 \n",
      "Saving model weights\n",
      "Loop 160000 / Episode 12392 / Epsilon 0.9124 / Avg. Reward -0.649 / Avg. Length 11.988 / Loss 45.9708 \n",
      "Loop 162000 / Episode 12548 / Epsilon 0.9119 / Avg. Reward -0.551 / Avg. Length 12.846 / Loss 51.9891 \n",
      "Loop 164000 / Episode 12699 / Epsilon 0.9115 / Avg. Reward -0.503 / Avg. Length 13.252 / Loss 50.9671 \n",
      "Loop 166000 / Episode 12845 / Epsilon 0.9110 / Avg. Reward -0.445 / Avg. Length 13.678 / Loss 47.3807 \n",
      "Loop 168000 / Episode 12989 / Epsilon 0.9105 / Avg. Reward -0.410 / Avg. Length 13.896 / Loss 46.8538 \n",
      "Saving model weights\n",
      "Loop 170000 / Episode 13139 / Epsilon 0.9100 / Avg. Reward -0.513 / Avg. Length 13.327 / Loss 46.5756 \n",
      "Loop 172000 / Episode 13296 / Epsilon 0.9096 / Avg. Reward -0.567 / Avg. Length 12.752 / Loss 50.5967 \n",
      "Loop 174000 / Episode 13454 / Epsilon 0.9091 / Avg. Reward -0.563 / Avg. Length 12.620 / Loss 48.1845 \n",
      "Loop 176000 / Episode 13604 / Epsilon 0.9086 / Avg. Reward -0.493 / Avg. Length 13.347 / Loss 45.9027 \n",
      "Loop 178000 / Episode 13742 / Epsilon 0.9082 / Avg. Reward -0.348 / Avg. Length 14.486 / Loss 46.1444 \n",
      "Saving model weights\n",
      "Loop 180000 / Episode 13893 / Epsilon 0.9077 / Avg. Reward -0.510 / Avg. Length 13.245 / Loss 44.8423 \n",
      "Loop 182000 / Episode 14047 / Epsilon 0.9072 / Avg. Reward -0.519 / Avg. Length 13.000 / Loss 50.5829 \n",
      "Loop 184000 / Episode 14205 / Epsilon 0.9068 / Avg. Reward -0.570 / Avg. Length 12.646 / Loss 47.5496 \n",
      "Loop 186000 / Episode 14358 / Epsilon 0.9063 / Avg. Reward -0.542 / Avg. Length 12.895 / Loss 45.9926 \n",
      "Loop 188000 / Episode 14504 / Epsilon 0.9058 / Avg. Reward -0.452 / Avg. Length 13.767 / Loss 44.7015 \n",
      "Saving model weights\n",
      "Loop 190000 / Episode 14664 / Epsilon 0.9053 / Avg. Reward -0.575 / Avg. Length 12.587 / Loss 45.1708 \n",
      "Loop 192000 / Episode 14812 / Epsilon 0.9049 / Avg. Reward -0.486 / Avg. Length 13.439 / Loss 50.6361 \n",
      "Loop 194000 / Episode 14960 / Epsilon 0.9044 / Avg. Reward -0.453 / Avg. Length 13.622 / Loss 48.2364 \n",
      "Loop 196000 / Episode 15127 / Epsilon 0.9039 / Avg. Reward -0.647 / Avg. Length 11.964 / Loss 45.8249 \n",
      "Loop 198000 / Episode 15280 / Epsilon 0.9035 / Avg. Reward -0.516 / Avg. Length 13.092 / Loss 48.0510 \n",
      "Saving model weights\n",
      "Loop 200000 / Episode 15438 / Epsilon 0.9030 / Avg. Reward -0.595 / Avg. Length 12.519 / Loss 44.9047 \n",
      "Loop 202000 / Episode 15593 / Epsilon 0.9025 / Avg. Reward -0.529 / Avg. Length 13.039 / Loss 50.3951 \n",
      "Loop 204000 / Episode 15744 / Epsilon 0.9021 / Avg. Reward -0.536 / Avg. Length 13.086 / Loss 46.8302 \n",
      "Loop 206000 / Episode 15887 / Epsilon 0.9016 / Avg. Reward -0.420 / Avg. Length 14.168 / Loss 44.9347 \n",
      "Loop 208000 / Episode 16027 / Epsilon 0.9011 / Avg. Reward -0.393 / Avg. Length 14.157 / Loss 45.3434 \n",
      "Saving model weights\n",
      "Loop 210000 / Episode 16182 / Epsilon 0.9006 / Avg. Reward -0.529 / Avg. Length 13.000 / Loss 44.9126 \n",
      "Loop 212000 / Episode 16331 / Epsilon 0.9002 / Avg. Reward -0.503 / Avg. Length 13.376 / Loss 50.8020 \n",
      "Loop 214000 / Episode 16476 / Epsilon 0.8997 / Avg. Reward -0.434 / Avg. Length 13.841 / Loss 48.7700 \n",
      "Loop 216000 / Episode 16623 / Epsilon 0.8992 / Avg. Reward -0.463 / Avg. Length 13.503 / Loss 47.5053 \n",
      "Loop 218000 / Episode 16767 / Epsilon 0.8988 / Avg. Reward -0.431 / Avg. Length 13.944 / Loss 47.0270 \n",
      "Saving model weights\n",
      "Loop 220000 / Episode 16927 / Epsilon 0.8983 / Avg. Reward -0.594 / Avg. Length 12.519 / Loss 45.6077 \n",
      "Loop 222000 / Episode 17087 / Epsilon 0.8978 / Avg. Reward -0.575 / Avg. Length 12.538 / Loss 51.5939 \n",
      "Loop 224000 / Episode 17235 / Epsilon 0.8974 / Avg. Reward -0.493 / Avg. Length 13.297 / Loss 47.7219 \n",
      "Loop 226000 / Episode 17391 / Epsilon 0.8969 / Avg. Reward -0.538 / Avg. Length 13.032 / Loss 46.6774 \n",
      "Loop 228000 / Episode 17549 / Epsilon 0.8964 / Avg. Reward -0.570 / Avg. Length 12.627 / Loss 45.7406 \n",
      "Saving model weights\n",
      "Loop 230000 / Episode 17705 / Epsilon 0.8959 / Avg. Reward -0.558 / Avg. Length 12.821 / Loss 45.3154 \n",
      "Loop 232000 / Episode 17851 / Epsilon 0.8955 / Avg. Reward -0.425 / Avg. Length 13.658 / Loss 50.6777 \n",
      "Loop 234000 / Episode 17997 / Epsilon 0.8950 / Avg. Reward -0.438 / Avg. Length 13.788 / Loss 48.6282 \n",
      "Loop 236000 / Episode 18144 / Epsilon 0.8945 / Avg. Reward -0.463 / Avg. Length 13.551 / Loss 47.6380 \n",
      "Loop 238000 / Episode 18282 / Epsilon 0.8941 / Avg. Reward -0.362 / Avg. Length 14.449 / Loss 45.1927 \n",
      "Saving model weights\n",
      "Loop 240000 / Episode 18434 / Epsilon 0.8936 / Avg. Reward -0.507 / Avg. Length 13.217 / Loss 46.1445 \n",
      "Loop 242000 / Episode 18581 / Epsilon 0.8931 / Avg. Reward -0.469 / Avg. Length 13.599 / Loss 51.8423 \n",
      "Loop 244000 / Episode 18737 / Epsilon 0.8927 / Avg. Reward -0.551 / Avg. Length 12.814 / Loss 48.2948 \n",
      "Loop 246000 / Episode 18897 / Epsilon 0.8922 / Avg. Reward -0.581 / Avg. Length 12.494 / Loss 48.7385 \n",
      "Loop 248000 / Episode 19041 / Epsilon 0.8917 / Avg. Reward -0.444 / Avg. Length 13.889 / Loss 46.4566 \n",
      "Saving model weights\n",
      "Loop 250000 / Episode 19203 / Epsilon 0.8912 / Avg. Reward -0.611 / Avg. Length 12.340 / Loss 46.5787 \n",
      "Loop 252000 / Episode 19351 / Epsilon 0.8908 / Avg. Reward -0.466 / Avg. Length 13.534 / Loss 52.4018 \n",
      "Loop 254000 / Episode 19508 / Epsilon 0.8903 / Avg. Reward -0.580 / Avg. Length 12.624 / Loss 49.9840 \n",
      "Loop 256000 / Episode 19658 / Epsilon 0.8898 / Avg. Reward -0.480 / Avg. Length 13.400 / Loss 49.1073 \n",
      "Loop 258000 / Episode 19813 / Epsilon 0.8894 / Avg. Reward -0.548 / Avg. Length 12.981 / Loss 47.7141 \n",
      "Saving model weights\n",
      "Loop 260000 / Episode 19962 / Epsilon 0.8889 / Avg. Reward -0.483 / Avg. Length 13.396 / Loss 46.3395 \n",
      "Loop 262000 / Episode 20109 / Epsilon 0.8884 / Avg. Reward -0.456 / Avg. Length 13.565 / Loss 55.0894 \n",
      "Loop 264000 / Episode 20267 / Epsilon 0.8880 / Avg. Reward -0.557 / Avg. Length 12.696 / Loss 51.2651 \n",
      "Loop 266000 / Episode 20403 / Epsilon 0.8875 / Avg. Reward -0.346 / Avg. Length 14.625 / Loss 50.4781 \n",
      "Loop 268000 / Episode 20558 / Epsilon 0.8870 / Avg. Reward -0.542 / Avg. Length 12.961 / Loss 48.8168 \n",
      "Saving model weights\n",
      "Loop 270000 / Episode 20715 / Epsilon 0.8865 / Avg. Reward -0.554 / Avg. Length 12.758 / Loss 48.6436 \n",
      "Loop 272000 / Episode 20864 / Epsilon 0.8861 / Avg. Reward -0.477 / Avg. Length 13.456 / Loss 56.5573 \n",
      "Loop 274000 / Episode 21024 / Epsilon 0.8856 / Avg. Reward -0.619 / Avg. Length 12.388 / Loss 51.3971 \n",
      "Loop 276000 / Episode 21177 / Epsilon 0.8851 / Avg. Reward -0.516 / Avg. Length 13.157 / Loss 50.7188 \n",
      "Loop 278000 / Episode 21329 / Epsilon 0.8847 / Avg. Reward -0.520 / Avg. Length 13.164 / Loss 49.8961 \n",
      "Saving model weights\n",
      "Loop 280000 / Episode 21482 / Epsilon 0.8842 / Avg. Reward -0.516 / Avg. Length 13.092 / Loss 48.9766 \n",
      "Loop 282000 / Episode 21626 / Epsilon 0.8837 / Avg. Reward -0.424 / Avg. Length 13.840 / Loss 55.1131 \n",
      "Loop 284000 / Episode 21791 / Epsilon 0.8833 / Avg. Reward -0.624 / Avg. Length 12.133 / Loss 52.0063 \n",
      "Loop 286000 / Episode 21942 / Epsilon 0.8828 / Avg. Reward -0.490 / Avg. Length 13.238 / Loss 50.7854 \n",
      "Loop 288000 / Episode 22108 / Epsilon 0.8823 / Avg. Reward -0.633 / Avg. Length 12.078 / Loss 48.9236 \n",
      "Saving model weights\n",
      "Loop 290000 / Episode 22259 / Epsilon 0.8818 / Avg. Reward -0.510 / Avg. Length 13.219 / Loss 47.6651 \n",
      "Loop 292000 / Episode 22406 / Epsilon 0.8814 / Avg. Reward -0.456 / Avg. Length 13.612 / Loss 53.8905 \n",
      "Loop 294000 / Episode 22564 / Epsilon 0.8809 / Avg. Reward -0.563 / Avg. Length 12.671 / Loss 50.8325 \n",
      "Loop 296000 / Episode 22721 / Epsilon 0.8804 / Avg. Reward -0.561 / Avg. Length 12.752 / Loss 49.1187 \n",
      "Loop 298000 / Episode 22868 / Epsilon 0.8800 / Avg. Reward -0.490 / Avg. Length 13.497 / Loss 48.3702 \n",
      "Saving model weights\n",
      "Loop 300000 / Episode 23026 / Epsilon 0.8795 / Avg. Reward -0.563 / Avg. Length 12.728 / Loss 48.5598 \n",
      "Loop 302000 / Episode 23178 / Epsilon 0.8790 / Avg. Reward -0.507 / Avg. Length 13.151 / Loss 55.8589 \n",
      "Loop 304000 / Episode 23330 / Epsilon 0.8786 / Avg. Reward -0.513 / Avg. Length 13.158 / Loss 53.0142 \n",
      "Loop 306000 / Episode 23472 / Epsilon 0.8781 / Avg. Reward -0.401 / Avg. Length 14.106 / Loss 51.7624 \n",
      "Loop 308000 / Episode 23619 / Epsilon 0.8776 / Avg. Reward -0.456 / Avg. Length 13.626 / Loss 50.0844 \n",
      "Saving model weights\n",
      "Loop 310000 / Episode 23775 / Epsilon 0.8771 / Avg. Reward -0.564 / Avg. Length 12.776 / Loss 49.6042 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 312000 / Episode 23931 / Epsilon 0.8767 / Avg. Reward -0.545 / Avg. Length 12.763 / Loss 56.0301 \n",
      "Loop 314000 / Episode 24080 / Epsilon 0.8762 / Avg. Reward -0.477 / Avg. Length 13.530 / Loss 54.0700 \n",
      "Loop 316000 / Episode 24234 / Epsilon 0.8757 / Avg. Reward -0.526 / Avg. Length 12.961 / Loss 52.0396 \n",
      "Loop 318000 / Episode 24379 / Epsilon 0.8753 / Avg. Reward -0.441 / Avg. Length 13.779 / Loss 51.5743 \n",
      "Saving model weights\n",
      "Loop 320000 / Episode 24523 / Epsilon 0.8748 / Avg. Reward -0.431 / Avg. Length 13.826 / Loss 50.6085 \n",
      "Loop 322000 / Episode 24680 / Epsilon 0.8743 / Avg. Reward -0.548 / Avg. Length 12.726 / Loss 54.9213 \n",
      "Loop 324000 / Episode 24828 / Epsilon 0.8739 / Avg. Reward -0.459 / Avg. Length 13.595 / Loss 52.5702 \n",
      "Loop 326000 / Episode 24980 / Epsilon 0.8734 / Avg. Reward -0.539 / Avg. Length 13.020 / Loss 51.4520 \n",
      "Loop 328000 / Episode 25140 / Epsilon 0.8729 / Avg. Reward -0.594 / Avg. Length 12.500 / Loss 49.6369 \n",
      "Saving model weights\n",
      "Loop 330000 / Episode 25292 / Epsilon 0.8724 / Avg. Reward -0.500 / Avg. Length 13.184 / Loss 49.7219 \n",
      "Loop 332000 / Episode 25453 / Epsilon 0.8720 / Avg. Reward -0.590 / Avg. Length 12.447 / Loss 54.7785 \n",
      "Loop 334000 / Episode 25602 / Epsilon 0.8715 / Avg. Reward -0.470 / Avg. Length 13.477 / Loss 49.8759 \n",
      "Loop 336000 / Episode 25750 / Epsilon 0.8710 / Avg. Reward -0.466 / Avg. Length 13.561 / Loss 49.7428 \n",
      "Loop 338000 / Episode 25898 / Epsilon 0.8706 / Avg. Reward -0.466 / Avg. Length 13.493 / Loss 48.0700 \n",
      "Saving model weights\n",
      "Loop 340000 / Episode 26038 / Epsilon 0.8701 / Avg. Reward -0.393 / Avg. Length 14.243 / Loss 49.0649 \n",
      "Loop 342000 / Episode 26186 / Epsilon 0.8696 / Avg. Reward -0.453 / Avg. Length 13.574 / Loss 53.9843 \n",
      "Loop 344000 / Episode 26328 / Epsilon 0.8692 / Avg. Reward -0.401 / Avg. Length 14.099 / Loss 50.9548 \n",
      "Loop 346000 / Episode 26475 / Epsilon 0.8687 / Avg. Reward -0.476 / Avg. Length 13.565 / Loss 49.1370 \n",
      "Loop 348000 / Episode 26620 / Epsilon 0.8682 / Avg. Reward -0.441 / Avg. Length 13.821 / Loss 49.2399 \n",
      "Saving model weights\n",
      "Loop 350000 / Episode 26768 / Epsilon 0.8677 / Avg. Reward -0.486 / Avg. Length 13.473 / Loss 48.8807 \n",
      "Loop 352000 / Episode 26922 / Epsilon 0.8673 / Avg. Reward -0.532 / Avg. Length 13.000 / Loss 55.6260 \n",
      "Loop 354000 / Episode 27063 / Epsilon 0.8668 / Avg. Reward -0.397 / Avg. Length 14.227 / Loss 53.1646 \n",
      "Loop 356000 / Episode 27203 / Epsilon 0.8663 / Avg. Reward -0.364 / Avg. Length 14.293 / Loss 52.1677 \n",
      "Loop 358000 / Episode 27353 / Epsilon 0.8659 / Avg. Reward -0.500 / Avg. Length 13.340 / Loss 50.6012 \n",
      "Saving model weights\n",
      "Loop 360000 / Episode 27501 / Epsilon 0.8654 / Avg. Reward -0.473 / Avg. Length 13.493 / Loss 49.1249 \n",
      "Loop 362000 / Episode 27662 / Epsilon 0.8649 / Avg. Reward -0.602 / Avg. Length 12.422 / Loss 55.3505 \n",
      "Loop 364000 / Episode 27800 / Epsilon 0.8645 / Avg. Reward -0.341 / Avg. Length 14.493 / Loss 53.6726 \n",
      "Loop 366000 / Episode 27940 / Epsilon 0.8640 / Avg. Reward -0.386 / Avg. Length 14.307 / Loss 51.7956 \n",
      "Loop 368000 / Episode 28083 / Epsilon 0.8635 / Avg. Reward -0.413 / Avg. Length 13.944 / Loss 50.1137 \n",
      "Saving model weights\n",
      "Loop 370000 / Episode 28232 / Epsilon 0.8630 / Avg. Reward -0.490 / Avg. Length 13.430 / Loss 50.9041 \n",
      "Loop 372000 / Episode 28383 / Epsilon 0.8626 / Avg. Reward -0.497 / Avg. Length 13.225 / Loss 57.3253 \n",
      "Loop 374000 / Episode 28536 / Epsilon 0.8621 / Avg. Reward -0.516 / Avg. Length 13.052 / Loss 53.9235 \n",
      "Loop 376000 / Episode 28685 / Epsilon 0.8616 / Avg. Reward -0.497 / Avg. Length 13.336 / Loss 52.4448 \n",
      "Loop 378000 / Episode 28831 / Epsilon 0.8612 / Avg. Reward -0.445 / Avg. Length 13.808 / Loss 51.7066 \n",
      "Saving model weights\n",
      "Loop 380000 / Episode 28977 / Epsilon 0.8607 / Avg. Reward -0.445 / Avg. Length 13.712 / Loss 52.0647 \n",
      "Loop 382000 / Episode 29127 / Epsilon 0.8602 / Avg. Reward -0.480 / Avg. Length 13.327 / Loss 60.1694 \n",
      "Loop 384000 / Episode 29279 / Epsilon 0.8598 / Avg. Reward -0.500 / Avg. Length 13.191 / Loss 55.8125 \n",
      "Loop 386000 / Episode 29436 / Epsilon 0.8593 / Avg. Reward -0.580 / Avg. Length 12.586 / Loss 54.3957 \n",
      "Loop 388000 / Episode 29582 / Epsilon 0.8588 / Avg. Reward -0.438 / Avg. Length 13.842 / Loss 54.5079 \n",
      "Saving model weights\n",
      "Loop 390000 / Episode 29717 / Epsilon 0.8583 / Avg. Reward -0.326 / Avg. Length 14.852 / Loss 53.6529 \n",
      "Loop 392000 / Episode 29854 / Epsilon 0.8579 / Avg. Reward -0.343 / Avg. Length 14.496 / Loss 60.0279 \n",
      "Loop 394000 / Episode 30007 / Epsilon 0.8574 / Avg. Reward -0.516 / Avg. Length 13.150 / Loss 57.6609 \n",
      "Loop 396000 / Episode 30160 / Epsilon 0.8569 / Avg. Reward -0.523 / Avg. Length 13.013 / Loss 54.8679 \n",
      "Loop 398000 / Episode 30305 / Epsilon 0.8565 / Avg. Reward -0.428 / Avg. Length 13.855 / Loss 54.5401 \n",
      "Saving model weights\n",
      "Loop 400000 / Episode 30464 / Epsilon 0.8560 / Avg. Reward -0.591 / Avg. Length 12.560 / Loss 52.5305 \n",
      "Loop 402000 / Episode 30609 / Epsilon 0.8555 / Avg. Reward -0.434 / Avg. Length 13.793 / Loss 59.4338 \n",
      "Loop 404000 / Episode 30757 / Epsilon 0.8551 / Avg. Reward -0.480 / Avg. Length 13.345 / Loss 57.2565 \n",
      "Loop 406000 / Episode 30914 / Epsilon 0.8546 / Avg. Reward -0.548 / Avg. Length 12.904 / Loss 56.2494 \n",
      "Loop 408000 / Episode 31050 / Epsilon 0.8541 / Avg. Reward -0.324 / Avg. Length 14.735 / Loss 54.2235 \n",
      "Saving model weights\n",
      "Loop 410000 / Episode 31193 / Epsilon 0.8536 / Avg. Reward -0.420 / Avg. Length 13.958 / Loss 53.2786 \n",
      "Loop 412000 / Episode 31345 / Epsilon 0.8532 / Avg. Reward -0.513 / Avg. Length 13.178 / Loss 58.1960 \n",
      "Loop 414000 / Episode 31502 / Epsilon 0.8527 / Avg. Reward -0.561 / Avg. Length 12.694 / Loss 55.6034 \n",
      "Loop 416000 / Episode 31645 / Epsilon 0.8522 / Avg. Reward -0.413 / Avg. Length 14.035 / Loss 55.2181 \n",
      "Loop 418000 / Episode 31796 / Epsilon 0.8518 / Avg. Reward -0.503 / Avg. Length 13.252 / Loss 52.3676 \n",
      "Saving model weights\n",
      "Loop 420000 / Episode 31950 / Epsilon 0.8513 / Avg. Reward -0.539 / Avg. Length 12.909 / Loss 52.5462 \n",
      "Loop 422000 / Episode 32099 / Epsilon 0.8508 / Avg. Reward -0.483 / Avg. Length 13.503 / Loss 57.3417 \n",
      "Loop 424000 / Episode 32249 / Epsilon 0.8504 / Avg. Reward -0.500 / Avg. Length 13.293 / Loss 53.9468 \n",
      "Loop 426000 / Episode 32400 / Epsilon 0.8499 / Avg. Reward -0.503 / Avg. Length 13.119 / Loss 53.0207 \n",
      "Loop 428000 / Episode 32548 / Epsilon 0.8494 / Avg. Reward -0.459 / Avg. Length 13.662 / Loss 51.7930 \n",
      "Saving model weights\n",
      "Loop 430000 / Episode 32686 / Epsilon 0.8489 / Avg. Reward -0.370 / Avg. Length 14.493 / Loss 52.1327 \n",
      "Loop 432000 / Episode 32833 / Epsilon 0.8485 / Avg. Reward -0.463 / Avg. Length 13.612 / Loss 55.5156 \n",
      "Loop 434000 / Episode 32973 / Epsilon 0.8480 / Avg. Reward -0.386 / Avg. Length 14.293 / Loss 51.8804 \n",
      "Loop 436000 / Episode 33108 / Epsilon 0.8475 / Avg. Reward -0.326 / Avg. Length 14.778 / Loss 50.9030 \n",
      "Loop 438000 / Episode 33263 / Epsilon 0.8471 / Avg. Reward -0.535 / Avg. Length 12.923 / Loss 50.9674 \n",
      "Saving model weights\n",
      "Loop 440000 / Episode 33414 / Epsilon 0.8466 / Avg. Reward -0.510 / Avg. Length 13.265 / Loss 49.9881 \n",
      "Loop 442000 / Episode 33558 / Epsilon 0.8461 / Avg. Reward -0.438 / Avg. Length 13.833 / Loss 59.3780 \n",
      "Loop 444000 / Episode 33714 / Epsilon 0.8457 / Avg. Reward -0.551 / Avg. Length 12.821 / Loss 54.2791 \n",
      "Loop 446000 / Episode 33868 / Epsilon 0.8452 / Avg. Reward -0.539 / Avg. Length 12.961 / Loss 53.6160 \n",
      "Loop 448000 / Episode 34015 / Epsilon 0.8447 / Avg. Reward -0.449 / Avg. Length 13.626 / Loss 52.9206 \n",
      "Saving model weights\n",
      "Loop 450000 / Episode 34169 / Epsilon 0.8442 / Avg. Reward -0.532 / Avg. Length 13.019 / Loss 52.0312 \n",
      "Loop 452000 / Episode 34303 / Epsilon 0.8438 / Avg. Reward -0.313 / Avg. Length 14.948 / Loss 56.8206 \n",
      "Loop 454000 / Episode 34453 / Epsilon 0.8433 / Avg. Reward -0.480 / Avg. Length 13.320 / Loss 53.9237 \n",
      "Loop 456000 / Episode 34609 / Epsilon 0.8428 / Avg. Reward -0.545 / Avg. Length 12.827 / Loss 52.8739 \n",
      "Loop 458000 / Episode 34754 / Epsilon 0.8424 / Avg. Reward -0.455 / Avg. Length 13.731 / Loss 52.5023 \n",
      "Saving model weights\n",
      "Loop 460000 / Episode 34896 / Epsilon 0.8419 / Avg. Reward -0.373 / Avg. Length 14.155 / Loss 51.4937 \n",
      "Loop 462000 / Episode 35048 / Epsilon 0.8414 / Avg. Reward -0.526 / Avg. Length 13.125 / Loss 54.6597 \n",
      "Loop 464000 / Episode 35198 / Epsilon 0.8410 / Avg. Reward -0.487 / Avg. Length 13.347 / Loss 51.5419 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 466000 / Episode 35343 / Epsilon 0.8405 / Avg. Reward -0.455 / Avg. Length 13.717 / Loss 51.1757 \n",
      "Loop 468000 / Episode 35487 / Epsilon 0.8400 / Avg. Reward -0.417 / Avg. Length 13.951 / Loss 49.5005 \n",
      "Saving model weights\n",
      "Loop 470000 / Episode 35631 / Epsilon 0.8395 / Avg. Reward -0.431 / Avg. Length 13.903 / Loss 49.2212 \n",
      "Loop 472000 / Episode 35780 / Epsilon 0.8391 / Avg. Reward -0.490 / Avg. Length 13.416 / Loss 54.9944 \n",
      "Loop 474000 / Episode 35922 / Epsilon 0.8386 / Avg. Reward -0.401 / Avg. Length 14.077 / Loss 52.1767 \n",
      "Loop 476000 / Episode 36067 / Epsilon 0.8381 / Avg. Reward -0.421 / Avg. Length 13.828 / Loss 51.0660 \n",
      "Loop 478000 / Episode 36224 / Epsilon 0.8377 / Avg. Reward -0.567 / Avg. Length 12.720 / Loss 51.3465 \n",
      "Saving model weights\n",
      "Loop 480000 / Episode 36372 / Epsilon 0.8372 / Avg. Reward -0.480 / Avg. Length 13.385 / Loss 49.3943 \n",
      "Loop 482000 / Episode 36526 / Epsilon 0.8367 / Avg. Reward -0.519 / Avg. Length 13.104 / Loss 52.3315 \n",
      "Loop 484000 / Episode 36684 / Epsilon 0.8363 / Avg. Reward -0.576 / Avg. Length 12.677 / Loss 49.6380 \n",
      "Loop 486000 / Episode 36835 / Epsilon 0.8358 / Avg. Reward -0.497 / Avg. Length 13.212 / Loss 48.1406 \n",
      "Loop 488000 / Episode 36979 / Epsilon 0.8353 / Avg. Reward -0.438 / Avg. Length 13.785 / Loss 48.1305 \n",
      "Saving model weights\n",
      "Loop 490000 / Episode 37115 / Epsilon 0.8348 / Avg. Reward -0.338 / Avg. Length 14.735 / Loss 47.5818 \n",
      "Loop 492000 / Episode 37251 / Epsilon 0.8344 / Avg. Reward -0.324 / Avg. Length 14.816 / Loss 53.7965 \n",
      "Loop 494000 / Episode 37394 / Epsilon 0.8339 / Avg. Reward -0.406 / Avg. Length 13.972 / Loss 52.3941 \n",
      "Loop 496000 / Episode 37537 / Epsilon 0.8334 / Avg. Reward -0.399 / Avg. Length 13.972 / Loss 50.0228 \n",
      "Loop 498000 / Episode 37682 / Epsilon 0.8330 / Avg. Reward -0.441 / Avg. Length 13.841 / Loss 50.5035 \n",
      "Saving model weights\n",
      "Loop 500000 / Episode 37823 / Epsilon 0.8325 / Avg. Reward -0.426 / Avg. Length 13.943 / Loss 48.5616 \n",
      "Loop 502000 / Episode 37968 / Epsilon 0.8320 / Avg. Reward -0.407 / Avg. Length 13.972 / Loss 56.0043 \n",
      "Loop 504000 / Episode 38112 / Epsilon 0.8316 / Avg. Reward -0.451 / Avg. Length 13.729 / Loss 53.2202 \n",
      "Loop 506000 / Episode 38247 / Epsilon 0.8311 / Avg. Reward -0.289 / Avg. Length 14.963 / Loss 53.1805 \n",
      "Loop 508000 / Episode 38399 / Epsilon 0.8306 / Avg. Reward -0.500 / Avg. Length 13.197 / Loss 51.4658 \n",
      "Saving model weights\n",
      "Loop 510000 / Episode 38535 / Epsilon 0.8301 / Avg. Reward -0.331 / Avg. Length 14.654 / Loss 50.6803 \n",
      "Loop 512000 / Episode 38665 / Epsilon 0.8297 / Avg. Reward -0.254 / Avg. Length 15.438 / Loss 52.9488 \n",
      "Loop 514000 / Episode 38792 / Epsilon 0.8292 / Avg. Reward -0.205 / Avg. Length 15.787 / Loss 50.5329 \n",
      "Loop 516000 / Episode 38937 / Epsilon 0.8287 / Avg. Reward -0.455 / Avg. Length 13.641 / Loss 48.5290 \n",
      "Loop 518000 / Episode 39080 / Epsilon 0.8283 / Avg. Reward -0.406 / Avg. Length 14.133 / Loss 48.4233 \n",
      "Saving model weights\n",
      "Loop 520000 / Episode 39228 / Epsilon 0.8278 / Avg. Reward -0.493 / Avg. Length 13.385 / Loss 47.6516 \n",
      "Loop 522000 / Episode 39373 / Epsilon 0.8273 / Avg. Reward -0.421 / Avg. Length 13.869 / Loss 52.7849 \n",
      "Loop 524000 / Episode 39518 / Epsilon 0.8269 / Avg. Reward -0.455 / Avg. Length 13.779 / Loss 49.8961 \n",
      "Loop 526000 / Episode 39661 / Epsilon 0.8264 / Avg. Reward -0.427 / Avg. Length 14.049 / Loss 49.6699 \n",
      "Loop 528000 / Episode 39793 / Epsilon 0.8259 / Avg. Reward -0.288 / Avg. Length 15.152 / Loss 48.5840 \n",
      "Saving model weights\n",
      "Loop 530000 / Episode 39952 / Epsilon 0.8254 / Avg. Reward -0.579 / Avg. Length 12.591 / Loss 48.0275 \n",
      "Loop 532000 / Episode 40103 / Epsilon 0.8250 / Avg. Reward -0.497 / Avg. Length 13.225 / Loss 51.7026 \n",
      "Loop 534000 / Episode 40248 / Epsilon 0.8245 / Avg. Reward -0.421 / Avg. Length 13.814 / Loss 50.0226 \n",
      "Loop 536000 / Episode 40394 / Epsilon 0.8240 / Avg. Reward -0.459 / Avg. Length 13.692 / Loss 48.7175 \n",
      "Loop 538000 / Episode 40544 / Epsilon 0.8236 / Avg. Reward -0.500 / Avg. Length 13.293 / Loss 48.7235 \n",
      "Saving model weights\n",
      "Loop 540000 / Episode 40688 / Epsilon 0.8231 / Avg. Reward -0.438 / Avg. Length 13.910 / Loss 47.9190 \n",
      "Loop 542000 / Episode 40839 / Epsilon 0.8226 / Avg. Reward -0.490 / Avg. Length 13.185 / Loss 55.7041 \n",
      "Loop 544000 / Episode 40975 / Epsilon 0.8222 / Avg. Reward -0.316 / Avg. Length 14.779 / Loss 53.9242 \n",
      "Loop 546000 / Episode 41114 / Epsilon 0.8217 / Avg. Reward -0.396 / Avg. Length 14.317 / Loss 52.3782 \n",
      "Loop 548000 / Episode 41250 / Epsilon 0.8212 / Avg. Reward -0.331 / Avg. Length 14.772 / Loss 50.1224 \n",
      "Saving model weights\n",
      "Loop 550000 / Episode 41401 / Epsilon 0.8207 / Avg. Reward -0.497 / Avg. Length 13.219 / Loss 49.6394 \n",
      "Loop 552000 / Episode 41532 / Epsilon 0.8203 / Avg. Reward -0.252 / Avg. Length 15.321 / Loss 57.8629 \n",
      "Loop 554000 / Episode 41675 / Epsilon 0.8198 / Avg. Reward -0.399 / Avg. Length 13.993 / Loss 55.1877 \n",
      "Loop 556000 / Episode 41815 / Epsilon 0.8193 / Avg. Reward -0.371 / Avg. Length 14.221 / Loss 53.2367 \n",
      "Loop 558000 / Episode 41960 / Epsilon 0.8189 / Avg. Reward -0.462 / Avg. Length 13.814 / Loss 52.1899 \n",
      "Saving model weights\n",
      "Loop 560000 / Episode 42103 / Epsilon 0.8184 / Avg. Reward -0.413 / Avg. Length 14.021 / Loss 52.9446 \n",
      "Loop 562000 / Episode 42255 / Epsilon 0.8179 / Avg. Reward -0.507 / Avg. Length 13.125 / Loss 54.9960 \n",
      "Loop 564000 / Episode 42403 / Epsilon 0.8175 / Avg. Reward -0.480 / Avg. Length 13.507 / Loss 52.8755 \n",
      "Loop 566000 / Episode 42546 / Epsilon 0.8170 / Avg. Reward -0.413 / Avg. Length 14.021 / Loss 51.9927 \n",
      "Loop 568000 / Episode 42674 / Epsilon 0.8165 / Avg. Reward -0.234 / Avg. Length 15.484 / Loss 49.3967 \n",
      "Saving model weights\n",
      "Loop 570000 / Episode 42820 / Epsilon 0.8160 / Avg. Reward -0.452 / Avg. Length 13.685 / Loss 50.4313 \n",
      "Loop 572000 / Episode 42960 / Epsilon 0.8156 / Avg. Reward -0.364 / Avg. Length 14.429 / Loss 52.9387 \n",
      "Loop 574000 / Episode 43098 / Epsilon 0.8151 / Avg. Reward -0.362 / Avg. Length 14.507 / Loss 52.0996 \n",
      "Loop 576000 / Episode 43248 / Epsilon 0.8146 / Avg. Reward -0.500 / Avg. Length 13.267 / Loss 50.4480 \n",
      "Loop 578000 / Episode 43388 / Epsilon 0.8142 / Avg. Reward -0.393 / Avg. Length 14.314 / Loss 50.1849 \n",
      "Saving model weights\n",
      "Loop 580000 / Episode 43528 / Epsilon 0.8137 / Avg. Reward -0.379 / Avg. Length 14.300 / Loss 49.4366 \n",
      "Loop 582000 / Episode 43664 / Epsilon 0.8132 / Avg. Reward -0.346 / Avg. Length 14.721 / Loss 58.2782 \n",
      "Loop 584000 / Episode 43809 / Epsilon 0.8128 / Avg. Reward -0.455 / Avg. Length 13.669 / Loss 54.4284 \n",
      "Loop 586000 / Episode 43954 / Epsilon 0.8123 / Avg. Reward -0.414 / Avg. Length 13.917 / Loss 52.9871 \n",
      "Loop 588000 / Episode 44100 / Epsilon 0.8118 / Avg. Reward -0.432 / Avg. Length 13.692 / Loss 53.1381 \n",
      "Saving model weights\n",
      "Loop 590000 / Episode 44240 / Epsilon 0.8113 / Avg. Reward -0.371 / Avg. Length 14.257 / Loss 52.4427 \n",
      "Loop 592000 / Episode 44378 / Epsilon 0.8109 / Avg. Reward -0.384 / Avg. Length 14.464 / Loss 57.4225 \n",
      "Loop 594000 / Episode 44499 / Epsilon 0.8104 / Avg. Reward -0.107 / Avg. Length 16.603 / Loss 56.8848 \n",
      "Loop 596000 / Episode 44645 / Epsilon 0.8099 / Avg. Reward -0.432 / Avg. Length 13.678 / Loss 54.9790 \n",
      "Loop 598000 / Episode 44785 / Epsilon 0.8095 / Avg. Reward -0.393 / Avg. Length 14.229 / Loss 54.4799 \n",
      "Saving model weights\n",
      "Loop 600000 / Episode 44931 / Epsilon 0.8090 / Avg. Reward -0.452 / Avg. Length 13.692 / Loss 53.7416 \n",
      "Loop 602000 / Episode 45073 / Epsilon 0.8085 / Avg. Reward -0.401 / Avg. Length 14.141 / Loss 58.9655 \n",
      "Loop 604000 / Episode 45214 / Epsilon 0.8081 / Avg. Reward -0.383 / Avg. Length 14.191 / Loss 56.3871 \n",
      "Loop 606000 / Episode 45356 / Epsilon 0.8076 / Avg. Reward -0.408 / Avg. Length 14.035 / Loss 54.9654 \n",
      "Loop 608000 / Episode 45504 / Epsilon 0.8071 / Avg. Reward -0.459 / Avg. Length 13.561 / Loss 53.3302 \n",
      "Saving model weights\n",
      "Loop 610000 / Episode 45642 / Epsilon 0.8066 / Avg. Reward -0.362 / Avg. Length 14.514 / Loss 53.3753 \n",
      "Loop 612000 / Episode 45777 / Epsilon 0.8062 / Avg. Reward -0.333 / Avg. Length 14.822 / Loss 56.9286 \n",
      "Loop 614000 / Episode 45906 / Epsilon 0.8057 / Avg. Reward -0.233 / Avg. Length 15.512 / Loss 54.0152 \n",
      "Loop 616000 / Episode 46040 / Epsilon 0.8052 / Avg. Reward -0.321 / Avg. Length 14.843 / Loss 53.2395 \n",
      "Loop 618000 / Episode 46184 / Epsilon 0.8048 / Avg. Reward -0.431 / Avg. Length 13.924 / Loss 53.2986 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights\n",
      "Loop 620000 / Episode 46324 / Epsilon 0.8043 / Avg. Reward -0.386 / Avg. Length 14.271 / Loss 52.7638 \n",
      "Loop 622000 / Episode 46461 / Epsilon 0.8038 / Avg. Reward -0.358 / Avg. Length 14.555 / Loss 55.4667 \n",
      "Loop 624000 / Episode 46599 / Epsilon 0.8034 / Avg. Reward -0.348 / Avg. Length 14.594 / Loss 53.5830 \n",
      "Loop 626000 / Episode 46730 / Epsilon 0.8029 / Avg. Reward -0.290 / Avg. Length 15.160 / Loss 52.4945 \n",
      "Loop 628000 / Episode 46881 / Epsilon 0.8024 / Avg. Reward -0.497 / Avg. Length 13.278 / Loss 51.7810 \n",
      "Saving model weights\n",
      "Loop 630000 / Episode 47029 / Epsilon 0.8019 / Avg. Reward -0.473 / Avg. Length 13.399 / Loss 49.7541 \n",
      "Loop 632000 / Episode 47149 / Epsilon 0.8015 / Avg. Reward -0.092 / Avg. Length 16.817 / Loss 55.5396 \n",
      "Loop 634000 / Episode 47296 / Epsilon 0.8010 / Avg. Reward -0.449 / Avg. Length 13.646 / Loss 52.2627 \n",
      "Loop 636000 / Episode 47437 / Epsilon 0.8005 / Avg. Reward -0.411 / Avg. Length 14.078 / Loss 50.9482 \n",
      "Loop 638000 / Episode 47575 / Epsilon 0.8001 / Avg. Reward -0.370 / Avg. Length 14.341 / Loss 49.9656 \n",
      "Saving model weights\n",
      "Loop 640000 / Episode 47703 / Epsilon 0.7996 / Avg. Reward -0.211 / Avg. Length 15.859 / Loss 49.1606 \n",
      "Loop 642000 / Episode 47845 / Epsilon 0.7991 / Avg. Reward -0.423 / Avg. Length 14.049 / Loss 56.0969 \n",
      "Loop 644000 / Episode 47986 / Epsilon 0.7987 / Avg. Reward -0.390 / Avg. Length 14.191 / Loss 53.4831 \n",
      "Loop 646000 / Episode 48143 / Epsilon 0.7982 / Avg. Reward -0.548 / Avg. Length 12.752 / Loss 53.4170 \n",
      "Loop 648000 / Episode 48296 / Epsilon 0.7977 / Avg. Reward -0.523 / Avg. Length 13.131 / Loss 53.8690 \n",
      "Saving model weights\n",
      "Loop 650000 / Episode 48435 / Epsilon 0.7972 / Avg. Reward -0.367 / Avg. Length 14.302 / Loss 51.9819 \n",
      "Loop 652000 / Episode 48576 / Epsilon 0.7968 / Avg. Reward -0.390 / Avg. Length 14.248 / Loss 57.5185 \n",
      "Loop 654000 / Episode 48715 / Epsilon 0.7963 / Avg. Reward -0.374 / Avg. Length 14.396 / Loss 54.7852 \n",
      "Loop 656000 / Episode 48855 / Epsilon 0.7958 / Avg. Reward -0.379 / Avg. Length 14.229 / Loss 53.5425 \n",
      "Loop 658000 / Episode 48997 / Epsilon 0.7954 / Avg. Reward -0.394 / Avg. Length 14.134 / Loss 53.4069 \n",
      "Saving model weights\n",
      "Loop 660000 / Episode 49152 / Epsilon 0.7949 / Avg. Reward -0.535 / Avg. Length 12.871 / Loss 52.5254 \n",
      "Loop 662000 / Episode 49296 / Epsilon 0.7944 / Avg. Reward -0.431 / Avg. Length 13.882 / Loss 57.6554 \n",
      "Loop 664000 / Episode 49434 / Epsilon 0.7940 / Avg. Reward -0.377 / Avg. Length 14.486 / Loss 56.5329 \n",
      "Loop 666000 / Episode 49581 / Epsilon 0.7935 / Avg. Reward -0.449 / Avg. Length 13.639 / Loss 54.1867 \n",
      "Loop 668000 / Episode 49709 / Epsilon 0.7930 / Avg. Reward -0.219 / Avg. Length 15.617 / Loss 53.8815 \n",
      "Saving model weights\n",
      "Loop 670000 / Episode 49850 / Epsilon 0.7925 / Avg. Reward -0.411 / Avg. Length 14.170 / Loss 53.0098 \n",
      "Loop 672000 / Episode 49994 / Epsilon 0.7921 / Avg. Reward -0.431 / Avg. Length 13.944 / Loss 58.0122 \n",
      "Loop 674000 / Episode 50130 / Epsilon 0.7916 / Avg. Reward -0.346 / Avg. Length 14.640 / Loss 56.1294 \n",
      "Loop 676000 / Episode 50283 / Epsilon 0.7911 / Avg. Reward -0.523 / Avg. Length 13.072 / Loss 53.9807 \n",
      "Loop 678000 / Episode 50422 / Epsilon 0.7907 / Avg. Reward -0.360 / Avg. Length 14.460 / Loss 54.4832 \n",
      "Saving model weights\n",
      "Loop 680000 / Episode 50563 / Epsilon 0.7902 / Avg. Reward -0.404 / Avg. Length 14.156 / Loss 54.1297 \n",
      "Loop 682000 / Episode 50707 / Epsilon 0.7897 / Avg. Reward -0.438 / Avg. Length 13.882 / Loss 57.4146 \n",
      "Loop 684000 / Episode 50835 / Epsilon 0.7893 / Avg. Reward -0.219 / Avg. Length 15.641 / Loss 55.0917 \n",
      "Loop 686000 / Episode 50977 / Epsilon 0.7888 / Avg. Reward -0.401 / Avg. Length 14.070 / Loss 53.4412 \n",
      "Loop 688000 / Episode 51115 / Epsilon 0.7883 / Avg. Reward -0.348 / Avg. Length 14.500 / Loss 53.8198 \n",
      "Saving model weights\n",
      "Loop 690000 / Episode 51247 / Epsilon 0.7878 / Avg. Reward -0.280 / Avg. Length 15.167 / Loss 53.8406 \n",
      "Loop 692000 / Episode 51385 / Epsilon 0.7874 / Avg. Reward -0.362 / Avg. Length 14.406 / Loss 58.2307 \n",
      "Loop 694000 / Episode 51526 / Epsilon 0.7869 / Avg. Reward -0.383 / Avg. Length 14.220 / Loss 57.5602 \n",
      "Loop 696000 / Episode 51674 / Epsilon 0.7864 / Avg. Reward -0.486 / Avg. Length 13.412 / Loss 55.8251 \n",
      "Loop 698000 / Episode 51810 / Epsilon 0.7860 / Avg. Reward -0.301 / Avg. Length 14.882 / Loss 54.9550 \n",
      "Saving model weights\n",
      "Loop 700000 / Episode 51944 / Epsilon 0.7855 / Avg. Reward -0.299 / Avg. Length 14.903 / Loss 54.6049 \n",
      "Loop 702000 / Episode 52079 / Epsilon 0.7850 / Avg. Reward -0.326 / Avg. Length 14.807 / Loss 58.6303 \n",
      "Loop 704000 / Episode 52228 / Epsilon 0.7846 / Avg. Reward -0.477 / Avg. Length 13.329 / Loss 56.3728 \n",
      "Loop 706000 / Episode 52360 / Epsilon 0.7841 / Avg. Reward -0.311 / Avg. Length 14.932 / Loss 54.8700 \n",
      "Loop 708000 / Episode 52502 / Epsilon 0.7836 / Avg. Reward -0.387 / Avg. Length 14.246 / Loss 54.5320 \n",
      "Saving model weights\n",
      "Loop 710000 / Episode 52633 / Epsilon 0.7831 / Avg. Reward -0.267 / Avg. Length 15.359 / Loss 52.7866 \n",
      "Loop 712000 / Episode 52768 / Epsilon 0.7827 / Avg. Reward -0.319 / Avg. Length 14.852 / Loss 59.1061 \n",
      "Loop 714000 / Episode 52909 / Epsilon 0.7822 / Avg. Reward -0.397 / Avg. Length 14.135 / Loss 57.0849 \n",
      "Loop 716000 / Episode 53049 / Epsilon 0.7817 / Avg. Reward -0.407 / Avg. Length 14.321 / Loss 55.7697 \n",
      "Loop 718000 / Episode 53188 / Epsilon 0.7813 / Avg. Reward -0.374 / Avg. Length 14.295 / Loss 55.8071 \n",
      "Saving model weights\n",
      "Loop 720000 / Episode 53342 / Epsilon 0.7808 / Avg. Reward -0.513 / Avg. Length 13.091 / Loss 55.1806 \n",
      "Loop 722000 / Episode 53474 / Epsilon 0.7803 / Avg. Reward -0.280 / Avg. Length 15.144 / Loss 59.4621 \n",
      "Loop 724000 / Episode 53604 / Epsilon 0.7799 / Avg. Reward -0.262 / Avg. Length 15.400 / Loss 55.5730 \n",
      "Loop 726000 / Episode 53732 / Epsilon 0.7794 / Avg. Reward -0.211 / Avg. Length 15.648 / Loss 55.7269 \n",
      "Loop 728000 / Episode 53869 / Epsilon 0.7789 / Avg. Reward -0.358 / Avg. Length 14.482 / Loss 55.9155 \n",
      "Saving model weights\n",
      "Loop 730000 / Episode 54012 / Epsilon 0.7784 / Avg. Reward -0.420 / Avg. Length 13.944 / Loss 55.2535 \n",
      "Loop 732000 / Episode 54147 / Epsilon 0.7780 / Avg. Reward -0.319 / Avg. Length 14.859 / Loss 59.6643 \n",
      "Loop 734000 / Episode 54285 / Epsilon 0.7775 / Avg. Reward -0.341 / Avg. Length 14.543 / Loss 57.7061 \n",
      "Loop 736000 / Episode 54433 / Epsilon 0.7770 / Avg. Reward -0.473 / Avg. Length 13.554 / Loss 56.0797 \n",
      "Loop 738000 / Episode 54574 / Epsilon 0.7766 / Avg. Reward -0.383 / Avg. Length 14.156 / Loss 53.9770 \n",
      "Saving model weights\n",
      "Loop 740000 / Episode 54719 / Epsilon 0.7761 / Avg. Reward -0.428 / Avg. Length 13.855 / Loss 55.1609 \n",
      "Loop 742000 / Episode 54862 / Epsilon 0.7756 / Avg. Reward -0.427 / Avg. Length 13.916 / Loss 56.2257 \n",
      "Loop 744000 / Episode 55012 / Epsilon 0.7752 / Avg. Reward -0.473 / Avg. Length 13.380 / Loss 54.6637 \n",
      "Loop 746000 / Episode 55150 / Epsilon 0.7747 / Avg. Reward -0.348 / Avg. Length 14.486 / Loss 53.8237 \n",
      "Loop 748000 / Episode 55283 / Epsilon 0.7742 / Avg. Reward -0.301 / Avg. Length 14.895 / Loss 53.5008 \n",
      "Saving model weights\n",
      "Loop 750000 / Episode 55434 / Epsilon 0.7737 / Avg. Reward -0.490 / Avg. Length 13.344 / Loss 52.5784 \n",
      "Loop 752000 / Episode 55570 / Epsilon 0.7733 / Avg. Reward -0.324 / Avg. Length 14.713 / Loss 57.9506 \n",
      "Loop 754000 / Episode 55701 / Epsilon 0.7728 / Avg. Reward -0.267 / Avg. Length 15.252 / Loss 55.8816 \n",
      "Loop 756000 / Episode 55837 / Epsilon 0.7723 / Avg. Reward -0.346 / Avg. Length 14.574 / Loss 55.1845 \n",
      "Loop 758000 / Episode 55979 / Epsilon 0.7719 / Avg. Reward -0.387 / Avg. Length 14.190 / Loss 53.3471 \n",
      "Saving model weights\n",
      "Loop 760000 / Episode 56118 / Epsilon 0.7714 / Avg. Reward -0.367 / Avg. Length 14.381 / Loss 54.1228 \n",
      "Loop 762000 / Episode 56253 / Epsilon 0.7709 / Avg. Reward -0.304 / Avg. Length 14.800 / Loss 56.8816 \n",
      "Loop 764000 / Episode 56391 / Epsilon 0.7705 / Avg. Reward -0.355 / Avg. Length 14.587 / Loss 55.5135 \n",
      "Loop 766000 / Episode 56533 / Epsilon 0.7700 / Avg. Reward -0.408 / Avg. Length 14.007 / Loss 56.4103 \n",
      "Loop 768000 / Episode 56678 / Epsilon 0.7695 / Avg. Reward -0.434 / Avg. Length 13.883 / Loss 55.3421 \n",
      "Saving model weights\n",
      "Loop 770000 / Episode 56817 / Epsilon 0.7690 / Avg. Reward -0.403 / Avg. Length 14.137 / Loss 53.8893 \n",
      "Loop 772000 / Episode 56950 / Epsilon 0.7686 / Avg. Reward -0.278 / Avg. Length 15.180 / Loss 62.2236 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 774000 / Episode 57090 / Epsilon 0.7681 / Avg. Reward -0.386 / Avg. Length 14.371 / Loss 59.8628 \n",
      "Loop 776000 / Episode 57235 / Epsilon 0.7676 / Avg. Reward -0.434 / Avg. Length 13.786 / Loss 57.8909 \n",
      "Loop 778000 / Episode 57376 / Epsilon 0.7672 / Avg. Reward -0.404 / Avg. Length 14.170 / Loss 58.6362 \n",
      "Saving model weights\n",
      "Loop 780000 / Episode 57514 / Epsilon 0.7667 / Avg. Reward -0.370 / Avg. Length 14.478 / Loss 57.8208 \n",
      "Loop 782000 / Episode 57643 / Epsilon 0.7662 / Avg. Reward -0.233 / Avg. Length 15.558 / Loss 60.0244 \n",
      "Loop 784000 / Episode 57767 / Epsilon 0.7658 / Avg. Reward -0.169 / Avg. Length 16.145 / Loss 57.7816 \n",
      "Loop 786000 / Episode 57898 / Epsilon 0.7653 / Avg. Reward -0.267 / Avg. Length 15.229 / Loss 56.2257 \n",
      "Loop 788000 / Episode 58039 / Epsilon 0.7648 / Avg. Reward -0.383 / Avg. Length 14.191 / Loss 55.7077 \n",
      "Saving model weights\n",
      "Loop 790000 / Episode 58172 / Epsilon 0.7643 / Avg. Reward -0.301 / Avg. Length 15.008 / Loss 55.2623 \n",
      "Loop 792000 / Episode 58316 / Epsilon 0.7639 / Avg. Reward -0.451 / Avg. Length 13.764 / Loss 57.5157 \n",
      "Loop 794000 / Episode 58448 / Epsilon 0.7634 / Avg. Reward -0.250 / Avg. Length 15.311 / Loss 55.2930 \n",
      "Loop 796000 / Episode 58575 / Epsilon 0.7629 / Avg. Reward -0.189 / Avg. Length 15.772 / Loss 54.4787 \n",
      "Loop 798000 / Episode 58710 / Epsilon 0.7625 / Avg. Reward -0.333 / Avg. Length 14.704 / Loss 54.2407 \n",
      "Saving model weights\n",
      "Loop 800000 / Episode 58843 / Epsilon 0.7620 / Avg. Reward -0.308 / Avg. Length 15.053 / Loss 52.5184 \n",
      "Loop 802000 / Episode 58991 / Epsilon 0.7615 / Avg. Reward -0.473 / Avg. Length 13.568 / Loss 59.9948 \n",
      "Loop 804000 / Episode 59137 / Epsilon 0.7611 / Avg. Reward -0.432 / Avg. Length 13.726 / Loss 58.3125 \n",
      "Loop 806000 / Episode 59263 / Epsilon 0.7606 / Avg. Reward -0.198 / Avg. Length 15.873 / Loss 57.0260 \n",
      "Loop 808000 / Episode 59396 / Epsilon 0.7601 / Avg. Reward -0.323 / Avg. Length 14.910 / Loss 57.0156 \n",
      "Saving model weights\n",
      "Loop 810000 / Episode 59537 / Epsilon 0.7596 / Avg. Reward -0.369 / Avg. Length 14.298 / Loss 56.3781 \n",
      "Loop 812000 / Episode 59668 / Epsilon 0.7592 / Avg. Reward -0.260 / Avg. Length 15.267 / Loss 59.9841 \n",
      "Loop 814000 / Episode 59802 / Epsilon 0.7587 / Avg. Reward -0.306 / Avg. Length 14.933 / Loss 56.2453 \n",
      "Loop 816000 / Episode 59947 / Epsilon 0.7582 / Avg. Reward -0.441 / Avg. Length 13.766 / Loss 55.8124 \n",
      "Loop 818000 / Episode 60065 / Epsilon 0.7578 / Avg. Reward -0.085 / Avg. Length 16.839 / Loss 55.5093 \n",
      "Saving model weights\n",
      "Loop 820000 / Episode 60198 / Epsilon 0.7573 / Avg. Reward -0.293 / Avg. Length 15.143 / Loss 53.1328 \n",
      "Loop 822000 / Episode 60335 / Epsilon 0.7568 / Avg. Reward -0.350 / Avg. Length 14.599 / Loss 56.8875 \n",
      "Loop 824000 / Episode 60458 / Epsilon 0.7564 / Avg. Reward -0.163 / Avg. Length 16.130 / Loss 54.4085 \n",
      "Loop 826000 / Episode 60590 / Epsilon 0.7559 / Avg. Reward -0.265 / Avg. Length 15.197 / Loss 54.3179 \n",
      "Loop 828000 / Episode 60715 / Epsilon 0.7554 / Avg. Reward -0.176 / Avg. Length 16.112 / Loss 53.8703 \n",
      "Saving model weights\n",
      "Loop 830000 / Episode 60847 / Epsilon 0.7549 / Avg. Reward -0.295 / Avg. Length 15.129 / Loss 52.5170 \n",
      "Loop 832000 / Episode 60977 / Epsilon 0.7545 / Avg. Reward -0.269 / Avg. Length 15.331 / Loss 59.7356 \n",
      "Loop 834000 / Episode 61127 / Epsilon 0.7540 / Avg. Reward -0.473 / Avg. Length 13.313 / Loss 58.3180 \n",
      "Loop 836000 / Episode 61259 / Epsilon 0.7535 / Avg. Reward -0.288 / Avg. Length 15.136 / Loss 57.7751 \n",
      "Loop 838000 / Episode 61395 / Epsilon 0.7531 / Avg. Reward -0.316 / Avg. Length 14.824 / Loss 56.7606 \n",
      "Saving model weights\n",
      "Loop 840000 / Episode 61535 / Epsilon 0.7526 / Avg. Reward -0.421 / Avg. Length 14.164 / Loss 55.4079 \n",
      "Loop 842000 / Episode 61669 / Epsilon 0.7521 / Avg. Reward -0.291 / Avg. Length 15.037 / Loss 61.5147 \n",
      "Loop 844000 / Episode 61812 / Epsilon 0.7517 / Avg. Reward -0.420 / Avg. Length 13.958 / Loss 59.6449 \n",
      "Loop 846000 / Episode 61935 / Epsilon 0.7512 / Avg. Reward -0.146 / Avg. Length 16.293 / Loss 59.2080 \n",
      "Loop 848000 / Episode 62065 / Epsilon 0.7507 / Avg. Reward -0.254 / Avg. Length 15.400 / Loss 58.1821 \n",
      "Saving model weights\n",
      "Loop 850000 / Episode 62201 / Epsilon 0.7502 / Avg. Reward -0.346 / Avg. Length 14.588 / Loss 56.8497 \n",
      "Loop 852000 / Episode 62341 / Epsilon 0.7498 / Avg. Reward -0.371 / Avg. Length 14.393 / Loss 60.2858 \n",
      "Loop 854000 / Episode 62479 / Epsilon 0.7493 / Avg. Reward -0.355 / Avg. Length 14.420 / Loss 58.6725 \n",
      "Loop 856000 / Episode 62602 / Epsilon 0.7488 / Avg. Reward -0.146 / Avg. Length 16.358 / Loss 56.6775 \n",
      "Loop 858000 / Episode 62731 / Epsilon 0.7484 / Avg. Reward -0.256 / Avg. Length 15.473 / Loss 56.4856 \n",
      "Saving model weights\n",
      "Loop 860000 / Episode 62868 / Epsilon 0.7479 / Avg. Reward -0.350 / Avg. Length 14.511 / Loss 56.4124 \n",
      "Loop 862000 / Episode 62994 / Epsilon 0.7474 / Avg. Reward -0.198 / Avg. Length 15.810 / Loss 60.6746 \n",
      "Loop 864000 / Episode 63119 / Epsilon 0.7470 / Avg. Reward -0.176 / Avg. Length 16.120 / Loss 60.1850 \n",
      "Loop 866000 / Episode 63255 / Epsilon 0.7465 / Avg. Reward -0.316 / Avg. Length 14.757 / Loss 58.5254 \n",
      "Loop 868000 / Episode 63388 / Epsilon 0.7460 / Avg. Reward -0.286 / Avg. Length 15.045 / Loss 57.2215 \n",
      "Saving model weights\n",
      "Loop 870000 / Episode 63512 / Epsilon 0.7455 / Avg. Reward -0.161 / Avg. Length 16.097 / Loss 58.5339 \n",
      "Loop 872000 / Episode 63652 / Epsilon 0.7451 / Avg. Reward -0.379 / Avg. Length 14.321 / Loss 62.8732 \n",
      "Loop 874000 / Episode 63780 / Epsilon 0.7446 / Avg. Reward -0.242 / Avg. Length 15.523 / Loss 60.2867 \n",
      "Loop 876000 / Episode 63921 / Epsilon 0.7441 / Avg. Reward -0.383 / Avg. Length 14.234 / Loss 57.7692 \n",
      "Loop 878000 / Episode 64043 / Epsilon 0.7437 / Avg. Reward -0.148 / Avg. Length 16.410 / Loss 56.3961 \n",
      "Saving model weights\n",
      "Loop 880000 / Episode 64165 / Epsilon 0.7432 / Avg. Reward -0.180 / Avg. Length 16.156 / Loss 57.8955 \n",
      "Loop 882000 / Episode 64295 / Epsilon 0.7427 / Avg. Reward -0.223 / Avg. Length 15.608 / Loss 61.4560 \n",
      "Loop 884000 / Episode 64423 / Epsilon 0.7423 / Avg. Reward -0.242 / Avg. Length 15.555 / Loss 59.7437 \n",
      "Loop 886000 / Episode 64565 / Epsilon 0.7418 / Avg. Reward -0.387 / Avg. Length 14.176 / Loss 58.6235 \n",
      "Loop 888000 / Episode 64690 / Epsilon 0.7413 / Avg. Reward -0.184 / Avg. Length 16.000 / Loss 57.7713 \n",
      "Saving model weights\n",
      "Loop 890000 / Episode 64819 / Epsilon 0.7408 / Avg. Reward -0.279 / Avg. Length 15.310 / Loss 57.0031 \n",
      "Loop 892000 / Episode 64940 / Epsilon 0.7404 / Avg. Reward -0.107 / Avg. Length 16.579 / Loss 61.2423 \n",
      "Loop 894000 / Episode 65075 / Epsilon 0.7399 / Avg. Reward -0.296 / Avg. Length 14.896 / Loss 58.2375 \n",
      "Loop 896000 / Episode 65208 / Epsilon 0.7394 / Avg. Reward -0.278 / Avg. Length 15.090 / Loss 58.5542 \n",
      "Loop 898000 / Episode 65343 / Epsilon 0.7390 / Avg. Reward -0.319 / Avg. Length 14.785 / Loss 57.3405 \n",
      "Saving model weights\n",
      "Loop 900000 / Episode 65484 / Epsilon 0.7385 / Avg. Reward -0.426 / Avg. Length 13.950 / Loss 57.6296 \n",
      "Loop 902000 / Episode 65616 / Epsilon 0.7380 / Avg. Reward -0.250 / Avg. Length 15.356 / Loss 61.7108 \n",
      "Loop 904000 / Episode 65749 / Epsilon 0.7376 / Avg. Reward -0.278 / Avg. Length 15.120 / Loss 60.2560 \n",
      "Loop 906000 / Episode 65886 / Epsilon 0.7371 / Avg. Reward -0.336 / Avg. Length 14.496 / Loss 58.9450 \n",
      "Loop 908000 / Episode 66014 / Epsilon 0.7366 / Avg. Reward -0.242 / Avg. Length 15.687 / Loss 58.3272 \n",
      "Saving model weights\n",
      "Loop 910000 / Episode 66151 / Epsilon 0.7361 / Avg. Reward -0.336 / Avg. Length 14.606 / Loss 57.7932 \n",
      "Loop 912000 / Episode 66285 / Epsilon 0.7357 / Avg. Reward -0.313 / Avg. Length 14.881 / Loss 61.8485 \n",
      "Loop 914000 / Episode 66427 / Epsilon 0.7352 / Avg. Reward -0.394 / Avg. Length 14.099 / Loss 61.0328 \n",
      "Loop 916000 / Episode 66531 / Epsilon 0.7347 / Avg. Reward  0.202 / Avg. Length 19.279 / Loss 58.2601 \n",
      "Loop 918000 / Episode 66666 / Epsilon 0.7343 / Avg. Reward -0.326 / Avg. Length 14.807 / Loss 58.2944 \n",
      "Saving model weights\n",
      "Loop 920000 / Episode 66799 / Epsilon 0.7338 / Avg. Reward -0.286 / Avg. Length 15.068 / Loss 57.3787 \n",
      "Loop 922000 / Episode 66932 / Epsilon 0.7333 / Avg. Reward -0.286 / Avg. Length 15.045 / Loss 62.2612 \n",
      "Loop 924000 / Episode 67064 / Epsilon 0.7329 / Avg. Reward -0.280 / Avg. Length 15.136 / Loss 58.8857 \n",
      "Loop 926000 / Episode 67188 / Epsilon 0.7324 / Avg. Reward -0.169 / Avg. Length 16.145 / Loss 59.5389 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 928000 / Episode 67323 / Epsilon 0.7319 / Avg. Reward -0.319 / Avg. Length 14.785 / Loss 58.0457 \n",
      "Saving model weights\n",
      "Loop 930000 / Episode 67463 / Epsilon 0.7314 / Avg. Reward -0.379 / Avg. Length 14.271 / Loss 57.7180 \n",
      "Loop 932000 / Episode 67590 / Epsilon 0.7310 / Avg. Reward -0.213 / Avg. Length 15.740 / Loss 62.7530 \n",
      "Loop 934000 / Episode 67712 / Epsilon 0.7305 / Avg. Reward -0.164 / Avg. Length 16.090 / Loss 60.8047 \n",
      "Loop 936000 / Episode 67850 / Epsilon 0.7300 / Avg. Reward -0.326 / Avg. Length 14.746 / Loss 59.3687 \n",
      "Loop 938000 / Episode 67981 / Epsilon 0.7296 / Avg. Reward -0.267 / Avg. Length 15.221 / Loss 57.6335 \n",
      "Saving model weights\n",
      "Loop 940000 / Episode 68116 / Epsilon 0.7291 / Avg. Reward -0.296 / Avg. Length 14.896 / Loss 58.3459 \n",
      "Loop 942000 / Episode 68249 / Epsilon 0.7286 / Avg. Reward -0.308 / Avg. Length 15.038 / Loss 62.5859 \n",
      "Loop 944000 / Episode 68377 / Epsilon 0.7282 / Avg. Reward -0.234 / Avg. Length 15.617 / Loss 58.7998 \n",
      "Loop 946000 / Episode 68508 / Epsilon 0.7277 / Avg. Reward -0.252 / Avg. Length 15.290 / Loss 59.7497 \n",
      "Loop 948000 / Episode 68634 / Epsilon 0.7272 / Avg. Reward -0.198 / Avg. Length 15.865 / Loss 58.5083 \n",
      "Saving model weights\n",
      "Loop 950000 / Episode 68758 / Epsilon 0.7267 / Avg. Reward -0.169 / Avg. Length 16.056 / Loss 58.0739 \n",
      "Loop 952000 / Episode 68888 / Epsilon 0.7263 / Avg. Reward -0.246 / Avg. Length 15.415 / Loss 62.6866 \n",
      "Loop 954000 / Episode 69014 / Epsilon 0.7258 / Avg. Reward -0.175 / Avg. Length 15.929 / Loss 59.5370 \n",
      "Loop 956000 / Episode 69141 / Epsilon 0.7253 / Avg. Reward -0.252 / Avg. Length 15.441 / Loss 59.6824 \n",
      "Loop 958000 / Episode 69271 / Epsilon 0.7249 / Avg. Reward -0.238 / Avg. Length 15.508 / Loss 58.8359 \n",
      "Saving model weights\n",
      "Loop 960000 / Episode 69397 / Epsilon 0.7244 / Avg. Reward -0.190 / Avg. Length 15.952 / Loss 58.1389 \n",
      "Loop 962000 / Episode 69518 / Epsilon 0.7239 / Avg. Reward -0.132 / Avg. Length 16.504 / Loss 65.5203 \n",
      "Loop 964000 / Episode 69663 / Epsilon 0.7235 / Avg. Reward -0.434 / Avg. Length 13.876 / Loss 63.7421 \n",
      "Loop 966000 / Episode 69785 / Epsilon 0.7230 / Avg. Reward -0.115 / Avg. Length 16.385 / Loss 63.0323 \n",
      "Loop 968000 / Episode 69902 / Epsilon 0.7225 / Avg. Reward -0.060 / Avg. Length 17.120 / Loss 62.2532 \n",
      "Saving model weights\n",
      "Loop 970000 / Episode 70034 / Epsilon 0.7220 / Avg. Reward -0.280 / Avg. Length 15.121 / Loss 61.6731 \n",
      "Loop 972000 / Episode 70157 / Epsilon 0.7216 / Avg. Reward -0.163 / Avg. Length 16.244 / Loss 63.2051 \n",
      "Loop 974000 / Episode 70293 / Epsilon 0.7211 / Avg. Reward -0.316 / Avg. Length 14.699 / Loss 63.2081 \n",
      "Loop 976000 / Episode 70419 / Epsilon 0.7206 / Avg. Reward -0.183 / Avg. Length 15.944 / Loss 61.8471 \n",
      "Loop 978000 / Episode 70540 / Epsilon 0.7202 / Avg. Reward -0.132 / Avg. Length 16.463 / Loss 60.1281 \n",
      "Saving model weights\n",
      "Loop 980000 / Episode 70664 / Epsilon 0.7197 / Avg. Reward -0.145 / Avg. Length 16.202 / Loss 60.4077 \n",
      "Loop 982000 / Episode 70791 / Epsilon 0.7192 / Avg. Reward -0.213 / Avg. Length 15.646 / Loss 62.6500 \n",
      "Loop 984000 / Episode 70922 / Epsilon 0.7188 / Avg. Reward -0.275 / Avg. Length 15.313 / Loss 62.2588 \n",
      "Loop 986000 / Episode 71044 / Epsilon 0.7183 / Avg. Reward -0.115 / Avg. Length 16.451 / Loss 60.0978 \n",
      "Loop 988000 / Episode 71166 / Epsilon 0.7178 / Avg. Reward -0.131 / Avg. Length 16.361 / Loss 60.5146 \n",
      "Saving model weights\n",
      "Loop 990000 / Episode 71305 / Epsilon 0.7173 / Avg. Reward -0.367 / Avg. Length 14.324 / Loss 60.3656 \n",
      "Loop 992000 / Episode 71435 / Epsilon 0.7169 / Avg. Reward -0.254 / Avg. Length 15.415 / Loss 61.5107 \n",
      "Loop 994000 / Episode 71565 / Epsilon 0.7164 / Avg. Reward -0.238 / Avg. Length 15.454 / Loss 60.1921 \n",
      "Loop 996000 / Episode 71694 / Epsilon 0.7159 / Avg. Reward -0.264 / Avg. Length 15.333 / Loss 58.7432 \n",
      "Loop 998000 / Episode 71814 / Epsilon 0.7155 / Avg. Reward -0.083 / Avg. Length 16.842 / Loss 57.9442 \n",
      "Saving model weights\n",
      "Loop 1000000 / Episode 71950 / Epsilon 0.7150 / Avg. Reward -0.338 / Avg. Length 14.618 / Loss 55.8414 \n",
      "Loop 1002000 / Episode 72075 / Epsilon 0.7145 / Avg. Reward -0.176 / Avg. Length 16.096 / Loss 61.3253 \n",
      "Loop 1004000 / Episode 72212 / Epsilon 0.7141 / Avg. Reward -0.328 / Avg. Length 14.599 / Loss 60.1284 \n",
      "Loop 1006000 / Episode 72336 / Epsilon 0.7136 / Avg. Reward -0.194 / Avg. Length 15.935 / Loss 57.9842 \n",
      "Loop 1008000 / Episode 72460 / Epsilon 0.7131 / Avg. Reward -0.153 / Avg. Length 16.202 / Loss 58.3303 \n",
      "Saving model weights\n",
      "Loop 1010000 / Episode 72597 / Epsilon 0.7126 / Avg. Reward -0.336 / Avg. Length 14.635 / Loss 59.6694 \n",
      "Loop 1012000 / Episode 72723 / Epsilon 0.7122 / Avg. Reward -0.214 / Avg. Length 15.754 / Loss 65.7160 \n",
      "Loop 1014000 / Episode 72845 / Epsilon 0.7117 / Avg. Reward -0.115 / Avg. Length 16.508 / Loss 63.7042 \n",
      "Loop 1016000 / Episode 72971 / Epsilon 0.7112 / Avg. Reward -0.183 / Avg. Length 15.952 / Loss 63.7559 \n",
      "Loop 1018000 / Episode 73117 / Epsilon 0.7108 / Avg. Reward -0.452 / Avg. Length 13.658 / Loss 61.7537 \n",
      "Saving model weights\n",
      "Loop 1020000 / Episode 73242 / Epsilon 0.7103 / Avg. Reward -0.208 / Avg. Length 15.896 / Loss 61.8267 \n",
      "Loop 1022000 / Episode 73388 / Epsilon 0.7098 / Avg. Reward -0.432 / Avg. Length 13.822 / Loss 65.6728 \n",
      "Loop 1024000 / Episode 73520 / Epsilon 0.7094 / Avg. Reward -0.288 / Avg. Length 15.008 / Loss 64.2807 \n",
      "Loop 1026000 / Episode 73648 / Epsilon 0.7089 / Avg. Reward -0.211 / Avg. Length 15.742 / Loss 62.1935 \n",
      "Loop 1028000 / Episode 73775 / Epsilon 0.7084 / Avg. Reward -0.213 / Avg. Length 15.709 / Loss 62.0215 \n",
      "Saving model weights\n",
      "Loop 1030000 / Episode 73896 / Epsilon 0.7079 / Avg. Reward -0.116 / Avg. Length 16.579 / Loss 62.2836 \n",
      "Loop 1032000 / Episode 74014 / Epsilon 0.7075 / Avg. Reward -0.085 / Avg. Length 16.847 / Loss 64.5924 \n",
      "Loop 1034000 / Episode 74149 / Epsilon 0.7070 / Avg. Reward -0.304 / Avg. Length 14.948 / Loss 63.3918 \n",
      "Loop 1036000 / Episode 74273 / Epsilon 0.7065 / Avg. Reward -0.169 / Avg. Length 16.056 / Loss 62.6599 \n",
      "Loop 1038000 / Episode 74400 / Epsilon 0.7061 / Avg. Reward -0.213 / Avg. Length 15.819 / Loss 61.6381 \n",
      "Saving model weights\n",
      "Loop 1040000 / Episode 74512 / Epsilon 0.7056 / Avg. Reward  0.027 / Avg. Length 17.786 / Loss 61.0547 \n",
      "Loop 1042000 / Episode 74637 / Epsilon 0.7051 / Avg. Reward -0.160 / Avg. Length 16.064 / Loss 67.5893 \n",
      "Loop 1044000 / Episode 74763 / Epsilon 0.7047 / Avg. Reward -0.214 / Avg. Length 15.738 / Loss 66.4193 \n",
      "Loop 1046000 / Episode 74899 / Epsilon 0.7042 / Avg. Reward -0.324 / Avg. Length 14.801 / Loss 64.9517 \n",
      "Loop 1048000 / Episode 75026 / Epsilon 0.7037 / Avg. Reward -0.205 / Avg. Length 15.756 / Loss 64.2799 \n",
      "Saving model weights\n",
      "Loop 1050000 / Episode 75147 / Epsilon 0.7032 / Avg. Reward -0.107 / Avg. Length 16.488 / Loss 62.9810 \n",
      "Loop 1052000 / Episode 75274 / Epsilon 0.7028 / Avg. Reward -0.205 / Avg. Length 15.701 / Loss 66.7104 \n",
      "Loop 1054000 / Episode 75407 / Epsilon 0.7023 / Avg. Reward -0.271 / Avg. Length 15.105 / Loss 63.8064 \n",
      "Loop 1056000 / Episode 75536 / Epsilon 0.7018 / Avg. Reward -0.240 / Avg. Length 15.496 / Loss 62.6218 \n",
      "Loop 1058000 / Episode 75669 / Epsilon 0.7014 / Avg. Reward -0.301 / Avg. Length 14.985 / Loss 61.4348 \n",
      "Saving model weights\n",
      "Loop 1060000 / Episode 75797 / Epsilon 0.7009 / Avg. Reward -0.227 / Avg. Length 15.539 / Loss 61.3876 \n",
      "Loop 1062000 / Episode 75926 / Epsilon 0.7004 / Avg. Reward -0.225 / Avg. Length 15.643 / Loss 64.0492 \n",
      "Loop 1064000 / Episode 76056 / Epsilon 0.7000 / Avg. Reward -0.238 / Avg. Length 15.400 / Loss 62.5917 \n",
      "Loop 1066000 / Episode 76202 / Epsilon 0.6995 / Avg. Reward -0.445 / Avg. Length 13.589 / Loss 61.2021 \n",
      "Loop 1068000 / Episode 76330 / Epsilon 0.6990 / Avg. Reward -0.203 / Avg. Length 15.750 / Loss 61.0673 \n",
      "Saving model weights\n",
      "Loop 1070000 / Episode 76458 / Epsilon 0.6985 / Avg. Reward -0.219 / Avg. Length 15.641 / Loss 60.5923 \n",
      "Loop 1072000 / Episode 76588 / Epsilon 0.6981 / Avg. Reward -0.262 / Avg. Length 15.269 / Loss 65.9109 \n",
      "Loop 1074000 / Episode 76708 / Epsilon 0.6976 / Avg. Reward -0.092 / Avg. Length 16.683 / Loss 63.4701 \n",
      "Loop 1076000 / Episode 76827 / Epsilon 0.6971 / Avg. Reward -0.067 / Avg. Length 16.908 / Loss 63.3446 \n",
      "Loop 1078000 / Episode 76948 / Epsilon 0.6967 / Avg. Reward -0.116 / Avg. Length 16.521 / Loss 63.2372 \n",
      "Saving model weights\n",
      "Loop 1080000 / Episode 77072 / Epsilon 0.6962 / Avg. Reward -0.177 / Avg. Length 16.129 / Loss 63.5364 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1082000 / Episode 77205 / Epsilon 0.6957 / Avg. Reward -0.286 / Avg. Length 15.060 / Loss 65.6586 \n",
      "Loop 1084000 / Episode 77324 / Epsilon 0.6953 / Avg. Reward -0.092 / Avg. Length 16.748 / Loss 63.7141 \n",
      "Loop 1086000 / Episode 77455 / Epsilon 0.6948 / Avg. Reward -0.275 / Avg. Length 15.160 / Loss 62.3870 \n",
      "Loop 1088000 / Episode 77578 / Epsilon 0.6943 / Avg. Reward -0.138 / Avg. Length 16.382 / Loss 61.8461 \n",
      "Saving model weights\n",
      "Loop 1090000 / Episode 77694 / Epsilon 0.6938 / Avg. Reward -0.052 / Avg. Length 17.259 / Loss 61.1625 \n",
      "Loop 1092000 / Episode 77815 / Epsilon 0.6934 / Avg. Reward -0.116 / Avg. Length 16.545 / Loss 63.8643 \n",
      "Loop 1094000 / Episode 77929 / Epsilon 0.6929 / Avg. Reward -0.035 / Avg. Length 17.368 / Loss 62.4564 \n",
      "Loop 1096000 / Episode 78036 / Epsilon 0.6924 / Avg. Reward  0.150 / Avg. Length 18.785 / Loss 62.8491 \n",
      "Loop 1098000 / Episode 78177 / Epsilon 0.6920 / Avg. Reward -0.397 / Avg. Length 14.227 / Loss 61.7083 \n",
      "Saving model weights\n",
      "Loop 1100000 / Episode 78300 / Epsilon 0.6915 / Avg. Reward -0.146 / Avg. Length 16.293 / Loss 60.7587 \n",
      "Loop 1102000 / Episode 78412 / Epsilon 0.6910 / Avg. Reward  0.009 / Avg. Length 17.562 / Loss 63.7910 \n",
      "Loop 1104000 / Episode 78534 / Epsilon 0.6906 / Avg. Reward -0.123 / Avg. Length 16.533 / Loss 62.4755 \n",
      "Loop 1106000 / Episode 78663 / Epsilon 0.6901 / Avg. Reward -0.209 / Avg. Length 15.628 / Loss 62.6558 \n",
      "Loop 1108000 / Episode 78785 / Epsilon 0.6896 / Avg. Reward -0.180 / Avg. Length 16.016 / Loss 62.6813 \n",
      "Saving model weights\n",
      "Loop 1110000 / Episode 78921 / Epsilon 0.6891 / Avg. Reward -0.279 / Avg. Length 15.029 / Loss 60.7827 \n",
      "Loop 1112000 / Episode 79056 / Epsilon 0.6887 / Avg. Reward -0.319 / Avg. Length 14.852 / Loss 63.2218 \n",
      "Loop 1114000 / Episode 79191 / Epsilon 0.6882 / Avg. Reward -0.326 / Avg. Length 14.778 / Loss 61.8418 \n",
      "Loop 1116000 / Episode 79297 / Epsilon 0.6877 / Avg. Reward  0.132 / Avg. Length 18.792 / Loss 59.7567 \n",
      "Loop 1118000 / Episode 79429 / Epsilon 0.6873 / Avg. Reward -0.288 / Avg. Length 15.250 / Loss 60.3106 \n",
      "Saving model weights\n",
      "Loop 1120000 / Episode 79547 / Epsilon 0.6868 / Avg. Reward -0.085 / Avg. Length 16.839 / Loss 58.3143 \n",
      "Loop 1122000 / Episode 79672 / Epsilon 0.6863 / Avg. Reward -0.168 / Avg. Length 16.088 / Loss 66.1316 \n",
      "Loop 1124000 / Episode 79789 / Epsilon 0.6859 / Avg. Reward -0.060 / Avg. Length 17.077 / Loss 64.6681 \n",
      "Loop 1126000 / Episode 79914 / Epsilon 0.6854 / Avg. Reward -0.200 / Avg. Length 15.928 / Loss 63.5306 \n",
      "Loop 1128000 / Episode 80047 / Epsilon 0.6849 / Avg. Reward -0.286 / Avg. Length 15.038 / Loss 61.9050 \n",
      "Saving model weights\n",
      "Loop 1130000 / Episode 80168 / Epsilon 0.6844 / Avg. Reward -0.107 / Avg. Length 16.595 / Loss 62.7531 \n",
      "Loop 1132000 / Episode 80288 / Epsilon 0.6840 / Avg. Reward -0.100 / Avg. Length 16.675 / Loss 65.8824 \n",
      "Loop 1134000 / Episode 80412 / Epsilon 0.6835 / Avg. Reward -0.161 / Avg. Length 16.137 / Loss 65.0262 \n",
      "Loop 1136000 / Episode 80544 / Epsilon 0.6830 / Avg. Reward -0.273 / Avg. Length 15.114 / Loss 63.9448 \n",
      "Loop 1138000 / Episode 80668 / Epsilon 0.6826 / Avg. Reward -0.161 / Avg. Length 16.145 / Loss 62.4291 \n",
      "Saving model weights\n",
      "Loop 1140000 / Episode 80783 / Epsilon 0.6821 / Avg. Reward -0.026 / Avg. Length 17.383 / Loss 63.4003 \n",
      "Loop 1142000 / Episode 80907 / Epsilon 0.6816 / Avg. Reward -0.161 / Avg. Length 16.177 / Loss 66.6200 \n",
      "Loop 1144000 / Episode 81045 / Epsilon 0.6812 / Avg. Reward -0.370 / Avg. Length 14.449 / Loss 63.1014 \n",
      "Loop 1146000 / Episode 81169 / Epsilon 0.6807 / Avg. Reward -0.137 / Avg. Length 16.097 / Loss 62.4378 \n",
      "Loop 1148000 / Episode 81290 / Epsilon 0.6802 / Avg. Reward -0.116 / Avg. Length 16.521 / Loss 63.1356 \n",
      "Saving model weights\n",
      "Loop 1150000 / Episode 81414 / Epsilon 0.6797 / Avg. Reward -0.194 / Avg. Length 16.024 / Loss 61.3775 \n",
      "Loop 1152000 / Episode 81533 / Epsilon 0.6793 / Avg. Reward -0.067 / Avg. Length 17.000 / Loss 64.1378 \n",
      "Loop 1154000 / Episode 81657 / Epsilon 0.6788 / Avg. Reward -0.137 / Avg. Length 16.137 / Loss 61.9758 \n",
      "Loop 1156000 / Episode 81791 / Epsilon 0.6783 / Avg. Reward -0.321 / Avg. Length 14.896 / Loss 62.8232 \n",
      "Loop 1158000 / Episode 81911 / Epsilon 0.6779 / Avg. Reward -0.083 / Avg. Length 16.683 / Loss 61.8566 \n",
      "Saving model weights\n",
      "Loop 1160000 / Episode 82048 / Epsilon 0.6774 / Avg. Reward -0.343 / Avg. Length 14.518 / Loss 62.1297 \n",
      "Loop 1162000 / Episode 82170 / Epsilon 0.6769 / Avg. Reward -0.115 / Avg. Length 16.410 / Loss 66.9641 \n",
      "Loop 1164000 / Episode 82294 / Epsilon 0.6765 / Avg. Reward -0.153 / Avg. Length 16.161 / Loss 64.2892 \n",
      "Loop 1166000 / Episode 82416 / Epsilon 0.6760 / Avg. Reward -0.148 / Avg. Length 16.320 / Loss 63.6088 \n",
      "Loop 1168000 / Episode 82547 / Epsilon 0.6755 / Avg. Reward -0.260 / Avg. Length 15.366 / Loss 63.9754 \n",
      "Saving model weights\n",
      "Loop 1170000 / Episode 82666 / Epsilon 0.6750 / Avg. Reward -0.126 / Avg. Length 16.647 / Loss 62.8427 \n",
      "Loop 1172000 / Episode 82803 / Epsilon 0.6746 / Avg. Reward -0.336 / Avg. Length 14.693 / Loss 69.1037 \n",
      "Loop 1174000 / Episode 82914 / Epsilon 0.6741 / Avg. Reward  0.072 / Avg. Length 18.045 / Loss 67.3391 \n",
      "Loop 1176000 / Episode 83039 / Epsilon 0.6736 / Avg. Reward -0.216 / Avg. Length 15.904 / Loss 68.2030 \n",
      "Loop 1178000 / Episode 83156 / Epsilon 0.6732 / Avg. Reward -0.051 / Avg. Length 17.077 / Loss 65.8609 \n",
      "Saving model weights\n",
      "Loop 1180000 / Episode 83282 / Epsilon 0.6727 / Avg. Reward -0.175 / Avg. Length 16.000 / Loss 65.9657 \n",
      "Loop 1182000 / Episode 83390 / Epsilon 0.6722 / Avg. Reward  0.120 / Avg. Length 18.417 / Loss 71.5093 \n",
      "Loop 1184000 / Episode 83521 / Epsilon 0.6718 / Avg. Reward -0.244 / Avg. Length 15.382 / Loss 68.9089 \n",
      "Loop 1186000 / Episode 83648 / Epsilon 0.6713 / Avg. Reward -0.220 / Avg. Length 15.709 / Loss 67.9551 \n",
      "Loop 1188000 / Episode 83772 / Epsilon 0.6708 / Avg. Reward -0.169 / Avg. Length 16.177 / Loss 68.7880 \n",
      "Saving model weights\n",
      "Loop 1190000 / Episode 83898 / Epsilon 0.6703 / Avg. Reward -0.198 / Avg. Length 15.873 / Loss 68.3388 \n",
      "Loop 1192000 / Episode 84021 / Epsilon 0.6699 / Avg. Reward -0.163 / Avg. Length 16.146 / Loss 70.9382 \n",
      "Loop 1194000 / Episode 84146 / Epsilon 0.6694 / Avg. Reward -0.200 / Avg. Length 15.976 / Loss 71.4181 \n",
      "Loop 1196000 / Episode 84270 / Epsilon 0.6689 / Avg. Reward -0.169 / Avg. Length 16.137 / Loss 69.8409 \n",
      "Loop 1198000 / Episode 84393 / Epsilon 0.6685 / Avg. Reward -0.187 / Avg. Length 16.016 / Loss 68.5724 \n",
      "Saving model weights\n",
      "Loop 1200000 / Episode 84509 / Epsilon 0.6680 / Avg. Reward  0.000 / Avg. Length 17.491 / Loss 66.8035 \n",
      "Loop 1202000 / Episode 84646 / Epsilon 0.6675 / Avg. Reward -0.328 / Avg. Length 14.664 / Loss 72.6620 \n",
      "Loop 1204000 / Episode 84768 / Epsilon 0.6671 / Avg. Reward -0.148 / Avg. Length 16.270 / Loss 71.2748 \n",
      "Loop 1206000 / Episode 84902 / Epsilon 0.6666 / Avg. Reward -0.306 / Avg. Length 15.007 / Loss 68.3378 \n",
      "Loop 1208000 / Episode 85019 / Epsilon 0.6661 / Avg. Reward -0.043 / Avg. Length 17.085 / Loss 68.6223 \n",
      "Saving model weights\n",
      "Loop 1210000 / Episode 85146 / Epsilon 0.6656 / Avg. Reward -0.213 / Avg. Length 15.709 / Loss 67.3880 \n",
      "Loop 1212000 / Episode 85273 / Epsilon 0.6652 / Avg. Reward -0.205 / Avg. Length 15.835 / Loss 71.8204 \n",
      "Loop 1214000 / Episode 85395 / Epsilon 0.6647 / Avg. Reward -0.156 / Avg. Length 16.295 / Loss 70.2598 \n",
      "Loop 1216000 / Episode 85505 / Epsilon 0.6642 / Avg. Reward  0.082 / Avg. Length 18.336 / Loss 69.7978 \n",
      "Loop 1218000 / Episode 85627 / Epsilon 0.6638 / Avg. Reward -0.131 / Avg. Length 16.361 / Loss 68.5351 \n",
      "Saving model weights\n",
      "Loop 1220000 / Episode 85736 / Epsilon 0.6633 / Avg. Reward  0.092 / Avg. Length 18.358 / Loss 67.1919 \n",
      "Loop 1222000 / Episode 85865 / Epsilon 0.6628 / Avg. Reward -0.287 / Avg. Length 15.318 / Loss 70.8627 \n",
      "Loop 1224000 / Episode 85985 / Epsilon 0.6624 / Avg. Reward -0.083 / Avg. Length 16.908 / Loss 69.2282 \n",
      "Loop 1226000 / Episode 86101 / Epsilon 0.6619 / Avg. Reward -0.043 / Avg. Length 17.181 / Loss 68.5604 \n",
      "Loop 1228000 / Episode 86215 / Epsilon 0.6614 / Avg. Reward -0.009 / Avg. Length 17.456 / Loss 67.9288 \n",
      "Saving model weights\n",
      "Loop 1230000 / Episode 86340 / Epsilon 0.6609 / Avg. Reward -0.168 / Avg. Length 16.104 / Loss 68.1053 \n",
      "Loop 1232000 / Episode 86461 / Epsilon 0.6605 / Avg. Reward -0.140 / Avg. Length 16.198 / Loss 66.3127 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1234000 / Episode 86568 / Epsilon 0.6600 / Avg. Reward  0.168 / Avg. Length 19.028 / Loss 64.0316 \n",
      "Loop 1236000 / Episode 86694 / Epsilon 0.6595 / Avg. Reward -0.190 / Avg. Length 15.937 / Loss 62.5463 \n",
      "Loop 1238000 / Episode 86809 / Epsilon 0.6591 / Avg. Reward -0.035 / Avg. Length 17.252 / Loss 62.4057 \n",
      "Saving model weights\n",
      "Loop 1240000 / Episode 86934 / Epsilon 0.6586 / Avg. Reward -0.160 / Avg. Length 16.048 / Loss 62.1079 \n",
      "Loop 1242000 / Episode 87047 / Epsilon 0.6581 / Avg. Reward  0.018 / Avg. Length 17.708 / Loss 67.3709 \n",
      "Loop 1244000 / Episode 87173 / Epsilon 0.6577 / Avg. Reward -0.183 / Avg. Length 15.937 / Loss 64.2201 \n",
      "Loop 1246000 / Episode 87301 / Epsilon 0.6572 / Avg. Reward -0.234 / Avg. Length 15.570 / Loss 65.0142 \n",
      "Loop 1248000 / Episode 87435 / Epsilon 0.6567 / Avg. Reward -0.284 / Avg. Length 14.985 / Loss 63.3139 \n",
      "Saving model weights\n",
      "Loop 1250000 / Episode 87553 / Epsilon 0.6562 / Avg. Reward -0.093 / Avg. Length 16.788 / Loss 63.3176 \n",
      "Loop 1252000 / Episode 87668 / Epsilon 0.6558 / Avg. Reward -0.026 / Avg. Length 17.400 / Loss 66.1803 \n",
      "Loop 1254000 / Episode 87793 / Epsilon 0.6553 / Avg. Reward -0.168 / Avg. Length 16.112 / Loss 64.7569 \n",
      "Loop 1256000 / Episode 87919 / Epsilon 0.6548 / Avg. Reward -0.183 / Avg. Length 15.833 / Loss 63.0228 \n",
      "Loop 1258000 / Episode 88036 / Epsilon 0.6544 / Avg. Reward -0.060 / Avg. Length 17.060 / Loss 62.6240 \n",
      "Saving model weights\n",
      "Loop 1260000 / Episode 88151 / Epsilon 0.6539 / Avg. Reward -0.000 / Avg. Length 17.496 / Loss 61.9280 \n",
      "Loop 1262000 / Episode 88260 / Epsilon 0.6534 / Avg. Reward  0.101 / Avg. Length 18.193 / Loss 65.0740 \n",
      "Loop 1264000 / Episode 88364 / Epsilon 0.6530 / Avg. Reward  0.221 / Avg. Length 19.404 / Loss 63.5013 \n",
      "Loop 1266000 / Episode 88476 / Epsilon 0.6525 / Avg. Reward  0.036 / Avg. Length 17.821 / Loss 61.7849 \n",
      "Loop 1268000 / Episode 88593 / Epsilon 0.6520 / Avg. Reward -0.060 / Avg. Length 17.068 / Loss 61.9465 \n",
      "Saving model weights\n",
      "Loop 1270000 / Episode 88717 / Epsilon 0.6515 / Avg. Reward -0.177 / Avg. Length 16.137 / Loss 61.2707 \n",
      "Loop 1272000 / Episode 88836 / Epsilon 0.6511 / Avg. Reward -0.092 / Avg. Length 16.807 / Loss 63.9539 \n",
      "Loop 1274000 / Episode 88956 / Epsilon 0.6506 / Avg. Reward -0.083 / Avg. Length 16.650 / Loss 62.8383 \n",
      "Loop 1276000 / Episode 89075 / Epsilon 0.6501 / Avg. Reward -0.084 / Avg. Length 16.790 / Loss 63.3946 \n",
      "Loop 1278000 / Episode 89196 / Epsilon 0.6497 / Avg. Reward -0.149 / Avg. Length 16.397 / Loss 62.8880 \n",
      "Saving model weights\n",
      "Loop 1280000 / Episode 89314 / Epsilon 0.6492 / Avg. Reward -0.051 / Avg. Length 17.119 / Loss 59.8422 \n",
      "Loop 1282000 / Episode 89428 / Epsilon 0.6487 / Avg. Reward -0.009 / Avg. Length 17.500 / Loss 68.1838 \n",
      "Loop 1284000 / Episode 89543 / Epsilon 0.6483 / Avg. Reward -0.017 / Avg. Length 17.443 / Loss 66.8099 \n",
      "Loop 1286000 / Episode 89658 / Epsilon 0.6478 / Avg. Reward -0.026 / Avg. Length 17.339 / Loss 64.9287 \n",
      "Loop 1288000 / Episode 89787 / Epsilon 0.6473 / Avg. Reward -0.233 / Avg. Length 15.527 / Loss 64.4510 \n",
      "Saving model weights\n",
      "Loop 1290000 / Episode 89908 / Epsilon 0.6468 / Avg. Reward -0.116 / Avg. Length 16.512 / Loss 64.5410 \n",
      "Loop 1292000 / Episode 90020 / Epsilon 0.6464 / Avg. Reward  0.036 / Avg. Length 17.893 / Loss 67.5205 \n",
      "Loop 1294000 / Episode 90128 / Epsilon 0.6459 / Avg. Reward  0.111 / Avg. Length 18.509 / Loss 64.8867 \n",
      "Loop 1296000 / Episode 90245 / Epsilon 0.6454 / Avg. Reward -0.034 / Avg. Length 17.145 / Loss 65.8581 \n",
      "Loop 1298000 / Episode 90371 / Epsilon 0.6450 / Avg. Reward -0.198 / Avg. Length 15.810 / Loss 65.1779 \n",
      "Saving model weights\n",
      "Loop 1300000 / Episode 90487 / Epsilon 0.6445 / Avg. Reward -0.060 / Avg. Length 17.155 / Loss 63.9711 \n",
      "Loop 1302000 / Episode 90609 / Epsilon 0.6440 / Avg. Reward -0.115 / Avg. Length 16.484 / Loss 71.1976 \n",
      "Loop 1304000 / Episode 90731 / Epsilon 0.6436 / Avg. Reward -0.115 / Avg. Length 16.434 / Loss 68.5866 \n",
      "Loop 1306000 / Episode 90849 / Epsilon 0.6431 / Avg. Reward -0.051 / Avg. Length 16.898 / Loss 67.8237 \n",
      "Loop 1308000 / Episode 90968 / Epsilon 0.6426 / Avg. Reward -0.067 / Avg. Length 16.866 / Loss 67.3786 \n",
      "Saving model weights\n",
      "Loop 1310000 / Episode 91084 / Epsilon 0.6421 / Avg. Reward -0.043 / Avg. Length 17.026 / Loss 66.3518 \n",
      "Loop 1312000 / Episode 91204 / Epsilon 0.6417 / Avg. Reward -0.083 / Avg. Length 16.858 / Loss 69.1460 \n",
      "Loop 1314000 / Episode 91314 / Epsilon 0.6412 / Avg. Reward  0.036 / Avg. Length 17.991 / Loss 67.6988 \n",
      "Loop 1316000 / Episode 91426 / Epsilon 0.6407 / Avg. Reward  0.036 / Avg. Length 17.946 / Loss 66.1076 \n",
      "Loop 1318000 / Episode 91535 / Epsilon 0.6403 / Avg. Reward  0.110 / Avg. Length 18.468 / Loss 64.8541 \n",
      "Saving model weights\n",
      "Loop 1320000 / Episode 91657 / Epsilon 0.6398 / Avg. Reward -0.139 / Avg. Length 16.320 / Loss 64.7511 \n",
      "Loop 1322000 / Episode 91771 / Epsilon 0.6393 / Avg. Reward  0.018 / Avg. Length 17.544 / Loss 66.5160 \n",
      "Loop 1324000 / Episode 91898 / Epsilon 0.6389 / Avg. Reward -0.213 / Avg. Length 15.795 / Loss 66.5329 \n",
      "Loop 1326000 / Episode 92013 / Epsilon 0.6384 / Avg. Reward  0.000 / Avg. Length 17.400 / Loss 64.6744 \n",
      "Loop 1328000 / Episode 92136 / Epsilon 0.6379 / Avg. Reward -0.146 / Avg. Length 16.228 / Loss 64.3639 \n",
      "Saving model weights\n",
      "Loop 1330000 / Episode 92251 / Epsilon 0.6374 / Avg. Reward -0.000 / Avg. Length 17.409 / Loss 63.3880 \n",
      "Loop 1332000 / Episode 92358 / Epsilon 0.6370 / Avg. Reward  0.131 / Avg. Length 18.692 / Loss 68.9981 \n",
      "Loop 1334000 / Episode 92470 / Epsilon 0.6365 / Avg. Reward  0.036 / Avg. Length 17.884 / Loss 66.3653 \n",
      "Loop 1336000 / Episode 92584 / Epsilon 0.6360 / Avg. Reward -0.009 / Avg. Length 17.404 / Loss 66.9183 \n",
      "Loop 1338000 / Episode 92713 / Epsilon 0.6356 / Avg. Reward -0.233 / Avg. Length 15.643 / Loss 66.5449 \n",
      "Saving model weights\n",
      "Loop 1340000 / Episode 92837 / Epsilon 0.6351 / Avg. Reward -0.169 / Avg. Length 16.000 / Loss 65.3096 \n",
      "Loop 1342000 / Episode 92961 / Epsilon 0.6346 / Avg. Reward -0.153 / Avg. Length 16.210 / Loss 70.1669 \n",
      "Loop 1344000 / Episode 93075 / Epsilon 0.6342 / Avg. Reward  0.000 / Avg. Length 17.526 / Loss 67.4803 \n",
      "Loop 1346000 / Episode 93196 / Epsilon 0.6337 / Avg. Reward -0.124 / Avg. Length 16.587 / Loss 66.5734 \n",
      "Loop 1348000 / Episode 93320 / Epsilon 0.6332 / Avg. Reward -0.153 / Avg. Length 16.105 / Loss 65.9317 \n",
      "Saving model weights\n",
      "Loop 1350000 / Episode 93425 / Epsilon 0.6327 / Avg. Reward  0.171 / Avg. Length 19.010 / Loss 66.7549 \n",
      "Loop 1352000 / Episode 93560 / Epsilon 0.6323 / Avg. Reward -0.311 / Avg. Length 14.785 / Loss 69.8672 \n",
      "Loop 1354000 / Episode 93676 / Epsilon 0.6318 / Avg. Reward -0.034 / Avg. Length 17.293 / Loss 67.9845 \n",
      "Loop 1356000 / Episode 93800 / Epsilon 0.6313 / Avg. Reward -0.169 / Avg. Length 16.105 / Loss 67.8910 \n",
      "Loop 1358000 / Episode 93924 / Epsilon 0.6309 / Avg. Reward -0.177 / Avg. Length 16.000 / Loss 67.2305 \n",
      "Saving model weights\n",
      "Loop 1360000 / Episode 94055 / Epsilon 0.6304 / Avg. Reward -0.244 / Avg. Length 15.458 / Loss 65.4854 \n",
      "Loop 1362000 / Episode 94175 / Epsilon 0.6299 / Avg. Reward -0.108 / Avg. Length 16.667 / Loss 70.9796 \n",
      "Loop 1364000 / Episode 94303 / Epsilon 0.6295 / Avg. Reward -0.211 / Avg. Length 15.617 / Loss 68.1624 \n",
      "Loop 1366000 / Episode 94419 / Epsilon 0.6290 / Avg. Reward -0.026 / Avg. Length 17.207 / Loss 69.7721 \n",
      "Loop 1368000 / Episode 94531 / Epsilon 0.6285 / Avg. Reward  0.036 / Avg. Length 17.884 / Loss 70.1125 \n",
      "Saving model weights\n",
      "Loop 1370000 / Episode 94646 / Epsilon 0.6280 / Avg. Reward -0.017 / Avg. Length 17.400 / Loss 67.8807 \n",
      "Loop 1372000 / Episode 94757 / Epsilon 0.6276 / Avg. Reward  0.072 / Avg. Length 17.982 / Loss 71.8414 \n",
      "Loop 1374000 / Episode 94874 / Epsilon 0.6271 / Avg. Reward -0.034 / Avg. Length 17.068 / Loss 69.1138 \n",
      "Loop 1376000 / Episode 94988 / Epsilon 0.6266 / Avg. Reward  0.018 / Avg. Length 17.588 / Loss 69.4314 \n",
      "Loop 1378000 / Episode 95100 / Epsilon 0.6262 / Avg. Reward  0.036 / Avg. Length 17.866 / Loss 68.6349 \n",
      "Saving model weights\n",
      "Loop 1380000 / Episode 95225 / Epsilon 0.6257 / Avg. Reward -0.192 / Avg. Length 15.904 / Loss 66.7331 \n",
      "Loop 1382000 / Episode 95346 / Epsilon 0.6252 / Avg. Reward -0.140 / Avg. Length 16.521 / Loss 70.7489 \n",
      "Loop 1384000 / Episode 95463 / Epsilon 0.6248 / Avg. Reward -0.026 / Avg. Length 17.231 / Loss 67.6060 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1386000 / Episode 95576 / Epsilon 0.6243 / Avg. Reward  0.009 / Avg. Length 17.646 / Loss 68.3593 \n",
      "Loop 1388000 / Episode 95697 / Epsilon 0.6238 / Avg. Reward -0.132 / Avg. Length 16.331 / Loss 67.5226 \n",
      "Saving model weights\n",
      "Loop 1390000 / Episode 95807 / Epsilon 0.6233 / Avg. Reward  0.082 / Avg. Length 18.291 / Loss 67.7743 \n",
      "Loop 1392000 / Episode 95922 / Epsilon 0.6229 / Avg. Reward -0.017 / Avg. Length 17.417 / Loss 69.2568 \n",
      "Loop 1394000 / Episode 96038 / Epsilon 0.6224 / Avg. Reward -0.026 / Avg. Length 17.293 / Loss 69.2779 \n",
      "Loop 1396000 / Episode 96152 / Epsilon 0.6219 / Avg. Reward -0.018 / Avg. Length 17.404 / Loss 67.0249 \n",
      "Loop 1398000 / Episode 96273 / Epsilon 0.6215 / Avg. Reward -0.083 / Avg. Length 16.694 / Loss 68.4219 \n",
      "Saving model weights\n",
      "Loop 1400000 / Episode 96382 / Epsilon 0.6210 / Avg. Reward  0.083 / Avg. Length 18.083 / Loss 68.4426 \n",
      "Loop 1402000 / Episode 96487 / Epsilon 0.6205 / Avg. Reward  0.229 / Avg. Length 19.343 / Loss 70.9182 \n",
      "Loop 1404000 / Episode 96605 / Epsilon 0.6201 / Avg. Reward -0.085 / Avg. Length 16.924 / Loss 69.8687 \n",
      "Loop 1406000 / Episode 96740 / Epsilon 0.6196 / Avg. Reward -0.326 / Avg. Length 14.793 / Loss 68.6537 \n",
      "Loop 1408000 / Episode 96851 / Epsilon 0.6191 / Avg. Reward  0.045 / Avg. Length 17.991 / Loss 67.1261 \n",
      "Saving model weights\n",
      "Loop 1410000 / Episode 96967 / Epsilon 0.6186 / Avg. Reward -0.017 / Avg. Length 17.345 / Loss 68.2572 \n",
      "Loop 1412000 / Episode 97083 / Epsilon 0.6182 / Avg. Reward -0.026 / Avg. Length 17.224 / Loss 72.2924 \n",
      "Loop 1414000 / Episode 97198 / Epsilon 0.6177 / Avg. Reward -0.026 / Avg. Length 17.278 / Loss 69.9793 \n",
      "Loop 1416000 / Episode 97315 / Epsilon 0.6172 / Avg. Reward -0.051 / Avg. Length 17.094 / Loss 69.8526 \n",
      "Loop 1418000 / Episode 97432 / Epsilon 0.6168 / Avg. Reward -0.060 / Avg. Length 17.103 / Loss 67.5456 \n",
      "Saving model weights\n",
      "Loop 1420000 / Episode 97558 / Epsilon 0.6163 / Avg. Reward -0.190 / Avg. Length 15.921 / Loss 68.3833 \n",
      "Loop 1422000 / Episode 97672 / Epsilon 0.6158 / Avg. Reward  0.000 / Avg. Length 17.553 / Loss 73.3389 \n",
      "Loop 1424000 / Episode 97780 / Epsilon 0.6154 / Avg. Reward  0.111 / Avg. Length 18.444 / Loss 71.6510 \n",
      "Loop 1426000 / Episode 97906 / Epsilon 0.6149 / Avg. Reward -0.198 / Avg. Length 15.746 / Loss 70.0996 \n",
      "Loop 1428000 / Episode 98029 / Epsilon 0.6144 / Avg. Reward -0.130 / Avg. Length 16.504 / Loss 69.7513 \n",
      "Saving model weights\n",
      "Loop 1430000 / Episode 98144 / Epsilon 0.6139 / Avg. Reward -0.009 / Avg. Length 17.391 / Loss 69.9488 \n",
      "Loop 1432000 / Episode 98262 / Epsilon 0.6135 / Avg. Reward -0.068 / Avg. Length 16.822 / Loss 72.3720 \n",
      "Loop 1434000 / Episode 98374 / Epsilon 0.6130 / Avg. Reward  0.036 / Avg. Length 17.866 / Loss 70.5931 \n",
      "Loop 1436000 / Episode 98493 / Epsilon 0.6125 / Avg. Reward -0.092 / Avg. Length 16.824 / Loss 70.2613 \n",
      "Loop 1438000 / Episode 98604 / Epsilon 0.6121 / Avg. Reward  0.036 / Avg. Length 17.919 / Loss 69.0151 \n",
      "Saving model weights\n",
      "Loop 1440000 / Episode 98710 / Epsilon 0.6116 / Avg. Reward  0.179 / Avg. Length 19.019 / Loss 70.3669 \n",
      "Loop 1442000 / Episode 98829 / Epsilon 0.6111 / Avg. Reward -0.092 / Avg. Length 16.739 / Loss 70.4141 \n",
      "Loop 1444000 / Episode 98936 / Epsilon 0.6107 / Avg. Reward  0.140 / Avg. Length 18.720 / Loss 69.4940 \n",
      "Loop 1446000 / Episode 99045 / Epsilon 0.6102 / Avg. Reward  0.119 / Avg. Length 18.440 / Loss 68.0932 \n",
      "Loop 1448000 / Episode 99140 / Epsilon 0.6097 / Avg. Reward  0.421 / Avg. Length 21.053 / Loss 66.7264 \n",
      "Saving model weights\n",
      "Loop 1450000 / Episode 99249 / Epsilon 0.6092 / Avg. Reward  0.110 / Avg. Length 18.339 / Loss 65.6764 \n",
      "Loop 1452000 / Episode 99353 / Epsilon 0.6088 / Avg. Reward  0.221 / Avg. Length 19.240 / Loss 69.5659 \n",
      "Loop 1454000 / Episode 99466 / Epsilon 0.6083 / Avg. Reward -0.009 / Avg. Length 17.381 / Loss 67.6146 \n",
      "Loop 1456000 / Episode 99582 / Epsilon 0.6078 / Avg. Reward -0.052 / Avg. Length 17.069 / Loss 67.1908 \n",
      "Loop 1458000 / Episode 99696 / Epsilon 0.6074 / Avg. Reward  0.061 / Avg. Length 18.000 / Loss 67.2966 \n",
      "Saving model weights\n",
      "Loop 1460000 / Episode 99814 / Epsilon 0.6069 / Avg. Reward -0.051 / Avg. Length 17.008 / Loss 67.2014 \n",
      "Loop 1462000 / Episode 99935 / Epsilon 0.6064 / Avg. Reward -0.124 / Avg. Length 16.529 / Loss 71.3254 \n",
      "Loop 1464000 / Episode 100051 / Epsilon 0.6060 / Avg. Reward -0.060 / Avg. Length 17.034 / Loss 68.2413 \n",
      "Loop 1466000 / Episode 100154 / Epsilon 0.6055 / Avg. Reward  0.243 / Avg. Length 19.485 / Loss 68.2188 \n",
      "Loop 1468000 / Episode 100271 / Epsilon 0.6050 / Avg. Reward -0.043 / Avg. Length 17.137 / Loss 68.6649 \n",
      "Saving model weights\n",
      "Loop 1470000 / Episode 100372 / Epsilon 0.6045 / Avg. Reward  0.257 / Avg. Length 19.772 / Loss 69.4290 \n",
      "Loop 1472000 / Episode 100483 / Epsilon 0.6041 / Avg. Reward  0.054 / Avg. Length 18.117 / Loss 69.5598 \n",
      "Loop 1474000 / Episode 100602 / Epsilon 0.6036 / Avg. Reward -0.076 / Avg. Length 16.782 / Loss 66.9620 \n",
      "Loop 1476000 / Episode 100722 / Epsilon 0.6031 / Avg. Reward -0.108 / Avg. Length 16.658 / Loss 67.4547 \n",
      "Loop 1478000 / Episode 100838 / Epsilon 0.6027 / Avg. Reward -0.034 / Avg. Length 17.259 / Loss 65.7696 \n",
      "Saving model weights\n",
      "Loop 1480000 / Episode 100945 / Epsilon 0.6022 / Avg. Reward  0.140 / Avg. Length 18.673 / Loss 65.7772 \n",
      "Loop 1482000 / Episode 101048 / Epsilon 0.6017 / Avg. Reward  0.233 / Avg. Length 19.485 / Loss 68.2029 \n",
      "Loop 1484000 / Episode 101162 / Epsilon 0.6013 / Avg. Reward  0.009 / Avg. Length 17.482 / Loss 66.3964 \n",
      "Loop 1486000 / Episode 101273 / Epsilon 0.6008 / Avg. Reward  0.063 / Avg. Length 18.009 / Loss 67.0033 \n",
      "Loop 1488000 / Episode 101372 / Epsilon 0.6003 / Avg. Reward  0.313 / Avg. Length 20.293 / Loss 66.8098 \n",
      "Saving model weights\n",
      "Loop 1490000 / Episode 101487 / Epsilon 0.5998 / Avg. Reward -0.026 / Avg. Length 17.209 / Loss 66.8091 \n",
      "Loop 1492000 / Episode 101594 / Epsilon 0.5994 / Avg. Reward  0.121 / Avg. Length 18.673 / Loss 69.9020 \n",
      "Loop 1494000 / Episode 101698 / Epsilon 0.5989 / Avg. Reward  0.240 / Avg. Length 19.423 / Loss 67.9758 \n",
      "Loop 1496000 / Episode 101806 / Epsilon 0.5984 / Avg. Reward  0.120 / Avg. Length 18.537 / Loss 68.3737 \n",
      "Loop 1498000 / Episode 101917 / Epsilon 0.5980 / Avg. Reward  0.063 / Avg. Length 17.964 / Loss 65.9897 \n",
      "Saving model weights\n",
      "Loop 1500000 / Episode 102039 / Epsilon 0.5975 / Avg. Reward -0.148 / Avg. Length 16.369 / Loss 66.8235 \n",
      "Loop 1502000 / Episode 102154 / Epsilon 0.5970 / Avg. Reward -0.009 / Avg. Length 17.348 / Loss 73.3107 \n",
      "Loop 1504000 / Episode 102257 / Epsilon 0.5966 / Avg. Reward  0.233 / Avg. Length 19.485 / Loss 71.0277 \n",
      "Loop 1506000 / Episode 102370 / Epsilon 0.5961 / Avg. Reward  0.000 / Avg. Length 17.602 / Loss 70.0934 \n",
      "Loop 1508000 / Episode 102468 / Epsilon 0.5956 / Avg. Reward  0.357 / Avg. Length 20.490 / Loss 69.8912 \n",
      "Saving model weights\n",
      "Loop 1510000 / Episode 102582 / Epsilon 0.5951 / Avg. Reward  0.009 / Avg. Length 17.509 / Loss 70.8994 \n",
      "Loop 1512000 / Episode 102685 / Epsilon 0.5947 / Avg. Reward  0.223 / Avg. Length 19.544 / Loss 72.8937 \n",
      "Loop 1514000 / Episode 102799 / Epsilon 0.5942 / Avg. Reward  0.018 / Avg. Length 17.561 / Loss 71.1391 \n",
      "Loop 1516000 / Episode 102897 / Epsilon 0.5937 / Avg. Reward  0.337 / Avg. Length 20.316 / Loss 69.8517 \n",
      "Loop 1518000 / Episode 102998 / Epsilon 0.5933 / Avg. Reward  0.277 / Avg. Length 19.842 / Loss 70.0605 \n",
      "Saving model weights\n",
      "Loop 1520000 / Episode 103099 / Epsilon 0.5928 / Avg. Reward  0.228 / Avg. Length 19.584 / Loss 68.3125 \n",
      "Loop 1522000 / Episode 103220 / Epsilon 0.5923 / Avg. Reward -0.116 / Avg. Length 16.554 / Loss 71.2701 \n",
      "Loop 1524000 / Episode 103324 / Epsilon 0.5919 / Avg. Reward  0.231 / Avg. Length 19.317 / Loss 71.3041 \n",
      "Loop 1526000 / Episode 103446 / Epsilon 0.5914 / Avg. Reward -0.148 / Avg. Length 16.336 / Loss 69.9001 \n",
      "Loop 1528000 / Episode 103558 / Epsilon 0.5909 / Avg. Reward  0.089 / Avg. Length 18.045 / Loss 69.2884 \n",
      "Saving model weights\n",
      "Loop 1530000 / Episode 103672 / Epsilon 0.5904 / Avg. Reward -0.026 / Avg. Length 17.482 / Loss 69.4442 \n",
      "Loop 1532000 / Episode 103789 / Epsilon 0.5900 / Avg. Reward -0.060 / Avg. Length 16.940 / Loss 75.2785 \n",
      "Loop 1534000 / Episode 103900 / Epsilon 0.5895 / Avg. Reward  0.027 / Avg. Length 17.946 / Loss 74.2951 \n",
      "Loop 1536000 / Episode 104009 / Epsilon 0.5890 / Avg. Reward  0.101 / Avg. Length 18.578 / Loss 73.3544 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1538000 / Episode 104113 / Epsilon 0.5886 / Avg. Reward  0.163 / Avg. Length 18.942 / Loss 73.8803 \n",
      "Saving model weights\n",
      "Loop 1540000 / Episode 104221 / Epsilon 0.5881 / Avg. Reward  0.157 / Avg. Length 18.750 / Loss 71.3208 \n",
      "Loop 1542000 / Episode 104330 / Epsilon 0.5876 / Avg. Reward  0.083 / Avg. Length 18.440 / Loss 75.1257 \n",
      "Loop 1544000 / Episode 104440 / Epsilon 0.5872 / Avg. Reward  0.073 / Avg. Length 18.182 / Loss 73.8275 \n",
      "Loop 1546000 / Episode 104549 / Epsilon 0.5867 / Avg. Reward  0.101 / Avg. Length 18.358 / Loss 72.3757 \n",
      "Loop 1548000 / Episode 104657 / Epsilon 0.5862 / Avg. Reward  0.093 / Avg. Length 18.417 / Loss 71.2127 \n",
      "Saving model weights\n",
      "Loop 1550000 / Episode 104765 / Epsilon 0.5857 / Avg. Reward  0.130 / Avg. Length 18.583 / Loss 70.6454 \n",
      "Loop 1552000 / Episode 104881 / Epsilon 0.5853 / Avg. Reward -0.052 / Avg. Length 17.009 / Loss 72.5856 \n",
      "Loop 1554000 / Episode 104989 / Epsilon 0.5848 / Avg. Reward  0.111 / Avg. Length 18.528 / Loss 70.9414 \n",
      "Loop 1556000 / Episode 105094 / Epsilon 0.5843 / Avg. Reward  0.190 / Avg. Length 19.219 / Loss 69.6297 \n",
      "Loop 1558000 / Episode 105195 / Epsilon 0.5839 / Avg. Reward  0.277 / Avg. Length 19.782 / Loss 68.9496 \n",
      "Saving model weights\n",
      "Loop 1560000 / Episode 105293 / Epsilon 0.5834 / Avg. Reward  0.347 / Avg. Length 20.531 / Loss 69.1525 \n",
      "Loop 1562000 / Episode 105401 / Epsilon 0.5829 / Avg. Reward  0.111 / Avg. Length 18.537 / Loss 73.7234 \n",
      "Loop 1564000 / Episode 105509 / Epsilon 0.5825 / Avg. Reward  0.102 / Avg. Length 18.481 / Loss 72.2041 \n",
      "Loop 1566000 / Episode 105621 / Epsilon 0.5820 / Avg. Reward  0.045 / Avg. Length 17.902 / Loss 71.1250 \n",
      "Loop 1568000 / Episode 105736 / Epsilon 0.5815 / Avg. Reward -0.035 / Avg. Length 17.383 / Loss 70.5065 \n",
      "Saving model weights\n",
      "Loop 1570000 / Episode 105853 / Epsilon 0.5810 / Avg. Reward -0.060 / Avg. Length 17.060 / Loss 69.8866 \n",
      "Loop 1572000 / Episode 105964 / Epsilon 0.5806 / Avg. Reward  0.054 / Avg. Length 17.955 / Loss 70.8890 \n",
      "Loop 1574000 / Episode 106069 / Epsilon 0.5801 / Avg. Reward  0.171 / Avg. Length 19.162 / Loss 68.7707 \n",
      "Loop 1576000 / Episode 106173 / Epsilon 0.5796 / Avg. Reward  0.173 / Avg. Length 19.221 / Loss 67.9615 \n",
      "Loop 1578000 / Episode 106274 / Epsilon 0.5792 / Avg. Reward  0.277 / Avg. Length 19.822 / Loss 66.8261 \n",
      "Saving model weights\n",
      "Loop 1580000 / Episode 106385 / Epsilon 0.5787 / Avg. Reward  0.054 / Avg. Length 17.955 / Loss 68.2089 \n",
      "Loop 1582000 / Episode 106486 / Epsilon 0.5782 / Avg. Reward  0.238 / Avg. Length 19.802 / Loss 68.1070 \n",
      "Loop 1584000 / Episode 106604 / Epsilon 0.5778 / Avg. Reward -0.076 / Avg. Length 16.864 / Loss 67.8161 \n",
      "Loop 1586000 / Episode 106720 / Epsilon 0.5773 / Avg. Reward -0.009 / Avg. Length 17.371 / Loss 69.7719 \n",
      "Loop 1588000 / Episode 106822 / Epsilon 0.5768 / Avg. Reward  0.245 / Avg. Length 19.608 / Loss 68.5988 \n",
      "Saving model weights\n",
      "Loop 1590000 / Episode 106941 / Epsilon 0.5763 / Avg. Reward -0.076 / Avg. Length 16.773 / Loss 67.3168 \n",
      "Loop 1592000 / Episode 107042 / Epsilon 0.5759 / Avg. Reward  0.248 / Avg. Length 19.782 / Loss 71.9186 \n",
      "Loop 1594000 / Episode 107128 / Epsilon 0.5754 / Avg. Reward  0.674 / Avg. Length 23.186 / Loss 71.8954 \n",
      "Loop 1596000 / Episode 107221 / Epsilon 0.5749 / Avg. Reward  0.452 / Avg. Length 21.366 / Loss 71.7970 \n",
      "Loop 1598000 / Episode 107321 / Epsilon 0.5745 / Avg. Reward  0.290 / Avg. Length 20.130 / Loss 70.6587 \n",
      "Saving model weights\n",
      "Loop 1600000 / Episode 107426 / Epsilon 0.5740 / Avg. Reward  0.200 / Avg. Length 19.171 / Loss 69.9068 \n",
      "Loop 1602000 / Episode 107528 / Epsilon 0.5735 / Avg. Reward  0.245 / Avg. Length 19.510 / Loss 74.4490 \n",
      "Loop 1604000 / Episode 107639 / Epsilon 0.5731 / Avg. Reward  0.090 / Avg. Length 18.009 / Loss 74.0430 \n",
      "Loop 1606000 / Episode 107758 / Epsilon 0.5726 / Avg. Reward -0.109 / Avg. Length 16.840 / Loss 72.1742 \n",
      "Loop 1608000 / Episode 107859 / Epsilon 0.5721 / Avg. Reward  0.267 / Avg. Length 19.762 / Loss 70.8400 \n",
      "Saving model weights\n",
      "Loop 1610000 / Episode 107971 / Epsilon 0.5716 / Avg. Reward  0.063 / Avg. Length 17.920 / Loss 70.3618 \n",
      "Loop 1612000 / Episode 108083 / Epsilon 0.5712 / Avg. Reward  0.036 / Avg. Length 17.884 / Loss 74.0419 \n",
      "Loop 1614000 / Episode 108183 / Epsilon 0.5707 / Avg. Reward  0.200 / Avg. Length 19.200 / Loss 73.3372 \n",
      "Loop 1616000 / Episode 108290 / Epsilon 0.5702 / Avg. Reward  0.215 / Avg. Length 19.355 / Loss 71.7761 \n",
      "Loop 1618000 / Episode 108398 / Epsilon 0.5698 / Avg. Reward  0.130 / Avg. Length 18.583 / Loss 72.5891 \n",
      "Saving model weights\n",
      "Loop 1620000 / Episode 108512 / Epsilon 0.5693 / Avg. Reward -0.009 / Avg. Length 17.377 / Loss 70.4338 \n",
      "Loop 1622000 / Episode 108611 / Epsilon 0.5688 / Avg. Reward  0.333 / Avg. Length 20.404 / Loss 73.7872 \n",
      "Loop 1624000 / Episode 108710 / Epsilon 0.5684 / Avg. Reward  0.293 / Avg. Length 20.071 / Loss 73.1119 \n",
      "Loop 1626000 / Episode 108821 / Epsilon 0.5679 / Avg. Reward  0.072 / Avg. Length 18.081 / Loss 72.6143 \n",
      "Loop 1628000 / Episode 108929 / Epsilon 0.5674 / Avg. Reward  0.111 / Avg. Length 18.426 / Loss 72.1370 \n",
      "Saving model weights\n",
      "Loop 1630000 / Episode 109036 / Epsilon 0.5669 / Avg. Reward  0.140 / Avg. Length 18.729 / Loss 72.4434 \n",
      "Loop 1632000 / Episode 109138 / Epsilon 0.5665 / Avg. Reward  0.245 / Avg. Length 19.755 / Loss 77.5977 \n",
      "Loop 1634000 / Episode 109240 / Epsilon 0.5660 / Avg. Reward  0.196 / Avg. Length 19.471 / Loss 75.4737 \n",
      "Loop 1636000 / Episode 109345 / Epsilon 0.5655 / Avg. Reward  0.152 / Avg. Length 19.019 / Loss 75.3106 \n",
      "Loop 1638000 / Episode 109455 / Epsilon 0.5651 / Avg. Reward  0.100 / Avg. Length 18.209 / Loss 74.2376 \n",
      "Saving model weights\n",
      "Loop 1640000 / Episode 109564 / Epsilon 0.5646 / Avg. Reward  0.128 / Avg. Length 18.477 / Loss 73.0560 \n",
      "Loop 1642000 / Episode 109676 / Epsilon 0.5641 / Avg. Reward  0.018 / Avg. Length 17.812 / Loss 73.6427 \n",
      "Loop 1644000 / Episode 109780 / Epsilon 0.5637 / Avg. Reward  0.173 / Avg. Length 19.077 / Loss 72.9878 \n",
      "Loop 1646000 / Episode 109892 / Epsilon 0.5632 / Avg. Reward  0.054 / Avg. Length 17.875 / Loss 71.0171 \n",
      "Loop 1648000 / Episode 109996 / Epsilon 0.5627 / Avg. Reward  0.212 / Avg. Length 19.375 / Loss 72.5442 \n",
      "Saving model weights\n",
      "Loop 1650000 / Episode 110110 / Epsilon 0.5622 / Avg. Reward  0.000 / Avg. Length 17.509 / Loss 71.9275 \n",
      "Loop 1652000 / Episode 110217 / Epsilon 0.5618 / Avg. Reward  0.140 / Avg. Length 18.701 / Loss 74.2837 \n",
      "Loop 1654000 / Episode 110334 / Epsilon 0.5613 / Avg. Reward -0.034 / Avg. Length 17.154 / Loss 72.6095 \n",
      "Loop 1656000 / Episode 110440 / Epsilon 0.5608 / Avg. Reward  0.142 / Avg. Length 18.858 / Loss 72.6995 \n",
      "Loop 1658000 / Episode 110538 / Epsilon 0.5604 / Avg. Reward  0.316 / Avg. Length 20.327 / Loss 71.7564 \n",
      "Saving model weights\n",
      "Loop 1660000 / Episode 110635 / Epsilon 0.5599 / Avg. Reward  0.361 / Avg. Length 20.577 / Loss 71.9731 \n",
      "Loop 1662000 / Episode 110748 / Epsilon 0.5594 / Avg. Reward  0.035 / Avg. Length 17.779 / Loss 72.0185 \n",
      "Loop 1664000 / Episode 110852 / Epsilon 0.5590 / Avg. Reward  0.173 / Avg. Length 19.231 / Loss 70.9719 \n",
      "Loop 1666000 / Episode 110956 / Epsilon 0.5585 / Avg. Reward  0.221 / Avg. Length 19.212 / Loss 70.7108 \n",
      "Loop 1668000 / Episode 111060 / Epsilon 0.5580 / Avg. Reward  0.202 / Avg. Length 19.240 / Loss 69.8619 \n",
      "Saving model weights\n",
      "Loop 1670000 / Episode 111161 / Epsilon 0.5575 / Avg. Reward  0.257 / Avg. Length 19.743 / Loss 70.1678 \n",
      "Loop 1672000 / Episode 111263 / Epsilon 0.5571 / Avg. Reward  0.265 / Avg. Length 19.676 / Loss 73.0549 \n",
      "Loop 1674000 / Episode 111360 / Epsilon 0.5566 / Avg. Reward  0.351 / Avg. Length 20.598 / Loss 72.9999 \n",
      "Loop 1676000 / Episode 111471 / Epsilon 0.5561 / Avg. Reward  0.054 / Avg. Length 17.928 / Loss 71.2950 \n",
      "Loop 1678000 / Episode 111567 / Epsilon 0.5557 / Avg. Reward  0.406 / Avg. Length 20.865 / Loss 71.6502 \n",
      "Saving model weights\n",
      "Loop 1680000 / Episode 111673 / Epsilon 0.5552 / Avg. Reward  0.179 / Avg. Length 18.991 / Loss 70.1352 \n",
      "Loop 1682000 / Episode 111780 / Epsilon 0.5547 / Avg. Reward  0.121 / Avg. Length 18.570 / Loss 77.8223 \n",
      "Loop 1684000 / Episode 111884 / Epsilon 0.5543 / Avg. Reward  0.202 / Avg. Length 19.337 / Loss 76.6693 \n",
      "Loop 1686000 / Episode 111997 / Epsilon 0.5538 / Avg. Reward  0.009 / Avg. Length 17.708 / Loss 74.6214 \n",
      "Loop 1688000 / Episode 112101 / Epsilon 0.5533 / Avg. Reward  0.212 / Avg. Length 19.202 / Loss 74.3736 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights\n",
      "Loop 1690000 / Episode 112208 / Epsilon 0.5528 / Avg. Reward  0.140 / Avg. Length 18.645 / Loss 74.0847 \n",
      "Loop 1692000 / Episode 112321 / Epsilon 0.5524 / Avg. Reward  0.009 / Avg. Length 17.593 / Loss 76.8858 \n",
      "Loop 1694000 / Episode 112438 / Epsilon 0.5519 / Avg. Reward -0.051 / Avg. Length 17.077 / Loss 75.1267 \n",
      "Loop 1696000 / Episode 112531 / Epsilon 0.5514 / Avg. Reward  0.462 / Avg. Length 21.570 / Loss 74.5727 \n",
      "Loop 1698000 / Episode 112648 / Epsilon 0.5510 / Avg. Reward -0.034 / Avg. Length 17.043 / Loss 74.2369 \n",
      "Saving model weights\n",
      "Loop 1700000 / Episode 112748 / Epsilon 0.5505 / Avg. Reward  0.300 / Avg. Length 20.030 / Loss 75.0513 \n",
      "Loop 1702000 / Episode 112841 / Epsilon 0.5500 / Avg. Reward  0.484 / Avg. Length 21.634 / Loss 78.9520 \n",
      "Loop 1704000 / Episode 112925 / Epsilon 0.5496 / Avg. Reward  0.702 / Avg. Length 23.464 / Loss 76.3641 \n",
      "Loop 1706000 / Episode 113024 / Epsilon 0.5491 / Avg. Reward  0.354 / Avg. Length 20.505 / Loss 75.5052 \n",
      "Loop 1708000 / Episode 113128 / Epsilon 0.5486 / Avg. Reward  0.202 / Avg. Length 19.308 / Loss 75.5930 \n",
      "Saving model weights\n",
      "Loop 1710000 / Episode 113224 / Epsilon 0.5481 / Avg. Reward  0.365 / Avg. Length 20.635 / Loss 75.7561 \n",
      "Loop 1712000 / Episode 113315 / Epsilon 0.5477 / Avg. Reward  0.527 / Avg. Length 21.835 / Loss 77.6181 \n",
      "Loop 1714000 / Episode 113408 / Epsilon 0.5472 / Avg. Reward  0.484 / Avg. Length 21.624 / Loss 76.4879 \n",
      "Loop 1716000 / Episode 113517 / Epsilon 0.5467 / Avg. Reward  0.128 / Avg. Length 18.541 / Loss 75.6449 \n",
      "Loop 1718000 / Episode 113642 / Epsilon 0.5463 / Avg. Reward -0.184 / Avg. Length 15.976 / Loss 76.3704 \n",
      "Saving model weights\n",
      "Loop 1720000 / Episode 113721 / Epsilon 0.5458 / Avg. Reward  0.924 / Avg. Length 25.190 / Loss 75.0719 \n",
      "Loop 1722000 / Episode 113827 / Epsilon 0.5453 / Avg. Reward  0.170 / Avg. Length 18.925 / Loss 77.7874 \n",
      "Loop 1724000 / Episode 113941 / Epsilon 0.5449 / Avg. Reward  0.009 / Avg. Length 17.482 / Loss 75.8076 \n",
      "Loop 1726000 / Episode 114058 / Epsilon 0.5444 / Avg. Reward -0.043 / Avg. Length 17.154 / Loss 74.8647 \n",
      "Loop 1728000 / Episode 114161 / Epsilon 0.5439 / Avg. Reward  0.223 / Avg. Length 19.427 / Loss 75.5805 \n",
      "Saving model weights\n",
      "Loop 1730000 / Episode 114261 / Epsilon 0.5434 / Avg. Reward  0.240 / Avg. Length 19.640 / Loss 73.9208 \n",
      "Loop 1732000 / Episode 114361 / Epsilon 0.5430 / Avg. Reward  0.340 / Avg. Length 20.280 / Loss 79.5110 \n",
      "Loop 1734000 / Episode 114454 / Epsilon 0.5425 / Avg. Reward  0.495 / Avg. Length 21.613 / Loss 77.6040 \n",
      "Loop 1736000 / Episode 114558 / Epsilon 0.5420 / Avg. Reward  0.183 / Avg. Length 19.192 / Loss 77.3852 \n",
      "Loop 1738000 / Episode 114654 / Epsilon 0.5416 / Avg. Reward  0.385 / Avg. Length 20.885 / Loss 76.9177 \n",
      "Saving model weights\n",
      "Loop 1740000 / Episode 114767 / Epsilon 0.5411 / Avg. Reward -0.053 / Avg. Length 17.124 / Loss 77.9753 \n",
      "Loop 1742000 / Episode 114870 / Epsilon 0.5406 / Avg. Reward  0.282 / Avg. Length 20.039 / Loss 77.2410 \n",
      "Loop 1744000 / Episode 114950 / Epsilon 0.5402 / Avg. Reward  0.912 / Avg. Length 25.050 / Loss 77.0768 \n",
      "Loop 1746000 / Episode 115048 / Epsilon 0.5397 / Avg. Reward  0.306 / Avg. Length 20.020 / Loss 77.3504 \n",
      "Loop 1748000 / Episode 115152 / Epsilon 0.5392 / Avg. Reward  0.192 / Avg. Length 19.442 / Loss 76.8685 \n",
      "Saving model weights\n",
      "Loop 1750000 / Episode 115256 / Epsilon 0.5387 / Avg. Reward  0.183 / Avg. Length 19.125 / Loss 75.2167 \n",
      "Loop 1752000 / Episode 115339 / Epsilon 0.5383 / Avg. Reward  0.795 / Avg. Length 24.398 / Loss 75.6783 \n",
      "Loop 1754000 / Episode 115430 / Epsilon 0.5378 / Avg. Reward  0.484 / Avg. Length 21.538 / Loss 73.6626 \n",
      "Loop 1756000 / Episode 115530 / Epsilon 0.5373 / Avg. Reward  0.310 / Avg. Length 20.320 / Loss 72.1501 \n",
      "Loop 1758000 / Episode 115634 / Epsilon 0.5369 / Avg. Reward  0.192 / Avg. Length 19.154 / Loss 72.9759 \n",
      "Saving model weights\n",
      "Loop 1760000 / Episode 115723 / Epsilon 0.5364 / Avg. Reward  0.562 / Avg. Length 22.292 / Loss 71.8417 \n",
      "Loop 1762000 / Episode 115825 / Epsilon 0.5359 / Avg. Reward  0.275 / Avg. Length 19.912 / Loss 76.5668 \n",
      "Loop 1764000 / Episode 115936 / Epsilon 0.5355 / Avg. Reward  0.045 / Avg. Length 17.964 / Loss 74.6996 \n",
      "Loop 1766000 / Episode 116030 / Epsilon 0.5350 / Avg. Reward  0.415 / Avg. Length 21.170 / Loss 73.9927 \n",
      "Loop 1768000 / Episode 116115 / Epsilon 0.5345 / Avg. Reward  0.729 / Avg. Length 23.671 / Loss 73.5201 \n",
      "Saving model weights\n",
      "Loop 1770000 / Episode 116213 / Epsilon 0.5340 / Avg. Reward  0.327 / Avg. Length 20.439 / Loss 73.2751 \n",
      "Loop 1772000 / Episode 116310 / Epsilon 0.5336 / Avg. Reward  0.351 / Avg. Length 20.598 / Loss 78.0145 \n",
      "Loop 1774000 / Episode 116427 / Epsilon 0.5331 / Avg. Reward -0.051 / Avg. Length 17.009 / Loss 76.5903 \n",
      "Loop 1776000 / Episode 116520 / Epsilon 0.5326 / Avg. Reward  0.462 / Avg. Length 21.677 / Loss 75.7813 \n",
      "Loop 1778000 / Episode 116622 / Epsilon 0.5322 / Avg. Reward  0.216 / Avg. Length 19.373 / Loss 74.2988 \n",
      "Saving model weights\n",
      "Loop 1780000 / Episode 116720 / Epsilon 0.5317 / Avg. Reward  0.347 / Avg. Length 20.480 / Loss 75.0283 \n",
      "Loop 1782000 / Episode 116826 / Epsilon 0.5312 / Avg. Reward  0.160 / Avg. Length 19.019 / Loss 77.2486 \n",
      "Loop 1784000 / Episode 116933 / Epsilon 0.5308 / Avg. Reward  0.121 / Avg. Length 18.617 / Loss 77.6036 \n",
      "Loop 1786000 / Episode 117024 / Epsilon 0.5303 / Avg. Reward  0.527 / Avg. Length 22.044 / Loss 76.0696 \n",
      "Loop 1788000 / Episode 117120 / Epsilon 0.5298 / Avg. Reward  0.396 / Avg. Length 20.823 / Loss 74.1638 \n",
      "Saving model weights\n",
      "Loop 1790000 / Episode 117206 / Epsilon 0.5293 / Avg. Reward  0.640 / Avg. Length 23.140 / Loss 74.6799 \n",
      "Loop 1792000 / Episode 117289 / Epsilon 0.5289 / Avg. Reward  0.807 / Avg. Length 24.229 / Loss 79.7208 \n",
      "Loop 1794000 / Episode 117383 / Epsilon 0.5284 / Avg. Reward  0.415 / Avg. Length 21.191 / Loss 78.3651 \n",
      "Loop 1796000 / Episode 117482 / Epsilon 0.5279 / Avg. Reward  0.283 / Avg. Length 19.919 / Loss 77.8009 \n",
      "Loop 1798000 / Episode 117582 / Epsilon 0.5275 / Avg. Reward  0.320 / Avg. Length 20.200 / Loss 77.9398 \n",
      "Saving model weights\n",
      "Loop 1800000 / Episode 117687 / Epsilon 0.5270 / Avg. Reward  0.152 / Avg. Length 18.867 / Loss 78.8049 \n",
      "Loop 1802000 / Episode 117775 / Epsilon 0.5265 / Avg. Reward  0.659 / Avg. Length 23.136 / Loss 81.6921 \n",
      "Loop 1804000 / Episode 117867 / Epsilon 0.5261 / Avg. Reward  0.489 / Avg. Length 21.707 / Loss 79.0766 \n",
      "Loop 1806000 / Episode 117956 / Epsilon 0.5256 / Avg. Reward  0.573 / Avg. Length 22.404 / Loss 78.2046 \n",
      "Loop 1808000 / Episode 118055 / Epsilon 0.5251 / Avg. Reward  0.323 / Avg. Length 20.212 / Loss 78.0865 \n",
      "Saving model weights\n",
      "Loop 1810000 / Episode 118159 / Epsilon 0.5246 / Avg. Reward  0.183 / Avg. Length 19.279 / Loss 78.1934 \n",
      "Loop 1812000 / Episode 118258 / Epsilon 0.5242 / Avg. Reward  0.313 / Avg. Length 20.020 / Loss 81.6227 \n",
      "Loop 1814000 / Episode 118354 / Epsilon 0.5237 / Avg. Reward  0.427 / Avg. Length 21.042 / Loss 81.3707 \n",
      "Loop 1816000 / Episode 118452 / Epsilon 0.5232 / Avg. Reward  0.327 / Avg. Length 20.235 / Loss 79.0593 \n",
      "Loop 1818000 / Episode 118555 / Epsilon 0.5228 / Avg. Reward  0.233 / Avg. Length 19.447 / Loss 78.8949 \n",
      "Saving model weights\n",
      "Loop 1820000 / Episode 118652 / Epsilon 0.5223 / Avg. Reward  0.351 / Avg. Length 20.412 / Loss 78.3039 \n",
      "Loop 1822000 / Episode 118739 / Epsilon 0.5218 / Avg. Reward  0.678 / Avg. Length 23.057 / Loss 78.4921 \n",
      "Loop 1824000 / Episode 118839 / Epsilon 0.5214 / Avg. Reward  0.340 / Avg. Length 20.270 / Loss 77.0149 \n",
      "Loop 1826000 / Episode 118939 / Epsilon 0.5209 / Avg. Reward  0.270 / Avg. Length 19.790 / Loss 77.1799 \n",
      "Loop 1828000 / Episode 119050 / Epsilon 0.5204 / Avg. Reward  0.081 / Avg. Length 18.216 / Loss 77.0272 \n",
      "Saving model weights\n",
      "Loop 1830000 / Episode 119162 / Epsilon 0.5199 / Avg. Reward  0.062 / Avg. Length 17.884 / Loss 77.9998 \n",
      "Loop 1832000 / Episode 119253 / Epsilon 0.5195 / Avg. Reward  0.484 / Avg. Length 21.802 / Loss 78.3377 \n",
      "Loop 1834000 / Episode 119357 / Epsilon 0.5190 / Avg. Reward  0.202 / Avg. Length 19.231 / Loss 76.9127 \n",
      "Loop 1836000 / Episode 119456 / Epsilon 0.5185 / Avg. Reward  0.313 / Avg. Length 20.313 / Loss 76.7451 \n",
      "Loop 1838000 / Episode 119563 / Epsilon 0.5181 / Avg. Reward  0.121 / Avg. Length 18.598 / Loss 75.7555 \n",
      "Saving model weights\n",
      "Loop 1840000 / Episode 119648 / Epsilon 0.5176 / Avg. Reward  0.706 / Avg. Length 23.659 / Loss 75.5053 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1842000 / Episode 119749 / Epsilon 0.5171 / Avg. Reward  0.257 / Avg. Length 19.644 / Loss 77.4337 \n",
      "Loop 1844000 / Episode 119849 / Epsilon 0.5167 / Avg. Reward  0.300 / Avg. Length 20.190 / Loss 76.7164 \n",
      "Loop 1846000 / Episode 119943 / Epsilon 0.5162 / Avg. Reward  0.383 / Avg. Length 20.638 / Loss 78.4907 \n",
      "Loop 1848000 / Episode 120033 / Epsilon 0.5157 / Avg. Reward  0.633 / Avg. Length 22.800 / Loss 77.5333 \n",
      "Saving model weights\n",
      "Loop 1850000 / Episode 120138 / Epsilon 0.5152 / Avg. Reward  0.190 / Avg. Length 19.124 / Loss 76.4747 \n",
      "Loop 1852000 / Episode 120231 / Epsilon 0.5148 / Avg. Reward  0.484 / Avg. Length 21.484 / Loss 78.2119 \n",
      "Loop 1854000 / Episode 120318 / Epsilon 0.5143 / Avg. Reward  0.621 / Avg. Length 22.713 / Loss 78.2364 \n",
      "Loop 1856000 / Episode 120410 / Epsilon 0.5138 / Avg. Reward  0.478 / Avg. Length 21.674 / Loss 75.8865 \n",
      "Loop 1858000 / Episode 120505 / Epsilon 0.5134 / Avg. Reward  0.463 / Avg. Length 21.316 / Loss 75.8028 \n",
      "Saving model weights\n",
      "Loop 1860000 / Episode 120606 / Epsilon 0.5129 / Avg. Reward  0.248 / Avg. Length 19.624 / Loss 76.9019 \n",
      "Loop 1862000 / Episode 120693 / Epsilon 0.5124 / Avg. Reward  0.621 / Avg. Length 22.943 / Loss 80.5680 \n",
      "Loop 1864000 / Episode 120790 / Epsilon 0.5120 / Avg. Reward  0.371 / Avg. Length 20.711 / Loss 77.9579 \n",
      "Loop 1866000 / Episode 120881 / Epsilon 0.5115 / Avg. Reward  0.560 / Avg. Length 22.209 / Loss 76.5178 \n",
      "Loop 1868000 / Episode 120990 / Epsilon 0.5110 / Avg. Reward  0.110 / Avg. Length 18.275 / Loss 75.6347 \n",
      "Saving model weights\n",
      "Loop 1870000 / Episode 121078 / Epsilon 0.5105 / Avg. Reward  0.625 / Avg. Length 22.716 / Loss 75.9340 \n",
      "Loop 1872000 / Episode 121166 / Epsilon 0.5101 / Avg. Reward  0.591 / Avg. Length 22.591 / Loss 79.4030 \n",
      "Loop 1874000 / Episode 121264 / Epsilon 0.5096 / Avg. Reward  0.357 / Avg. Length 20.408 / Loss 77.5688 \n",
      "Loop 1876000 / Episode 121359 / Epsilon 0.5091 / Avg. Reward  0.432 / Avg. Length 21.168 / Loss 78.0031 \n",
      "Loop 1878000 / Episode 121463 / Epsilon 0.5087 / Avg. Reward  0.212 / Avg. Length 19.212 / Loss 76.2409 \n",
      "Saving model weights\n",
      "Loop 1880000 / Episode 121557 / Epsilon 0.5082 / Avg. Reward  0.468 / Avg. Length 21.340 / Loss 75.7838 \n",
      "Loop 1882000 / Episode 121671 / Epsilon 0.5077 / Avg. Reward  0.000 / Avg. Length 17.553 / Loss 80.3437 \n",
      "Loop 1884000 / Episode 121755 / Epsilon 0.5073 / Avg. Reward  0.738 / Avg. Length 23.786 / Loss 78.4757 \n",
      "Loop 1886000 / Episode 121860 / Epsilon 0.5068 / Avg. Reward  0.152 / Avg. Length 19.029 / Loss 77.4558 \n",
      "Loop 1888000 / Episode 121960 / Epsilon 0.5063 / Avg. Reward  0.310 / Avg. Length 20.070 / Loss 78.1510 \n",
      "Saving model weights\n",
      "Loop 1890000 / Episode 122059 / Epsilon 0.5058 / Avg. Reward  0.313 / Avg. Length 20.101 / Loss 77.7419 \n",
      "Loop 1892000 / Episode 122150 / Epsilon 0.5054 / Avg. Reward  0.527 / Avg. Length 22.055 / Loss 82.5273 \n",
      "Loop 1894000 / Episode 122241 / Epsilon 0.5049 / Avg. Reward  0.505 / Avg. Length 21.879 / Loss 81.2896 \n",
      "Loop 1896000 / Episode 122327 / Epsilon 0.5044 / Avg. Reward  0.698 / Avg. Length 23.419 / Loss 80.9049 \n",
      "Loop 1898000 / Episode 122422 / Epsilon 0.5040 / Avg. Reward  0.400 / Avg. Length 20.874 / Loss 79.8342 \n",
      "Saving model weights\n",
      "Loop 1900000 / Episode 122517 / Epsilon 0.5035 / Avg. Reward  0.411 / Avg. Length 20.968 / Loss 79.5859 \n",
      "Loop 1902000 / Episode 122616 / Epsilon 0.5030 / Avg. Reward  0.343 / Avg. Length 20.414 / Loss 80.7662 \n",
      "Loop 1904000 / Episode 122718 / Epsilon 0.5026 / Avg. Reward  0.245 / Avg. Length 19.608 / Loss 79.0360 \n",
      "Loop 1906000 / Episode 122822 / Epsilon 0.5021 / Avg. Reward  0.212 / Avg. Length 19.260 / Loss 78.4387 \n",
      "Loop 1908000 / Episode 122907 / Epsilon 0.5016 / Avg. Reward  0.694 / Avg. Length 23.247 / Loss 77.6724 \n",
      "Saving model weights\n",
      "Loop 1910000 / Episode 123008 / Epsilon 0.5011 / Avg. Reward  0.287 / Avg. Length 19.881 / Loss 77.5550 \n",
      "Loop 1912000 / Episode 123098 / Epsilon 0.5007 / Avg. Reward  0.600 / Avg. Length 22.400 / Loss 80.8116 \n",
      "Loop 1914000 / Episode 123199 / Epsilon 0.5002 / Avg. Reward  0.248 / Avg. Length 19.594 / Loss 79.4443 \n",
      "Loop 1916000 / Episode 123291 / Epsilon 0.4997 / Avg. Reward  0.500 / Avg. Length 21.957 / Loss 79.4542 \n",
      "Loop 1918000 / Episode 123393 / Epsilon 0.4993 / Avg. Reward  0.225 / Avg. Length 19.598 / Loss 78.8091 \n",
      "Saving model weights\n",
      "Loop 1920000 / Episode 123483 / Epsilon 0.4988 / Avg. Reward  0.489 / Avg. Length 21.778 / Loss 78.5478 \n",
      "Loop 1922000 / Episode 123573 / Epsilon 0.4983 / Avg. Reward  0.622 / Avg. Length 22.667 / Loss 86.3909 \n",
      "Loop 1924000 / Episode 123653 / Epsilon 0.4979 / Avg. Reward  0.863 / Avg. Length 24.800 / Loss 86.7465 \n",
      "Loop 1926000 / Episode 123736 / Epsilon 0.4974 / Avg. Reward  0.795 / Avg. Length 24.120 / Loss 84.0423 \n",
      "Loop 1928000 / Episode 123825 / Epsilon 0.4969 / Avg. Reward  0.494 / Avg. Length 21.674 / Loss 84.5723 \n",
      "Saving model weights\n",
      "Loop 1930000 / Episode 123922 / Epsilon 0.4964 / Avg. Reward  0.464 / Avg. Length 21.505 / Loss 84.6880 \n",
      "Loop 1932000 / Episode 124010 / Epsilon 0.4960 / Avg. Reward  0.602 / Avg. Length 22.545 / Loss 83.5236 \n",
      "Loop 1934000 / Episode 124115 / Epsilon 0.4955 / Avg. Reward  0.171 / Avg. Length 19.133 / Loss 81.1090 \n",
      "Loop 1936000 / Episode 124213 / Epsilon 0.4950 / Avg. Reward  0.347 / Avg. Length 20.449 / Loss 81.9795 \n",
      "Loop 1938000 / Episode 124301 / Epsilon 0.4946 / Avg. Reward  0.602 / Avg. Length 22.580 / Loss 80.8012 \n",
      "Saving model weights\n",
      "Loop 1940000 / Episode 124397 / Epsilon 0.4941 / Avg. Reward  0.406 / Avg. Length 20.927 / Loss 80.4898 \n",
      "Loop 1942000 / Episode 124499 / Epsilon 0.4936 / Avg. Reward  0.235 / Avg. Length 19.637 / Loss 87.3165 \n",
      "Loop 1944000 / Episode 124601 / Epsilon 0.4932 / Avg. Reward  0.255 / Avg. Length 19.588 / Loss 85.1192 \n",
      "Loop 1946000 / Episode 124694 / Epsilon 0.4927 / Avg. Reward  0.441 / Avg. Length 21.473 / Loss 83.9440 \n",
      "Loop 1948000 / Episode 124793 / Epsilon 0.4922 / Avg. Reward  0.313 / Avg. Length 20.232 / Loss 84.0703 \n",
      "Saving model weights\n",
      "Loop 1950000 / Episode 124905 / Epsilon 0.4917 / Avg. Reward  0.054 / Avg. Length 17.875 / Loss 85.4574 \n",
      "Loop 1952000 / Episode 124986 / Epsilon 0.4913 / Avg. Reward  0.802 / Avg. Length 24.346 / Loss 83.2705 \n",
      "Loop 1954000 / Episode 125088 / Epsilon 0.4908 / Avg. Reward  0.294 / Avg. Length 19.902 / Loss 80.8758 \n",
      "Loop 1956000 / Episode 125176 / Epsilon 0.4903 / Avg. Reward  0.580 / Avg. Length 22.693 / Loss 80.0930 \n",
      "Loop 1958000 / Episode 125264 / Epsilon 0.4899 / Avg. Reward  0.636 / Avg. Length 22.761 / Loss 80.9561 \n",
      "Saving model weights\n",
      "Loop 1960000 / Episode 125351 / Epsilon 0.4894 / Avg. Reward  0.632 / Avg. Length 22.874 / Loss 79.2430 \n",
      "Loop 1962000 / Episode 125442 / Epsilon 0.4889 / Avg. Reward  0.538 / Avg. Length 22.022 / Loss 82.0640 \n",
      "Loop 1964000 / Episode 125533 / Epsilon 0.4885 / Avg. Reward  0.527 / Avg. Length 22.088 / Loss 81.4510 \n",
      "Loop 1966000 / Episode 125622 / Epsilon 0.4880 / Avg. Reward  0.573 / Avg. Length 22.438 / Loss 79.8506 \n",
      "Loop 1968000 / Episode 125716 / Epsilon 0.4875 / Avg. Reward  0.426 / Avg. Length 21.277 / Loss 78.2850 \n",
      "Saving model weights\n",
      "Loop 1970000 / Episode 125821 / Epsilon 0.4870 / Avg. Reward  0.171 / Avg. Length 19.029 / Loss 80.3439 \n",
      "Loop 1972000 / Episode 125914 / Epsilon 0.4866 / Avg. Reward  0.462 / Avg. Length 21.484 / Loss 82.6582 \n",
      "Loop 1974000 / Episode 126012 / Epsilon 0.4861 / Avg. Reward  0.327 / Avg. Length 20.255 / Loss 80.1754 \n",
      "Loop 1976000 / Episode 126098 / Epsilon 0.4856 / Avg. Reward  0.698 / Avg. Length 23.477 / Loss 80.4569 \n",
      "Loop 1978000 / Episode 126193 / Epsilon 0.4852 / Avg. Reward  0.358 / Avg. Length 20.621 / Loss 78.9684 \n",
      "Saving model weights\n",
      "Loop 1980000 / Episode 126270 / Epsilon 0.4847 / Avg. Reward  1.026 / Avg. Length 26.545 / Loss 79.6133 \n",
      "Loop 1982000 / Episode 126355 / Epsilon 0.4842 / Avg. Reward  0.659 / Avg. Length 23.318 / Loss 83.3668 \n",
      "Loop 1984000 / Episode 126450 / Epsilon 0.4838 / Avg. Reward  0.421 / Avg. Length 20.811 / Loss 81.0090 \n",
      "Loop 1986000 / Episode 126540 / Epsilon 0.4833 / Avg. Reward  0.600 / Avg. Length 22.611 / Loss 79.7044 \n",
      "Loop 1988000 / Episode 126638 / Epsilon 0.4828 / Avg. Reward  0.337 / Avg. Length 20.429 / Loss 80.2551 \n",
      "Saving model weights\n",
      "Loop 1990000 / Episode 126731 / Epsilon 0.4823 / Avg. Reward  0.473 / Avg. Length 21.409 / Loss 80.8881 \n",
      "Loop 1992000 / Episode 126820 / Epsilon 0.4819 / Avg. Reward  0.551 / Avg. Length 22.292 / Loss 81.0746 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1994000 / Episode 126909 / Epsilon 0.4814 / Avg. Reward  0.629 / Avg. Length 22.730 / Loss 79.4097 \n",
      "Loop 1996000 / Episode 127001 / Epsilon 0.4809 / Avg. Reward  0.467 / Avg. Length 21.533 / Loss 78.7594 \n",
      "Loop 1998000 / Episode 127089 / Epsilon 0.4805 / Avg. Reward  0.591 / Avg. Length 22.489 / Loss 77.5930 \n",
      "Saving model weights\n",
      "Loop 2000000 / Episode 127184 / Epsilon 0.4800 / Avg. Reward  0.453 / Avg. Length 21.526 / Loss 77.4685 \n",
      "Loop 2002000 / Episode 127278 / Epsilon 0.4795 / Avg. Reward  0.394 / Avg. Length 20.819 / Loss 82.8447 \n",
      "Loop 2004000 / Episode 127365 / Epsilon 0.4791 / Avg. Reward  0.690 / Avg. Length 23.460 / Loss 81.5909 \n",
      "Loop 2006000 / Episode 127461 / Epsilon 0.4786 / Avg. Reward  0.385 / Avg. Length 20.813 / Loss 81.7056 \n",
      "Loop 2008000 / Episode 127554 / Epsilon 0.4781 / Avg. Reward  0.430 / Avg. Length 21.269 / Loss 79.7224 \n",
      "Saving model weights\n",
      "Loop 2010000 / Episode 127647 / Epsilon 0.4776 / Avg. Reward  0.473 / Avg. Length 21.624 / Loss 79.4183 \n",
      "Loop 2012000 / Episode 127728 / Epsilon 0.4772 / Avg. Reward  0.840 / Avg. Length 24.852 / Loss 82.0186 \n",
      "Loop 2014000 / Episode 127820 / Epsilon 0.4767 / Avg. Reward  0.478 / Avg. Length 21.663 / Loss 78.2479 \n",
      "Loop 2016000 / Episode 127913 / Epsilon 0.4762 / Avg. Reward  0.441 / Avg. Length 21.376 / Loss 77.8723 \n",
      "Loop 2018000 / Episode 128013 / Epsilon 0.4758 / Avg. Reward  0.320 / Avg. Length 20.170 / Loss 79.7049 \n",
      "Saving model weights\n",
      "Loop 2020000 / Episode 128100 / Epsilon 0.4753 / Avg. Reward  0.609 / Avg. Length 22.805 / Loss 78.8654 \n",
      "Loop 2022000 / Episode 128186 / Epsilon 0.4748 / Avg. Reward  0.686 / Avg. Length 23.221 / Loss 84.3167 \n",
      "Loop 2024000 / Episode 128268 / Epsilon 0.4744 / Avg. Reward  0.829 / Avg. Length 24.659 / Loss 81.0242 \n",
      "Loop 2026000 / Episode 128354 / Epsilon 0.4739 / Avg. Reward  0.686 / Avg. Length 23.244 / Loss 80.5452 \n",
      "Loop 2028000 / Episode 128445 / Epsilon 0.4734 / Avg. Reward  0.495 / Avg. Length 21.692 / Loss 81.0589 \n",
      "Saving model weights\n",
      "Loop 2030000 / Episode 128531 / Epsilon 0.4729 / Avg. Reward  0.686 / Avg. Length 23.512 / Loss 81.2810 \n",
      "Loop 2032000 / Episode 128621 / Epsilon 0.4725 / Avg. Reward  0.578 / Avg. Length 22.289 / Loss 82.4826 \n",
      "Loop 2034000 / Episode 128710 / Epsilon 0.4720 / Avg. Reward  0.539 / Avg. Length 22.292 / Loss 80.4247 \n",
      "Loop 2036000 / Episode 128804 / Epsilon 0.4715 / Avg. Reward  0.468 / Avg. Length 21.436 / Loss 78.1603 \n",
      "Loop 2038000 / Episode 128895 / Epsilon 0.4711 / Avg. Reward  0.495 / Avg. Length 21.549 / Loss 78.9847 \n",
      "Saving model weights\n",
      "Loop 2040000 / Episode 128979 / Epsilon 0.4706 / Avg. Reward  0.798 / Avg. Length 24.190 / Loss 77.8589 \n",
      "Loop 2042000 / Episode 129069 / Epsilon 0.4701 / Avg. Reward  0.489 / Avg. Length 21.622 / Loss 83.4768 \n",
      "Loop 2044000 / Episode 129151 / Epsilon 0.4697 / Avg. Reward  0.927 / Avg. Length 25.000 / Loss 81.3222 \n",
      "Loop 2046000 / Episode 129226 / Epsilon 0.4692 / Avg. Reward  1.067 / Avg. Length 26.773 / Loss 81.0176 \n",
      "Loop 2048000 / Episode 129307 / Epsilon 0.4687 / Avg. Reward  0.840 / Avg. Length 24.654 / Loss 80.5874 \n",
      "Saving model weights\n",
      "Loop 2050000 / Episode 129404 / Epsilon 0.4682 / Avg. Reward  0.381 / Avg. Length 20.660 / Loss 79.7378 \n",
      "Loop 2052000 / Episode 129491 / Epsilon 0.4678 / Avg. Reward  0.621 / Avg. Length 22.816 / Loss 83.5013 \n",
      "Loop 2054000 / Episode 129582 / Epsilon 0.4673 / Avg. Reward  0.516 / Avg. Length 21.879 / Loss 83.7384 \n",
      "Loop 2056000 / Episode 129675 / Epsilon 0.4668 / Avg. Reward  0.484 / Avg. Length 21.677 / Loss 81.4913 \n",
      "Loop 2058000 / Episode 129761 / Epsilon 0.4664 / Avg. Reward  0.686 / Avg. Length 23.384 / Loss 81.9885 \n",
      "Saving model weights\n",
      "Loop 2060000 / Episode 129854 / Epsilon 0.4659 / Avg. Reward  0.452 / Avg. Length 21.366 / Loss 81.2733 \n",
      "Loop 2062000 / Episode 129941 / Epsilon 0.4654 / Avg. Reward  0.667 / Avg. Length 23.126 / Loss 83.7487 \n",
      "Loop 2064000 / Episode 130017 / Epsilon 0.4650 / Avg. Reward  1.039 / Avg. Length 26.263 / Loss 81.2150 \n",
      "Loop 2066000 / Episode 130116 / Epsilon 0.4645 / Avg. Reward  0.303 / Avg. Length 20.030 / Loss 80.2720 \n",
      "Loop 2068000 / Episode 130206 / Epsilon 0.4640 / Avg. Reward  0.500 / Avg. Length 21.689 / Loss 80.2061 \n",
      "Saving model weights\n",
      "Loop 2070000 / Episode 130293 / Epsilon 0.4635 / Avg. Reward  0.736 / Avg. Length 23.736 / Loss 79.1024 \n",
      "Loop 2072000 / Episode 130372 / Epsilon 0.4631 / Avg. Reward  0.886 / Avg. Length 24.987 / Loss 85.1615 \n",
      "Loop 2074000 / Episode 130474 / Epsilon 0.4626 / Avg. Reward  0.265 / Avg. Length 19.784 / Loss 84.9147 \n",
      "Loop 2076000 / Episode 130555 / Epsilon 0.4621 / Avg. Reward  0.852 / Avg. Length 24.778 / Loss 81.8527 \n",
      "Loop 2078000 / Episode 130637 / Epsilon 0.4617 / Avg. Reward  0.817 / Avg. Length 24.268 / Loss 82.5472 \n",
      "Saving model weights\n",
      "Loop 2080000 / Episode 130727 / Epsilon 0.4612 / Avg. Reward  0.556 / Avg. Length 22.356 / Loss 81.4346 \n",
      "Loop 2082000 / Episode 130808 / Epsilon 0.4607 / Avg. Reward  0.840 / Avg. Length 24.617 / Loss 85.6964 \n",
      "Loop 2084000 / Episode 130899 / Epsilon 0.4603 / Avg. Reward  0.505 / Avg. Length 21.945 / Loss 84.0083 \n",
      "Loop 2086000 / Episode 130997 / Epsilon 0.4598 / Avg. Reward  0.367 / Avg. Length 20.480 / Loss 83.9643 \n",
      "Loop 2088000 / Episode 131090 / Epsilon 0.4593 / Avg. Reward  0.430 / Avg. Length 21.097 / Loss 84.0593 \n",
      "Saving model weights\n",
      "Loop 2090000 / Episode 131172 / Epsilon 0.4588 / Avg. Reward  0.841 / Avg. Length 24.756 / Loss 82.8282 \n",
      "Loop 2092000 / Episode 131258 / Epsilon 0.4584 / Avg. Reward  0.674 / Avg. Length 23.314 / Loss 86.0551 \n",
      "Loop 2094000 / Episode 131345 / Epsilon 0.4579 / Avg. Reward  0.632 / Avg. Length 22.839 / Loss 84.4685 \n",
      "Loop 2096000 / Episode 131428 / Epsilon 0.4574 / Avg. Reward  0.795 / Avg. Length 24.084 / Loss 85.7630 \n",
      "Loop 2098000 / Episode 131515 / Epsilon 0.4570 / Avg. Reward  0.678 / Avg. Length 23.264 / Loss 83.0076 \n",
      "Saving model weights\n",
      "Loop 2100000 / Episode 131602 / Epsilon 0.4565 / Avg. Reward  0.609 / Avg. Length 22.448 / Loss 83.1198 \n",
      "Loop 2102000 / Episode 131696 / Epsilon 0.4560 / Avg. Reward  0.500 / Avg. Length 21.713 / Loss 91.2658 \n",
      "Loop 2104000 / Episode 131783 / Epsilon 0.4556 / Avg. Reward  0.563 / Avg. Length 22.333 / Loss 88.5398 \n",
      "Loop 2106000 / Episode 131866 / Epsilon 0.4551 / Avg. Reward  0.831 / Avg. Length 24.422 / Loss 86.8216 \n",
      "Loop 2108000 / Episode 131958 / Epsilon 0.4546 / Avg. Reward  0.554 / Avg. Length 22.054 / Loss 86.9693 \n",
      "Saving model weights\n",
      "Loop 2110000 / Episode 132034 / Epsilon 0.4541 / Avg. Reward  0.961 / Avg. Length 25.724 / Loss 85.8266 \n",
      "Loop 2112000 / Episode 132127 / Epsilon 0.4537 / Avg. Reward  0.527 / Avg. Length 21.903 / Loss 87.4400 \n",
      "Loop 2114000 / Episode 132216 / Epsilon 0.4532 / Avg. Reward  0.584 / Avg. Length 22.483 / Loss 86.5940 \n",
      "Loop 2116000 / Episode 132305 / Epsilon 0.4527 / Avg. Reward  0.607 / Avg. Length 22.573 / Loss 86.6414 \n",
      "Loop 2118000 / Episode 132394 / Epsilon 0.4523 / Avg. Reward  0.596 / Avg. Length 22.472 / Loss 85.4422 \n",
      "Saving model weights\n",
      "Loop 2120000 / Episode 132477 / Epsilon 0.4518 / Avg. Reward  0.771 / Avg. Length 24.024 / Loss 85.1369 \n",
      "Loop 2122000 / Episode 132560 / Epsilon 0.4513 / Avg. Reward  0.783 / Avg. Length 24.145 / Loss 87.4155 \n",
      "Loop 2124000 / Episode 132638 / Epsilon 0.4509 / Avg. Reward  0.949 / Avg. Length 25.538 / Loss 85.8757 \n",
      "Loop 2126000 / Episode 132725 / Epsilon 0.4504 / Avg. Reward  0.667 / Avg. Length 22.977 / Loss 85.5129 \n",
      "Loop 2128000 / Episode 132807 / Epsilon 0.4499 / Avg. Reward  0.817 / Avg. Length 24.561 / Loss 85.6418 \n",
      "Saving model weights\n",
      "Loop 2130000 / Episode 132882 / Epsilon 0.4494 / Avg. Reward  1.027 / Avg. Length 26.400 / Loss 84.0340 \n",
      "Loop 2132000 / Episode 132974 / Epsilon 0.4490 / Avg. Reward  0.489 / Avg. Length 21.685 / Loss 91.3800 \n",
      "Loop 2134000 / Episode 133064 / Epsilon 0.4485 / Avg. Reward  0.600 / Avg. Length 22.522 / Loss 89.6725 \n",
      "Loop 2136000 / Episode 133144 / Epsilon 0.4480 / Avg. Reward  0.875 / Avg. Length 24.900 / Loss 88.1750 \n",
      "Loop 2138000 / Episode 133232 / Epsilon 0.4476 / Avg. Reward  0.568 / Avg. Length 22.398 / Loss 89.1028 \n",
      "Saving model weights\n",
      "Loop 2140000 / Episode 133333 / Epsilon 0.4471 / Avg. Reward  0.307 / Avg. Length 20.089 / Loss 88.1422 \n",
      "Loop 2142000 / Episode 133422 / Epsilon 0.4466 / Avg. Reward  0.562 / Avg. Length 22.157 / Loss 91.7419 \n",
      "Loop 2144000 / Episode 133507 / Epsilon 0.4462 / Avg. Reward  0.718 / Avg. Length 23.459 / Loss 89.5408 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2146000 / Episode 133592 / Epsilon 0.4457 / Avg. Reward  0.753 / Avg. Length 23.882 / Loss 90.2018 \n",
      "Loop 2148000 / Episode 133673 / Epsilon 0.4452 / Avg. Reward  0.778 / Avg. Length 24.222 / Loss 89.5145 \n",
      "Saving model weights\n",
      "Loop 2150000 / Episode 133752 / Epsilon 0.4447 / Avg. Reward  0.975 / Avg. Length 25.759 / Loss 88.2284 \n",
      "Loop 2152000 / Episode 133826 / Epsilon 0.4443 / Avg. Reward  1.135 / Avg. Length 27.135 / Loss 92.3212 \n",
      "Loop 2154000 / Episode 133912 / Epsilon 0.4438 / Avg. Reward  0.674 / Avg. Length 23.209 / Loss 91.5895 \n",
      "Loop 2156000 / Episode 134005 / Epsilon 0.4433 / Avg. Reward  0.430 / Avg. Length 21.118 / Loss 90.2992 \n",
      "Loop 2158000 / Episode 134079 / Epsilon 0.4429 / Avg. Reward  1.189 / Avg. Length 27.649 / Loss 91.0801 \n",
      "Saving model weights\n",
      "Loop 2160000 / Episode 134158 / Epsilon 0.4424 / Avg. Reward  0.823 / Avg. Length 24.823 / Loss 89.3661 \n",
      "Loop 2162000 / Episode 134238 / Epsilon 0.4419 / Avg. Reward  0.900 / Avg. Length 25.488 / Loss 91.1022 \n",
      "Loop 2164000 / Episode 134314 / Epsilon 0.4415 / Avg. Reward  0.947 / Avg. Length 25.855 / Loss 89.9560 \n",
      "Loop 2166000 / Episode 134398 / Epsilon 0.4410 / Avg. Reward  0.762 / Avg. Length 24.131 / Loss 89.6660 \n",
      "Loop 2168000 / Episode 134494 / Epsilon 0.4405 / Avg. Reward  0.417 / Avg. Length 20.865 / Loss 89.9915 \n",
      "Saving model weights\n",
      "Loop 2170000 / Episode 134577 / Epsilon 0.4400 / Avg. Reward  0.759 / Avg. Length 23.940 / Loss 87.7172 \n",
      "Loop 2172000 / Episode 134656 / Epsilon 0.4396 / Avg. Reward  0.835 / Avg. Length 24.709 / Loss 93.0010 \n",
      "Loop 2174000 / Episode 134741 / Epsilon 0.4391 / Avg. Reward  0.812 / Avg. Length 24.094 / Loss 91.6925 \n",
      "Loop 2176000 / Episode 134838 / Epsilon 0.4386 / Avg. Reward  0.392 / Avg. Length 20.794 / Loss 90.4217 \n",
      "Loop 2178000 / Episode 134918 / Epsilon 0.4382 / Avg. Reward  0.863 / Avg. Length 24.825 / Loss 89.4442 \n",
      "Saving model weights\n",
      "Loop 2180000 / Episode 134980 / Epsilon 0.4377 / Avg. Reward  1.726 / Avg. Length 32.516 / Loss 89.8246 \n",
      "Loop 2182000 / Episode 135061 / Epsilon 0.4372 / Avg. Reward  0.840 / Avg. Length 24.593 / Loss 93.7789 \n",
      "Loop 2184000 / Episode 135159 / Epsilon 0.4368 / Avg. Reward  0.357 / Avg. Length 20.490 / Loss 92.9788 \n",
      "Loop 2186000 / Episode 135242 / Epsilon 0.4363 / Avg. Reward  0.747 / Avg. Length 23.976 / Loss 90.3770 \n",
      "Loop 2188000 / Episode 135324 / Epsilon 0.4358 / Avg. Reward  0.829 / Avg. Length 24.439 / Loss 89.6381 \n",
      "Saving model weights\n",
      "Loop 2190000 / Episode 135407 / Epsilon 0.4353 / Avg. Reward  0.759 / Avg. Length 24.000 / Loss 89.9960 \n",
      "Loop 2192000 / Episode 135482 / Epsilon 0.4349 / Avg. Reward  1.080 / Avg. Length 26.427 / Loss 94.9981 \n",
      "Loop 2194000 / Episode 135566 / Epsilon 0.4344 / Avg. Reward  0.750 / Avg. Length 23.976 / Loss 94.5838 \n",
      "Loop 2196000 / Episode 135657 / Epsilon 0.4339 / Avg. Reward  0.538 / Avg. Length 22.011 / Loss 91.5219 \n",
      "Loop 2198000 / Episode 135730 / Epsilon 0.4335 / Avg. Reward  1.137 / Avg. Length 27.164 / Loss 92.4523 \n",
      "Saving model weights\n",
      "Loop 2200000 / Episode 135809 / Epsilon 0.4330 / Avg. Reward  0.949 / Avg. Length 25.380 / Loss 91.3424 \n",
      "Loop 2202000 / Episode 135889 / Epsilon 0.4325 / Avg. Reward  0.900 / Avg. Length 25.150 / Loss 92.6882 \n",
      "Loop 2204000 / Episode 135963 / Epsilon 0.4321 / Avg. Reward  1.149 / Avg. Length 27.000 / Loss 91.2535 \n",
      "Loop 2206000 / Episode 136053 / Epsilon 0.4316 / Avg. Reward  0.533 / Avg. Length 22.011 / Loss 91.8725 \n",
      "Loop 2208000 / Episode 136127 / Epsilon 0.4311 / Avg. Reward  1.149 / Avg. Length 27.081 / Loss 91.7867 \n",
      "Saving model weights\n",
      "Loop 2210000 / Episode 136206 / Epsilon 0.4306 / Avg. Reward  0.962 / Avg. Length 25.696 / Loss 90.1313 \n",
      "Loop 2212000 / Episode 136282 / Epsilon 0.4302 / Avg. Reward  1.000 / Avg. Length 25.803 / Loss 95.6471 \n",
      "Loop 2214000 / Episode 136371 / Epsilon 0.4297 / Avg. Reward  0.640 / Avg. Length 22.933 / Loss 93.7504 \n",
      "Loop 2216000 / Episode 136459 / Epsilon 0.4292 / Avg. Reward  0.602 / Avg. Length 22.511 / Loss 92.9976 \n",
      "Loop 2218000 / Episode 136538 / Epsilon 0.4288 / Avg. Reward  0.899 / Avg. Length 25.456 / Loss 93.0664 \n",
      "Saving model weights\n",
      "Loop 2220000 / Episode 136624 / Epsilon 0.4283 / Avg. Reward  0.686 / Avg. Length 23.337 / Loss 93.8360 \n",
      "Loop 2222000 / Episode 136690 / Epsilon 0.4278 / Avg. Reward  1.515 / Avg. Length 30.258 / Loss 95.7914 \n",
      "Loop 2224000 / Episode 136760 / Epsilon 0.4274 / Avg. Reward  1.257 / Avg. Length 28.257 / Loss 92.6764 \n",
      "Loop 2226000 / Episode 136856 / Epsilon 0.4269 / Avg. Reward  0.417 / Avg. Length 21.042 / Loss 92.7545 \n",
      "Loop 2228000 / Episode 136954 / Epsilon 0.4264 / Avg. Reward  0.357 / Avg. Length 20.398 / Loss 92.7727 \n",
      "Saving model weights\n",
      "Loop 2230000 / Episode 137028 / Epsilon 0.4259 / Avg. Reward  1.149 / Avg. Length 27.054 / Loss 91.5407 \n",
      "Loop 2232000 / Episode 137095 / Epsilon 0.4255 / Avg. Reward  1.433 / Avg. Length 29.731 / Loss 95.1290 \n",
      "Loop 2234000 / Episode 137176 / Epsilon 0.4250 / Avg. Reward  0.802 / Avg. Length 24.321 / Loss 94.1868 \n",
      "Loop 2236000 / Episode 137261 / Epsilon 0.4245 / Avg. Reward  0.741 / Avg. Length 23.812 / Loss 92.1571 \n",
      "Loop 2238000 / Episode 137346 / Epsilon 0.4241 / Avg. Reward  0.741 / Avg. Length 23.682 / Loss 92.2723 \n",
      "Saving model weights\n",
      "Loop 2240000 / Episode 137422 / Epsilon 0.4236 / Avg. Reward  1.026 / Avg. Length 26.303 / Loss 92.3773 \n",
      "Loop 2242000 / Episode 137500 / Epsilon 0.4231 / Avg. Reward  0.949 / Avg. Length 25.641 / Loss 96.6245 \n",
      "Loop 2244000 / Episode 137578 / Epsilon 0.4227 / Avg. Reward  0.923 / Avg. Length 25.462 / Loss 95.1279 \n",
      "Loop 2246000 / Episode 137663 / Epsilon 0.4222 / Avg. Reward  0.741 / Avg. Length 23.753 / Loss 94.1412 \n",
      "Loop 2248000 / Episode 137740 / Epsilon 0.4217 / Avg. Reward  0.974 / Avg. Length 26.000 / Loss 93.7259 \n",
      "Saving model weights\n",
      "Loop 2250000 / Episode 137798 / Epsilon 0.4212 / Avg. Reward  1.828 / Avg. Length 33.241 / Loss 93.7635 \n",
      "Loop 2252000 / Episode 137870 / Epsilon 0.4208 / Avg. Reward  1.250 / Avg. Length 28.181 / Loss 92.8574 \n",
      "Loop 2254000 / Episode 137953 / Epsilon 0.4203 / Avg. Reward  0.819 / Avg. Length 24.265 / Loss 91.7564 \n",
      "Loop 2256000 / Episode 138040 / Epsilon 0.4198 / Avg. Reward  0.667 / Avg. Length 23.264 / Loss 90.7724 \n",
      "Loop 2258000 / Episode 138120 / Epsilon 0.4194 / Avg. Reward  0.875 / Avg. Length 24.875 / Loss 88.2783 \n",
      "Saving model weights\n",
      "Loop 2260000 / Episode 138205 / Epsilon 0.4189 / Avg. Reward  0.706 / Avg. Length 23.659 / Loss 90.3971 \n",
      "Loop 2262000 / Episode 138270 / Epsilon 0.4184 / Avg. Reward  1.492 / Avg. Length 30.338 / Loss 94.2221 \n",
      "Loop 2264000 / Episode 138338 / Epsilon 0.4180 / Avg. Reward  1.426 / Avg. Length 29.559 / Loss 93.7383 \n",
      "Loop 2266000 / Episode 138416 / Epsilon 0.4175 / Avg. Reward  0.949 / Avg. Length 25.718 / Loss 89.9922 \n",
      "Loop 2268000 / Episode 138502 / Epsilon 0.4170 / Avg. Reward  0.605 / Avg. Length 22.884 / Loss 90.2750 \n",
      "Saving model weights\n",
      "Loop 2270000 / Episode 138582 / Epsilon 0.4165 / Avg. Reward  0.950 / Avg. Length 25.388 / Loss 90.1668 \n",
      "Loop 2272000 / Episode 138649 / Epsilon 0.4161 / Avg. Reward  1.478 / Avg. Length 29.970 / Loss 94.3569 \n",
      "Loop 2274000 / Episode 138732 / Epsilon 0.4156 / Avg. Reward  0.783 / Avg. Length 24.157 / Loss 92.2238 \n",
      "Loop 2276000 / Episode 138817 / Epsilon 0.4151 / Avg. Reward  0.682 / Avg. Length 23.388 / Loss 92.9063 \n",
      "Loop 2278000 / Episode 138893 / Epsilon 0.4147 / Avg. Reward  1.026 / Avg. Length 26.461 / Loss 91.2755 \n",
      "Saving model weights\n",
      "Loop 2280000 / Episode 138985 / Epsilon 0.4142 / Avg. Reward  0.489 / Avg. Length 21.543 / Loss 91.0346 \n",
      "Loop 2282000 / Episode 139070 / Epsilon 0.4137 / Avg. Reward  0.741 / Avg. Length 23.659 / Loss 96.5190 \n",
      "Loop 2284000 / Episode 139153 / Epsilon 0.4133 / Avg. Reward  0.759 / Avg. Length 24.229 / Loss 94.3312 \n",
      "Loop 2286000 / Episode 139225 / Epsilon 0.4128 / Avg. Reward  1.181 / Avg. Length 27.403 / Loss 94.3857 \n",
      "Loop 2288000 / Episode 139294 / Epsilon 0.4123 / Avg. Reward  1.348 / Avg. Length 29.087 / Loss 94.4179 \n",
      "Saving model weights\n",
      "Loop 2290000 / Episode 139368 / Epsilon 0.4118 / Avg. Reward  1.122 / Avg. Length 27.216 / Loss 93.3440 \n",
      "Loop 2292000 / Episode 139446 / Epsilon 0.4114 / Avg. Reward  0.962 / Avg. Length 25.551 / Loss 96.6088 \n",
      "Loop 2294000 / Episode 139522 / Epsilon 0.4109 / Avg. Reward  1.013 / Avg. Length 26.039 / Loss 95.8076 \n",
      "Loop 2296000 / Episode 139594 / Epsilon 0.4104 / Avg. Reward  1.250 / Avg. Length 28.194 / Loss 95.5840 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2298000 / Episode 139678 / Epsilon 0.4100 / Avg. Reward  0.714 / Avg. Length 23.857 / Loss 95.0526 \n",
      "Saving model weights\n",
      "Loop 2300000 / Episode 139754 / Epsilon 0.4095 / Avg. Reward  1.013 / Avg. Length 26.079 / Loss 94.9400 \n",
      "Loop 2302000 / Episode 139836 / Epsilon 0.4090 / Avg. Reward  0.805 / Avg. Length 24.488 / Loss 98.3880 \n",
      "Loop 2304000 / Episode 139911 / Epsilon 0.4086 / Avg. Reward  1.027 / Avg. Length 26.453 / Loss 97.8183 \n",
      "Loop 2306000 / Episode 139982 / Epsilon 0.4081 / Avg. Reward  1.225 / Avg. Length 27.958 / Loss 97.1698 \n",
      "Loop 2308000 / Episode 140068 / Epsilon 0.4076 / Avg. Reward  0.709 / Avg. Length 23.605 / Loss 96.1473 \n",
      "Saving model weights\n",
      "Loop 2310000 / Episode 140145 / Epsilon 0.4071 / Avg. Reward  1.026 / Avg. Length 25.987 / Loss 96.7855 \n",
      "Loop 2312000 / Episode 140213 / Epsilon 0.4067 / Avg. Reward  1.382 / Avg. Length 29.382 / Loss 102.3831 \n",
      "Loop 2314000 / Episode 140305 / Epsilon 0.4062 / Avg. Reward  0.500 / Avg. Length 21.804 / Loss 101.4622 \n",
      "Loop 2316000 / Episode 140373 / Epsilon 0.4057 / Avg. Reward  1.397 / Avg. Length 29.294 / Loss 100.1167 \n",
      "Loop 2318000 / Episode 140454 / Epsilon 0.4053 / Avg. Reward  0.840 / Avg. Length 24.765 / Loss 98.9177 \n",
      "Saving model weights\n",
      "Loop 2320000 / Episode 140533 / Epsilon 0.4048 / Avg. Reward  0.899 / Avg. Length 25.278 / Loss 98.1965 \n",
      "Loop 2322000 / Episode 140620 / Epsilon 0.4043 / Avg. Reward  0.655 / Avg. Length 23.126 / Loss 105.2104 \n",
      "Loop 2324000 / Episode 140691 / Epsilon 0.4039 / Avg. Reward  1.225 / Avg. Length 28.014 / Loss 102.2472 \n",
      "Loop 2326000 / Episode 140769 / Epsilon 0.4034 / Avg. Reward  0.962 / Avg. Length 25.782 / Loss 102.6831 \n",
      "Loop 2328000 / Episode 140851 / Epsilon 0.4029 / Avg. Reward  0.817 / Avg. Length 24.329 / Loss 100.3057 \n",
      "Saving model weights\n",
      "Loop 2330000 / Episode 140931 / Epsilon 0.4024 / Avg. Reward  0.875 / Avg. Length 24.850 / Loss 102.3080 \n",
      "Loop 2332000 / Episode 141011 / Epsilon 0.4020 / Avg. Reward  0.925 / Avg. Length 25.175 / Loss 101.1215 \n",
      "Loop 2334000 / Episode 141093 / Epsilon 0.4015 / Avg. Reward  0.768 / Avg. Length 24.220 / Loss 101.5880 \n",
      "Loop 2336000 / Episode 141169 / Epsilon 0.4010 / Avg. Reward  1.039 / Avg. Length 26.118 / Loss 100.6796 \n",
      "Loop 2338000 / Episode 141243 / Epsilon 0.4006 / Avg. Reward  1.122 / Avg. Length 27.081 / Loss 100.0394 \n",
      "Saving model weights\n",
      "Loop 2340000 / Episode 141317 / Epsilon 0.4001 / Avg. Reward  1.149 / Avg. Length 27.392 / Loss 99.5558 \n",
      "Loop 2342000 / Episode 141395 / Epsilon 0.3996 / Avg. Reward  0.962 / Avg. Length 25.628 / Loss 102.5498 \n",
      "Loop 2344000 / Episode 141473 / Epsilon 0.3992 / Avg. Reward  0.923 / Avg. Length 25.436 / Loss 100.7484 \n",
      "Loop 2346000 / Episode 141548 / Epsilon 0.3987 / Avg. Reward  1.053 / Avg. Length 26.587 / Loss 100.3276 \n",
      "Loop 2348000 / Episode 141615 / Epsilon 0.3982 / Avg. Reward  1.388 / Avg. Length 29.269 / Loss 98.3416 \n",
      "Saving model weights\n",
      "Loop 2350000 / Episode 141680 / Epsilon 0.3977 / Avg. Reward  1.646 / Avg. Length 31.692 / Loss 98.5255 \n",
      "Loop 2352000 / Episode 141754 / Epsilon 0.3973 / Avg. Reward  1.081 / Avg. Length 26.811 / Loss 101.9329 \n",
      "Loop 2354000 / Episode 141828 / Epsilon 0.3968 / Avg. Reward  1.068 / Avg. Length 26.581 / Loss 99.4728 \n",
      "Loop 2356000 / Episode 141909 / Epsilon 0.3963 / Avg. Reward  0.889 / Avg. Length 25.086 / Loss 98.1623 \n",
      "Loop 2358000 / Episode 141978 / Epsilon 0.3959 / Avg. Reward  1.377 / Avg. Length 29.232 / Loss 97.5955 \n",
      "Saving model weights\n",
      "Loop 2360000 / Episode 142051 / Epsilon 0.3954 / Avg. Reward  1.123 / Avg. Length 26.904 / Loss 97.4579 \n",
      "Loop 2362000 / Episode 142122 / Epsilon 0.3949 / Avg. Reward  1.310 / Avg. Length 28.620 / Loss 101.4715 \n",
      "Loop 2364000 / Episode 142210 / Epsilon 0.3945 / Avg. Reward  0.591 / Avg. Length 22.727 / Loss 100.4319 \n",
      "Loop 2366000 / Episode 142286 / Epsilon 0.3940 / Avg. Reward  1.000 / Avg. Length 26.105 / Loss 97.2339 \n",
      "Loop 2368000 / Episode 142363 / Epsilon 0.3935 / Avg. Reward  0.974 / Avg. Length 25.675 / Loss 99.5511 \n",
      "Saving model weights\n",
      "Loop 2370000 / Episode 142433 / Epsilon 0.3930 / Avg. Reward  1.329 / Avg. Length 28.929 / Loss 97.7657 \n",
      "Loop 2372000 / Episode 142497 / Epsilon 0.3926 / Avg. Reward  1.578 / Avg. Length 31.188 / Loss 100.7718 \n",
      "Loop 2374000 / Episode 142566 / Epsilon 0.3921 / Avg. Reward  1.348 / Avg. Length 28.928 / Loss 101.1218 \n",
      "Loop 2376000 / Episode 142641 / Epsilon 0.3916 / Avg. Reward  1.133 / Avg. Length 26.880 / Loss 99.5601 \n",
      "Loop 2378000 / Episode 142713 / Epsilon 0.3912 / Avg. Reward  1.153 / Avg. Length 27.556 / Loss 98.8405 \n",
      "Saving model weights\n",
      "Loop 2380000 / Episode 142779 / Epsilon 0.3907 / Avg. Reward  1.545 / Avg. Length 30.621 / Loss 98.8827 \n",
      "Loop 2382000 / Episode 142850 / Epsilon 0.3902 / Avg. Reward  1.254 / Avg. Length 28.211 / Loss 99.4919 \n",
      "Loop 2384000 / Episode 142923 / Epsilon 0.3898 / Avg. Reward  1.096 / Avg. Length 26.973 / Loss 96.9412 \n",
      "Loop 2386000 / Episode 142996 / Epsilon 0.3893 / Avg. Reward  1.164 / Avg. Length 27.644 / Loss 96.2959 \n",
      "Loop 2388000 / Episode 143079 / Epsilon 0.3888 / Avg. Reward  0.783 / Avg. Length 24.120 / Loss 96.1154 \n",
      "Saving model weights\n",
      "Loop 2390000 / Episode 143152 / Epsilon 0.3883 / Avg. Reward  1.110 / Avg. Length 26.918 / Loss 97.4925 \n",
      "Loop 2392000 / Episode 143225 / Epsilon 0.3879 / Avg. Reward  1.205 / Avg. Length 27.740 / Loss 100.1856 \n",
      "Loop 2394000 / Episode 143300 / Epsilon 0.3874 / Avg. Reward  1.040 / Avg. Length 26.533 / Loss 98.7052 \n",
      "Loop 2396000 / Episode 143371 / Epsilon 0.3869 / Avg. Reward  1.169 / Avg. Length 27.479 / Loss 97.7263 \n",
      "Loop 2398000 / Episode 143453 / Epsilon 0.3865 / Avg. Reward  0.915 / Avg. Length 25.354 / Loss 96.9179 \n",
      "Saving model weights\n",
      "Loop 2400000 / Episode 143531 / Epsilon 0.3860 / Avg. Reward  0.872 / Avg. Length 24.756 / Loss 98.0771 \n",
      "Loop 2402000 / Episode 143604 / Epsilon 0.3855 / Avg. Reward  1.288 / Avg. Length 28.370 / Loss 107.1580 \n",
      "Loop 2404000 / Episode 143683 / Epsilon 0.3851 / Avg. Reward  0.848 / Avg. Length 24.468 / Loss 103.3424 \n",
      "Loop 2406000 / Episode 143757 / Epsilon 0.3846 / Avg. Reward  1.203 / Avg. Length 27.730 / Loss 105.0664 \n",
      "Loop 2408000 / Episode 143828 / Epsilon 0.3841 / Avg. Reward  1.268 / Avg. Length 28.423 / Loss 103.1592 \n",
      "Saving model weights\n",
      "Loop 2410000 / Episode 143899 / Epsilon 0.3836 / Avg. Reward  1.211 / Avg. Length 27.845 / Loss 102.0499 \n",
      "Loop 2412000 / Episode 143980 / Epsilon 0.3832 / Avg. Reward  0.877 / Avg. Length 24.951 / Loss 106.4398 \n",
      "Loop 2414000 / Episode 144039 / Epsilon 0.3827 / Avg. Reward  1.898 / Avg. Length 33.780 / Loss 102.8901 \n",
      "Loop 2416000 / Episode 144117 / Epsilon 0.3822 / Avg. Reward  0.923 / Avg. Length 25.436 / Loss 103.5943 \n",
      "Loop 2418000 / Episode 144187 / Epsilon 0.3818 / Avg. Reward  1.314 / Avg. Length 28.829 / Loss 102.0606 \n",
      "Saving model weights\n",
      "Loop 2420000 / Episode 144266 / Epsilon 0.3813 / Avg. Reward  0.823 / Avg. Length 24.392 / Loss 103.2067 \n",
      "Loop 2422000 / Episode 144333 / Epsilon 0.3808 / Avg. Reward  1.552 / Avg. Length 30.701 / Loss 102.4719 \n",
      "Loop 2424000 / Episode 144408 / Epsilon 0.3804 / Avg. Reward  1.040 / Avg. Length 26.320 / Loss 99.9680 \n",
      "Loop 2426000 / Episode 144482 / Epsilon 0.3799 / Avg. Reward  1.176 / Avg. Length 27.486 / Loss 99.0019 \n",
      "Loop 2428000 / Episode 144563 / Epsilon 0.3794 / Avg. Reward  0.802 / Avg. Length 24.407 / Loss 99.8836 \n",
      "Saving model weights\n",
      "Loop 2430000 / Episode 144633 / Epsilon 0.3789 / Avg. Reward  1.329 / Avg. Length 28.929 / Loss 98.6020 \n",
      "Loop 2432000 / Episode 144708 / Epsilon 0.3785 / Avg. Reward  1.053 / Avg. Length 26.413 / Loss 107.3574 \n",
      "Loop 2434000 / Episode 144776 / Epsilon 0.3780 / Avg. Reward  1.397 / Avg. Length 29.279 / Loss 104.1881 \n",
      "Loop 2436000 / Episode 144839 / Epsilon 0.3775 / Avg. Reward  1.667 / Avg. Length 31.571 / Loss 103.6589 \n",
      "Loop 2438000 / Episode 144899 / Epsilon 0.3771 / Avg. Reward  1.817 / Avg. Length 33.033 / Loss 104.5478 \n",
      "Saving model weights\n",
      "Loop 2440000 / Episode 144967 / Epsilon 0.3766 / Avg. Reward  1.485 / Avg. Length 30.147 / Loss 102.9005 \n",
      "Loop 2442000 / Episode 145028 / Epsilon 0.3761 / Avg. Reward  1.803 / Avg. Length 32.984 / Loss 106.7449 \n",
      "Loop 2444000 / Episode 145110 / Epsilon 0.3757 / Avg. Reward  0.817 / Avg. Length 24.402 / Loss 104.4252 \n",
      "Loop 2446000 / Episode 145179 / Epsilon 0.3752 / Avg. Reward  1.348 / Avg. Length 28.986 / Loss 102.3905 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2448000 / Episode 145250 / Epsilon 0.3747 / Avg. Reward  1.239 / Avg. Length 28.070 / Loss 102.8372 \n",
      "Saving model weights\n",
      "Loop 2450000 / Episode 145318 / Epsilon 0.3742 / Avg. Reward  1.338 / Avg. Length 28.912 / Loss 102.0886 \n",
      "Loop 2452000 / Episode 145385 / Epsilon 0.3738 / Avg. Reward  1.507 / Avg. Length 29.955 / Loss 106.1524 \n",
      "Loop 2454000 / Episode 145450 / Epsilon 0.3733 / Avg. Reward  1.615 / Avg. Length 31.123 / Loss 103.2921 \n",
      "Loop 2456000 / Episode 145523 / Epsilon 0.3728 / Avg. Reward  1.123 / Avg. Length 27.096 / Loss 101.6868 \n",
      "Loop 2458000 / Episode 145599 / Epsilon 0.3724 / Avg. Reward  1.079 / Avg. Length 26.592 / Loss 102.6459 \n",
      "Saving model weights\n",
      "Loop 2460000 / Episode 145670 / Epsilon 0.3719 / Avg. Reward  1.282 / Avg. Length 28.366 / Loss 101.5363 \n",
      "Loop 2462000 / Episode 145738 / Epsilon 0.3714 / Avg. Reward  1.382 / Avg. Length 29.382 / Loss 107.1750 \n",
      "Loop 2464000 / Episode 145793 / Epsilon 0.3710 / Avg. Reward  1.982 / Avg. Length 34.236 / Loss 103.0949 \n",
      "Loop 2466000 / Episode 145861 / Epsilon 0.3705 / Avg. Reward  1.529 / Avg. Length 30.059 / Loss 104.8018 \n",
      "Loop 2468000 / Episode 145930 / Epsilon 0.3700 / Avg. Reward  1.493 / Avg. Length 30.159 / Loss 102.3665 \n",
      "Saving model weights\n",
      "Loop 2470000 / Episode 145992 / Epsilon 0.3695 / Avg. Reward  1.645 / Avg. Length 31.694 / Loss 102.0838 \n",
      "Loop 2472000 / Episode 146058 / Epsilon 0.3691 / Avg. Reward  1.561 / Avg. Length 30.576 / Loss 105.8499 \n",
      "Loop 2474000 / Episode 146124 / Epsilon 0.3686 / Avg. Reward  1.470 / Avg. Length 29.985 / Loss 104.8596 \n",
      "Loop 2476000 / Episode 146198 / Epsilon 0.3681 / Avg. Reward  1.135 / Avg. Length 27.230 / Loss 101.5161 \n",
      "Loop 2478000 / Episode 146258 / Epsilon 0.3677 / Avg. Reward  1.833 / Avg. Length 33.050 / Loss 102.4907 \n",
      "Saving model weights\n",
      "Loop 2480000 / Episode 146332 / Epsilon 0.3672 / Avg. Reward  1.149 / Avg. Length 27.189 / Loss 103.2654 \n",
      "Loop 2482000 / Episode 146402 / Epsilon 0.3667 / Avg. Reward  1.329 / Avg. Length 28.600 / Loss 113.0202 \n",
      "Loop 2484000 / Episode 146471 / Epsilon 0.3663 / Avg. Reward  1.333 / Avg. Length 28.913 / Loss 111.9358 \n",
      "Loop 2486000 / Episode 146543 / Epsilon 0.3658 / Avg. Reward  1.139 / Avg. Length 27.306 / Loss 113.0834 \n",
      "Loop 2488000 / Episode 146606 / Epsilon 0.3653 / Avg. Reward  1.794 / Avg. Length 32.667 / Loss 109.9595 \n",
      "Saving model weights\n",
      "Loop 2490000 / Episode 146662 / Epsilon 0.3648 / Avg. Reward  2.089 / Avg. Length 35.286 / Loss 109.5856 \n",
      "Loop 2492000 / Episode 146732 / Epsilon 0.3644 / Avg. Reward  1.300 / Avg. Length 28.729 / Loss 112.0897 \n",
      "Loop 2494000 / Episode 146800 / Epsilon 0.3639 / Avg. Reward  1.456 / Avg. Length 29.471 / Loss 109.0006 \n",
      "Loop 2496000 / Episode 146878 / Epsilon 0.3634 / Avg. Reward  0.987 / Avg. Length 25.615 / Loss 110.3663 \n",
      "Loop 2498000 / Episode 146937 / Epsilon 0.3630 / Avg. Reward  1.831 / Avg. Length 32.898 / Loss 108.6729 \n",
      "Saving model weights\n",
      "Loop 2500000 / Episode 147002 / Epsilon 0.3625 / Avg. Reward  1.692 / Avg. Length 31.708 / Loss 108.6313 \n",
      "Loop 2502000 / Episode 147073 / Epsilon 0.3620 / Avg. Reward  1.225 / Avg. Length 28.000 / Loss 111.6923 \n",
      "Loop 2504000 / Episode 147143 / Epsilon 0.3616 / Avg. Reward  1.343 / Avg. Length 28.800 / Loss 111.1230 \n",
      "Loop 2506000 / Episode 147214 / Epsilon 0.3611 / Avg. Reward  1.225 / Avg. Length 27.817 / Loss 109.1060 \n",
      "Loop 2508000 / Episode 147281 / Epsilon 0.3606 / Avg. Reward  1.478 / Avg. Length 30.299 / Loss 111.8877 \n",
      "Saving model weights\n",
      "Loop 2510000 / Episode 147351 / Epsilon 0.3601 / Avg. Reward  1.200 / Avg. Length 27.929 / Loss 108.6516 \n",
      "Loop 2512000 / Episode 147420 / Epsilon 0.3597 / Avg. Reward  1.406 / Avg. Length 29.594 / Loss 113.4472 \n",
      "Loop 2514000 / Episode 147484 / Epsilon 0.3592 / Avg. Reward  1.578 / Avg. Length 31.297 / Loss 113.0907 \n",
      "Loop 2516000 / Episode 147562 / Epsilon 0.3587 / Avg. Reward  0.923 / Avg. Length 25.256 / Loss 110.0354 \n",
      "Loop 2518000 / Episode 147637 / Epsilon 0.3583 / Avg. Reward  1.107 / Avg. Length 26.813 / Loss 111.6528 \n",
      "Saving model weights\n",
      "Loop 2520000 / Episode 147700 / Epsilon 0.3578 / Avg. Reward  1.730 / Avg. Length 32.127 / Loss 110.9829 \n",
      "Loop 2522000 / Episode 147750 / Epsilon 0.3573 / Avg. Reward  2.520 / Avg. Length 39.080 / Loss 115.1459 \n",
      "Loop 2524000 / Episode 147822 / Epsilon 0.3569 / Avg. Reward  1.306 / Avg. Length 28.444 / Loss 112.4015 \n",
      "Loop 2526000 / Episode 147889 / Epsilon 0.3564 / Avg. Reward  1.373 / Avg. Length 29.343 / Loss 112.8408 \n",
      "Loop 2528000 / Episode 147951 / Epsilon 0.3559 / Avg. Reward  1.710 / Avg. Length 32.032 / Loss 111.4593 \n",
      "Saving model weights\n",
      "Loop 2530000 / Episode 148023 / Epsilon 0.3554 / Avg. Reward  1.264 / Avg. Length 28.403 / Loss 111.0592 \n",
      "Loop 2532000 / Episode 148089 / Epsilon 0.3550 / Avg. Reward  1.515 / Avg. Length 30.273 / Loss 114.0274 \n",
      "Loop 2534000 / Episode 148157 / Epsilon 0.3545 / Avg. Reward  1.368 / Avg. Length 29.368 / Loss 112.1764 \n",
      "Loop 2536000 / Episode 148219 / Epsilon 0.3540 / Avg. Reward  1.694 / Avg. Length 32.113 / Loss 109.6788 \n",
      "Loop 2538000 / Episode 148275 / Epsilon 0.3536 / Avg. Reward  2.107 / Avg. Length 35.232 / Loss 109.5355 \n",
      "Saving model weights\n",
      "Loop 2540000 / Episode 148341 / Epsilon 0.3531 / Avg. Reward  1.500 / Avg. Length 30.455 / Loss 109.1645 \n",
      "Loop 2542000 / Episode 148405 / Epsilon 0.3526 / Avg. Reward  1.562 / Avg. Length 30.734 / Loss 111.9072 \n",
      "Loop 2544000 / Episode 148485 / Epsilon 0.3522 / Avg. Reward  0.937 / Avg. Length 25.712 / Loss 108.5755 \n",
      "Loop 2546000 / Episode 148573 / Epsilon 0.3517 / Avg. Reward  0.602 / Avg. Length 22.761 / Loss 107.8910 \n",
      "Loop 2548000 / Episode 148646 / Epsilon 0.3512 / Avg. Reward  1.164 / Avg. Length 27.411 / Loss 106.6739 \n",
      "Saving model weights\n",
      "Loop 2550000 / Episode 148710 / Epsilon 0.3507 / Avg. Reward  1.625 / Avg. Length 31.328 / Loss 107.0781 \n",
      "Loop 2552000 / Episode 148777 / Epsilon 0.3503 / Avg. Reward  1.388 / Avg. Length 29.388 / Loss 112.0351 \n",
      "Loop 2554000 / Episode 148852 / Epsilon 0.3498 / Avg. Reward  1.147 / Avg. Length 27.027 / Loss 111.9832 \n",
      "Loop 2556000 / Episode 148925 / Epsilon 0.3493 / Avg. Reward  1.096 / Avg. Length 26.685 / Loss 111.1096 \n",
      "Loop 2558000 / Episode 148987 / Epsilon 0.3489 / Avg. Reward  1.742 / Avg. Length 32.661 / Loss 109.6421 \n",
      "Saving model weights\n",
      "Loop 2560000 / Episode 149045 / Epsilon 0.3484 / Avg. Reward  1.931 / Avg. Length 33.828 / Loss 111.2003 \n",
      "Loop 2562000 / Episode 149115 / Epsilon 0.3479 / Avg. Reward  1.371 / Avg. Length 29.343 / Loss 115.5431 \n",
      "Loop 2564000 / Episode 149181 / Epsilon 0.3475 / Avg. Reward  1.500 / Avg. Length 30.530 / Loss 115.8825 \n",
      "Loop 2566000 / Episode 149244 / Epsilon 0.3470 / Avg. Reward  1.651 / Avg. Length 31.444 / Loss 112.1985 \n",
      "Loop 2568000 / Episode 149305 / Epsilon 0.3465 / Avg. Reward  1.770 / Avg. Length 32.525 / Loss 114.0409 \n",
      "Saving model weights\n",
      "Loop 2570000 / Episode 149379 / Epsilon 0.3460 / Avg. Reward  1.122 / Avg. Length 27.014 / Loss 113.5168 \n",
      "Loop 2572000 / Episode 149437 / Epsilon 0.3456 / Avg. Reward  1.948 / Avg. Length 34.431 / Loss 119.1972 \n",
      "Loop 2574000 / Episode 149495 / Epsilon 0.3451 / Avg. Reward  2.017 / Avg. Length 34.586 / Loss 117.6838 \n",
      "Loop 2576000 / Episode 149548 / Epsilon 0.3446 / Avg. Reward  2.245 / Avg. Length 36.755 / Loss 114.1403 \n",
      "Loop 2578000 / Episode 149617 / Epsilon 0.3442 / Avg. Reward  1.493 / Avg. Length 30.203 / Loss 115.1121 \n",
      "Saving model weights\n",
      "Loop 2580000 / Episode 149685 / Epsilon 0.3437 / Avg. Reward  1.265 / Avg. Length 28.456 / Loss 114.1073 \n",
      "Loop 2582000 / Episode 149768 / Epsilon 0.3432 / Avg. Reward  0.795 / Avg. Length 24.301 / Loss 118.3817 \n",
      "Loop 2584000 / Episode 149842 / Epsilon 0.3428 / Avg. Reward  1.149 / Avg. Length 27.486 / Loss 117.8356 \n",
      "Loop 2586000 / Episode 149909 / Epsilon 0.3423 / Avg. Reward  1.463 / Avg. Length 30.060 / Loss 117.4659 \n",
      "Loop 2588000 / Episode 149975 / Epsilon 0.3418 / Avg. Reward  1.485 / Avg. Length 30.227 / Loss 115.7446 \n",
      "Saving model weights\n",
      "Loop 2590000 / Episode 150041 / Epsilon 0.3413 / Avg. Reward  1.470 / Avg. Length 30.212 / Loss 116.8174 \n",
      "Loop 2592000 / Episode 150105 / Epsilon 0.3409 / Avg. Reward  1.656 / Avg. Length 31.406 / Loss 116.3601 \n",
      "Loop 2594000 / Episode 150175 / Epsilon 0.3404 / Avg. Reward  1.286 / Avg. Length 28.414 / Loss 113.0077 \n",
      "Loop 2596000 / Episode 150233 / Epsilon 0.3399 / Avg. Reward  1.914 / Avg. Length 34.052 / Loss 113.3190 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2598000 / Episode 150323 / Epsilon 0.3395 / Avg. Reward  0.589 / Avg. Length 22.622 / Loss 114.2256 \n",
      "Saving model weights\n",
      "Loop 2600000 / Episode 150377 / Epsilon 0.3390 / Avg. Reward  2.185 / Avg. Length 36.000 / Loss 112.5202 \n",
      "Loop 2602000 / Episode 150442 / Epsilon 0.3385 / Avg. Reward  1.646 / Avg. Length 31.354 / Loss 111.9143 \n",
      "Loop 2604000 / Episode 150513 / Epsilon 0.3381 / Avg. Reward  1.169 / Avg. Length 27.465 / Loss 111.2936 \n",
      "Loop 2606000 / Episode 150581 / Epsilon 0.3376 / Avg. Reward  1.529 / Avg. Length 30.412 / Loss 109.8955 \n",
      "Loop 2608000 / Episode 150639 / Epsilon 0.3371 / Avg. Reward  1.879 / Avg. Length 33.621 / Loss 107.6491 \n",
      "Saving model weights\n",
      "Loop 2610000 / Episode 150704 / Epsilon 0.3366 / Avg. Reward  1.600 / Avg. Length 30.908 / Loss 108.7956 \n",
      "Loop 2612000 / Episode 150765 / Epsilon 0.3362 / Avg. Reward  1.803 / Avg. Length 32.967 / Loss 112.2253 \n",
      "Loop 2614000 / Episode 150833 / Epsilon 0.3357 / Avg. Reward  1.426 / Avg. Length 29.456 / Loss 112.5847 \n",
      "Loop 2616000 / Episode 150890 / Epsilon 0.3352 / Avg. Reward  2.088 / Avg. Length 35.193 / Loss 110.0795 \n",
      "Loop 2618000 / Episode 150954 / Epsilon 0.3348 / Avg. Reward  1.656 / Avg. Length 31.578 / Loss 109.5640 \n",
      "Saving model weights\n",
      "Loop 2620000 / Episode 151019 / Epsilon 0.3343 / Avg. Reward  1.554 / Avg. Length 30.677 / Loss 108.6752 \n",
      "Loop 2622000 / Episode 151081 / Epsilon 0.3338 / Avg. Reward  1.742 / Avg. Length 32.129 / Loss 113.4543 \n",
      "Loop 2624000 / Episode 151147 / Epsilon 0.3334 / Avg. Reward  1.455 / Avg. Length 30.015 / Loss 112.6391 \n",
      "Loop 2626000 / Episode 151207 / Epsilon 0.3329 / Avg. Reward  1.950 / Avg. Length 33.783 / Loss 110.8745 \n",
      "Loop 2628000 / Episode 151278 / Epsilon 0.3324 / Avg. Reward  1.197 / Avg. Length 27.859 / Loss 110.5741 \n",
      "Saving model weights\n",
      "Loop 2630000 / Episode 151346 / Epsilon 0.3319 / Avg. Reward  1.456 / Avg. Length 29.750 / Loss 111.5575 \n",
      "Loop 2632000 / Episode 151405 / Epsilon 0.3315 / Avg. Reward  1.915 / Avg. Length 33.915 / Loss 116.5605 \n",
      "Loop 2634000 / Episode 151474 / Epsilon 0.3310 / Avg. Reward  1.348 / Avg. Length 28.899 / Loss 115.9444 \n",
      "Loop 2636000 / Episode 151530 / Epsilon 0.3305 / Avg. Reward  2.161 / Avg. Length 35.857 / Loss 116.8756 \n",
      "Loop 2638000 / Episode 151606 / Epsilon 0.3301 / Avg. Reward  1.013 / Avg. Length 26.316 / Loss 113.1726 \n",
      "Saving model weights\n",
      "Loop 2640000 / Episode 151674 / Epsilon 0.3296 / Avg. Reward  1.412 / Avg. Length 29.441 / Loss 112.8774 \n",
      "Loop 2642000 / Episode 151734 / Epsilon 0.3291 / Avg. Reward  1.733 / Avg. Length 32.300 / Loss 117.8964 \n",
      "Loop 2644000 / Episode 151794 / Epsilon 0.3287 / Avg. Reward  1.917 / Avg. Length 33.600 / Loss 116.2564 \n",
      "Loop 2646000 / Episode 151860 / Epsilon 0.3282 / Avg. Reward  1.545 / Avg. Length 30.848 / Loss 115.4913 \n",
      "Loop 2648000 / Episode 151924 / Epsilon 0.3277 / Avg. Reward  1.547 / Avg. Length 30.766 / Loss 113.1745 \n",
      "Saving model weights\n",
      "Loop 2650000 / Episode 152002 / Epsilon 0.3272 / Avg. Reward  1.013 / Avg. Length 26.103 / Loss 113.4476 \n",
      "Loop 2652000 / Episode 152071 / Epsilon 0.3268 / Avg. Reward  1.391 / Avg. Length 29.072 / Loss 122.8096 \n",
      "Loop 2654000 / Episode 152123 / Epsilon 0.3263 / Avg. Reward  2.442 / Avg. Length 38.212 / Loss 118.3897 \n",
      "Loop 2656000 / Episode 152193 / Epsilon 0.3258 / Avg. Reward  1.329 / Avg. Length 28.686 / Loss 118.0730 \n",
      "Loop 2658000 / Episode 152235 / Epsilon 0.3254 / Avg. Reward  3.381 / Avg. Length 46.167 / Loss 117.8648 \n",
      "Saving model weights\n",
      "Loop 2660000 / Episode 152293 / Epsilon 0.3249 / Avg. Reward  2.103 / Avg. Length 35.500 / Loss 118.1645 \n",
      "Loop 2662000 / Episode 152356 / Epsilon 0.3244 / Avg. Reward  1.651 / Avg. Length 31.508 / Loss 120.7512 \n",
      "Loop 2664000 / Episode 152418 / Epsilon 0.3240 / Avg. Reward  1.742 / Avg. Length 32.081 / Loss 120.2483 \n",
      "Loop 2666000 / Episode 152478 / Epsilon 0.3235 / Avg. Reward  1.900 / Avg. Length 33.850 / Loss 118.3055 \n",
      "Loop 2668000 / Episode 152538 / Epsilon 0.3230 / Avg. Reward  1.817 / Avg. Length 33.133 / Loss 117.1537 \n",
      "Saving model weights\n",
      "Loop 2670000 / Episode 152612 / Epsilon 0.3225 / Avg. Reward  1.149 / Avg. Length 27.149 / Loss 118.9408 \n",
      "Loop 2672000 / Episode 152674 / Epsilon 0.3221 / Avg. Reward  1.694 / Avg. Length 31.855 / Loss 122.7854 \n",
      "Loop 2674000 / Episode 152731 / Epsilon 0.3216 / Avg. Reward  2.070 / Avg. Length 35.035 / Loss 120.9761 \n",
      "Loop 2676000 / Episode 152800 / Epsilon 0.3211 / Avg. Reward  1.362 / Avg. Length 28.942 / Loss 121.5280 \n",
      "Loop 2678000 / Episode 152870 / Epsilon 0.3207 / Avg. Reward  1.271 / Avg. Length 28.557 / Loss 118.8319 \n",
      "Saving model weights\n",
      "Loop 2680000 / Episode 152940 / Epsilon 0.3202 / Avg. Reward  1.386 / Avg. Length 29.114 / Loss 119.6353 \n",
      "Loop 2682000 / Episode 152995 / Epsilon 0.3197 / Avg. Reward  2.236 / Avg. Length 36.218 / Loss 125.6463 \n",
      "Loop 2684000 / Episode 153059 / Epsilon 0.3193 / Avg. Reward  1.609 / Avg. Length 31.250 / Loss 124.7307 \n",
      "Loop 2686000 / Episode 153116 / Epsilon 0.3188 / Avg. Reward  1.982 / Avg. Length 34.298 / Loss 124.6223 \n",
      "Loop 2688000 / Episode 153167 / Epsilon 0.3183 / Avg. Reward  2.569 / Avg. Length 39.510 / Loss 122.3051 \n",
      "Saving model weights\n",
      "Loop 2690000 / Episode 153237 / Epsilon 0.3178 / Avg. Reward  1.357 / Avg. Length 28.929 / Loss 122.9143 \n",
      "Loop 2692000 / Episode 153314 / Epsilon 0.3174 / Avg. Reward  1.013 / Avg. Length 26.130 / Loss 128.5152 \n",
      "Loop 2694000 / Episode 153371 / Epsilon 0.3169 / Avg. Reward  2.053 / Avg. Length 34.860 / Loss 125.0213 \n",
      "Loop 2696000 / Episode 153429 / Epsilon 0.3164 / Avg. Reward  2.052 / Avg. Length 34.707 / Loss 125.2305 \n",
      "Loop 2698000 / Episode 153488 / Epsilon 0.3160 / Avg. Reward  1.864 / Avg. Length 33.271 / Loss 126.2496 \n",
      "Saving model weights\n",
      "Loop 2700000 / Episode 153543 / Epsilon 0.3155 / Avg. Reward  2.255 / Avg. Length 36.855 / Loss 123.9915 \n",
      "Loop 2702000 / Episode 153598 / Epsilon 0.3150 / Avg. Reward  2.145 / Avg. Length 35.364 / Loss 128.3697 \n",
      "Loop 2704000 / Episode 153649 / Epsilon 0.3146 / Avg. Reward  2.686 / Avg. Length 40.451 / Loss 126.3605 \n",
      "Loop 2706000 / Episode 153703 / Epsilon 0.3141 / Avg. Reward  2.278 / Avg. Length 36.796 / Loss 123.1958 \n",
      "Loop 2708000 / Episode 153772 / Epsilon 0.3136 / Avg. Reward  1.377 / Avg. Length 28.971 / Loss 126.4062 \n",
      "Saving model weights\n",
      "Loop 2710000 / Episode 153830 / Epsilon 0.3131 / Avg. Reward  1.983 / Avg. Length 34.724 / Loss 125.2201 \n",
      "Loop 2712000 / Episode 153882 / Epsilon 0.3127 / Avg. Reward  2.385 / Avg. Length 38.173 / Loss 128.0733 \n",
      "Loop 2714000 / Episode 153937 / Epsilon 0.3122 / Avg. Reward  2.273 / Avg. Length 36.436 / Loss 123.2004 \n",
      "Loop 2716000 / Episode 154001 / Epsilon 0.3117 / Avg. Reward  1.391 / Avg. Length 29.328 / Loss 124.4016 \n",
      "Loop 2718000 / Episode 154055 / Epsilon 0.3113 / Avg. Reward  2.537 / Avg. Length 39.278 / Loss 121.6894 \n",
      "Saving model weights\n",
      "Loop 2720000 / Episode 154114 / Epsilon 0.3108 / Avg. Reward  1.881 / Avg. Length 33.847 / Loss 121.7230 \n",
      "Loop 2722000 / Episode 154179 / Epsilon 0.3103 / Avg. Reward  1.538 / Avg. Length 30.708 / Loss 126.1611 \n",
      "Loop 2724000 / Episode 154247 / Epsilon 0.3099 / Avg. Reward  1.471 / Avg. Length 29.750 / Loss 122.7416 \n",
      "Loop 2726000 / Episode 154303 / Epsilon 0.3094 / Avg. Reward  2.125 / Avg. Length 35.554 / Loss 124.5022 \n",
      "Loop 2728000 / Episode 154350 / Epsilon 0.3089 / Avg. Reward  2.915 / Avg. Length 41.830 / Loss 122.7894 \n",
      "Saving model weights\n",
      "Loop 2730000 / Episode 154408 / Epsilon 0.3084 / Avg. Reward  2.034 / Avg. Length 34.741 / Loss 121.2162 \n",
      "Loop 2732000 / Episode 154469 / Epsilon 0.3080 / Avg. Reward  1.820 / Avg. Length 32.656 / Loss 124.4923 \n",
      "Loop 2734000 / Episode 154536 / Epsilon 0.3075 / Avg. Reward  1.507 / Avg. Length 30.149 / Loss 124.5680 \n",
      "Loop 2736000 / Episode 154594 / Epsilon 0.3070 / Avg. Reward  2.000 / Avg. Length 34.328 / Loss 123.6427 \n",
      "Loop 2738000 / Episode 154655 / Epsilon 0.3066 / Avg. Reward  1.787 / Avg. Length 32.705 / Loss 121.6288 \n",
      "Saving model weights\n",
      "Loop 2740000 / Episode 154722 / Epsilon 0.3061 / Avg. Reward  1.493 / Avg. Length 30.134 / Loss 123.2832 \n",
      "Loop 2742000 / Episode 154777 / Epsilon 0.3056 / Avg. Reward  2.236 / Avg. Length 36.491 / Loss 128.4186 \n",
      "Loop 2744000 / Episode 154833 / Epsilon 0.3052 / Avg. Reward  2.107 / Avg. Length 35.589 / Loss 127.5128 \n",
      "Loop 2746000 / Episode 154894 / Epsilon 0.3047 / Avg. Reward  1.787 / Avg. Length 32.869 / Loss 125.8294 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2748000 / Episode 154934 / Epsilon 0.3042 / Avg. Reward  3.800 / Avg. Length 49.600 / Loss 126.4180 \n",
      "Saving model weights\n",
      "Loop 2750000 / Episode 154996 / Epsilon 0.3037 / Avg. Reward  1.645 / Avg. Length 31.597 / Loss 121.8151 \n",
      "Loop 2752000 / Episode 155062 / Epsilon 0.3033 / Avg. Reward  1.591 / Avg. Length 31.212 / Loss 129.1319 \n",
      "Loop 2754000 / Episode 155118 / Epsilon 0.3028 / Avg. Reward  2.143 / Avg. Length 35.589 / Loss 127.6013 \n",
      "Loop 2756000 / Episode 155181 / Epsilon 0.3023 / Avg. Reward  1.667 / Avg. Length 31.444 / Loss 128.2187 \n",
      "Loop 2758000 / Episode 155240 / Epsilon 0.3019 / Avg. Reward  2.000 / Avg. Length 34.271 / Loss 125.3445 \n",
      "Saving model weights\n",
      "Loop 2760000 / Episode 155297 / Epsilon 0.3014 / Avg. Reward  2.018 / Avg. Length 34.930 / Loss 126.3669 \n",
      "Loop 2762000 / Episode 155357 / Epsilon 0.3009 / Avg. Reward  1.900 / Avg. Length 33.167 / Loss 125.6026 \n",
      "Loop 2764000 / Episode 155418 / Epsilon 0.3005 / Avg. Reward  1.803 / Avg. Length 33.131 / Loss 124.5914 \n",
      "Loop 2766000 / Episode 155467 / Epsilon 0.3000 / Avg. Reward  2.633 / Avg. Length 39.837 / Loss 124.3908 \n",
      "Loop 2768000 / Episode 155519 / Epsilon 0.2995 / Avg. Reward  2.385 / Avg. Length 37.481 / Loss 124.1869 \n",
      "Saving model weights\n",
      "Loop 2770000 / Episode 155568 / Epsilon 0.2990 / Avg. Reward  2.918 / Avg. Length 42.327 / Loss 124.4615 \n",
      "Loop 2772000 / Episode 155633 / Epsilon 0.2986 / Avg. Reward  1.615 / Avg. Length 31.231 / Loss 127.5430 \n",
      "Loop 2774000 / Episode 155695 / Epsilon 0.2981 / Avg. Reward  1.581 / Avg. Length 31.290 / Loss 128.3504 \n",
      "Loop 2776000 / Episode 155757 / Epsilon 0.2976 / Avg. Reward  1.839 / Avg. Length 33.177 / Loss 125.6484 \n",
      "Loop 2778000 / Episode 155814 / Epsilon 0.2972 / Avg. Reward  2.053 / Avg. Length 35.070 / Loss 127.1351 \n",
      "Saving model weights\n",
      "Loop 2780000 / Episode 155871 / Epsilon 0.2967 / Avg. Reward  1.930 / Avg. Length 33.842 / Loss 123.1893 \n",
      "Loop 2782000 / Episode 155926 / Epsilon 0.2962 / Avg. Reward  2.236 / Avg. Length 36.564 / Loss 128.4150 \n",
      "Loop 2784000 / Episode 155997 / Epsilon 0.2958 / Avg. Reward  1.296 / Avg. Length 28.775 / Loss 128.7859 \n",
      "Loop 2786000 / Episode 156067 / Epsilon 0.2953 / Avg. Reward  1.343 / Avg. Length 28.829 / Loss 126.1641 \n",
      "Loop 2788000 / Episode 156116 / Epsilon 0.2948 / Avg. Reward  2.633 / Avg. Length 39.816 / Loss 125.2474 \n",
      "Saving model weights\n",
      "Loop 2790000 / Episode 156175 / Epsilon 0.2943 / Avg. Reward  1.983 / Avg. Length 34.492 / Loss 123.1050 \n",
      "Loop 2792000 / Episode 156225 / Epsilon 0.2939 / Avg. Reward  2.600 / Avg. Length 39.640 / Loss 122.8405 \n",
      "Loop 2794000 / Episode 156286 / Epsilon 0.2934 / Avg. Reward  1.787 / Avg. Length 32.623 / Loss 120.8681 \n",
      "Loop 2796000 / Episode 156345 / Epsilon 0.2929 / Avg. Reward  2.034 / Avg. Length 34.678 / Loss 120.7837 \n",
      "Loop 2798000 / Episode 156404 / Epsilon 0.2925 / Avg. Reward  1.932 / Avg. Length 33.542 / Loss 122.0029 \n",
      "Saving model weights\n",
      "Loop 2800000 / Episode 156454 / Epsilon 0.2920 / Avg. Reward  2.680 / Avg. Length 40.260 / Loss 122.7400 \n",
      "Loop 2802000 / Episode 156499 / Epsilon 0.2915 / Avg. Reward  3.133 / Avg. Length 43.911 / Loss 122.3194 \n",
      "Loop 2804000 / Episode 156541 / Epsilon 0.2911 / Avg. Reward  3.333 / Avg. Length 46.000 / Loss 120.7444 \n",
      "Loop 2806000 / Episode 156584 / Epsilon 0.2906 / Avg. Reward  3.419 / Avg. Length 46.721 / Loss 117.5497 \n",
      "Loop 2808000 / Episode 156640 / Epsilon 0.2901 / Avg. Reward  2.250 / Avg. Length 36.286 / Loss 114.1933 \n",
      "Saving model weights\n",
      "Loop 2810000 / Episode 156698 / Epsilon 0.2896 / Avg. Reward  2.103 / Avg. Length 35.362 / Loss 115.5609 \n",
      "Loop 2812000 / Episode 156763 / Epsilon 0.2892 / Avg. Reward  1.569 / Avg. Length 30.815 / Loss 118.8872 \n",
      "Loop 2814000 / Episode 156812 / Epsilon 0.2887 / Avg. Reward  2.673 / Avg. Length 40.592 / Loss 118.4939 \n",
      "Loop 2816000 / Episode 156877 / Epsilon 0.2882 / Avg. Reward  1.569 / Avg. Length 31.000 / Loss 115.0505 \n",
      "Loop 2818000 / Episode 156931 / Epsilon 0.2878 / Avg. Reward  2.259 / Avg. Length 36.611 / Loss 115.3283 \n",
      "Saving model weights\n",
      "Loop 2820000 / Episode 156984 / Epsilon 0.2873 / Avg. Reward  2.283 / Avg. Length 36.811 / Loss 114.9026 \n",
      "Loop 2822000 / Episode 157035 / Epsilon 0.2868 / Avg. Reward  2.686 / Avg. Length 40.627 / Loss 123.5651 \n",
      "Loop 2824000 / Episode 157075 / Epsilon 0.2864 / Avg. Reward  3.775 / Avg. Length 49.775 / Loss 119.3230 \n",
      "Loop 2826000 / Episode 157130 / Epsilon 0.2859 / Avg. Reward  2.091 / Avg. Length 35.164 / Loss 120.5774 \n",
      "Loop 2828000 / Episode 157188 / Epsilon 0.2854 / Avg. Reward  2.034 / Avg. Length 34.810 / Loss 118.7317 \n",
      "Saving model weights\n",
      "Loop 2830000 / Episode 157244 / Epsilon 0.2849 / Avg. Reward  2.179 / Avg. Length 35.625 / Loss 119.8518 \n",
      "Loop 2832000 / Episode 157305 / Epsilon 0.2845 / Avg. Reward  1.754 / Avg. Length 32.295 / Loss 128.1516 \n",
      "Loop 2834000 / Episode 157372 / Epsilon 0.2840 / Avg. Reward  1.567 / Avg. Length 30.731 / Loss 126.1578 \n",
      "Loop 2836000 / Episode 157427 / Epsilon 0.2835 / Avg. Reward  2.236 / Avg. Length 36.673 / Loss 124.5156 \n",
      "Loop 2838000 / Episode 157484 / Epsilon 0.2831 / Avg. Reward  1.982 / Avg. Length 34.316 / Loss 125.3226 \n",
      "Saving model weights\n",
      "Loop 2840000 / Episode 157524 / Epsilon 0.2826 / Avg. Reward  4.000 / Avg. Length 51.150 / Loss 123.1780 \n",
      "Loop 2842000 / Episode 157581 / Epsilon 0.2821 / Avg. Reward  1.930 / Avg. Length 33.842 / Loss 128.2027 \n",
      "Loop 2844000 / Episode 157633 / Epsilon 0.2817 / Avg. Reward  2.654 / Avg. Length 39.808 / Loss 127.3441 \n",
      "Loop 2846000 / Episode 157691 / Epsilon 0.2812 / Avg. Reward  1.914 / Avg. Length 33.845 / Loss 126.0982 \n",
      "Loop 2848000 / Episode 157749 / Epsilon 0.2807 / Avg. Reward  1.897 / Avg. Length 33.672 / Loss 124.0729 \n",
      "Saving model weights\n",
      "Loop 2850000 / Episode 157796 / Epsilon 0.2802 / Avg. Reward  3.149 / Avg. Length 44.362 / Loss 124.3229 \n",
      "Loop 2852000 / Episode 157849 / Epsilon 0.2798 / Avg. Reward  2.377 / Avg. Length 37.774 / Loss 130.4562 \n",
      "Loop 2854000 / Episode 157893 / Epsilon 0.2793 / Avg. Reward  3.273 / Avg. Length 45.000 / Loss 129.6904 \n",
      "Loop 2856000 / Episode 157947 / Epsilon 0.2788 / Avg. Reward  2.296 / Avg. Length 37.037 / Loss 128.1842 \n",
      "Loop 2858000 / Episode 158003 / Epsilon 0.2784 / Avg. Reward  1.679 / Avg. Length 31.875 / Loss 126.9373 \n",
      "Saving model weights\n",
      "Loop 2860000 / Episode 158053 / Epsilon 0.2779 / Avg. Reward  3.160 / Avg. Length 44.240 / Loss 127.4126 \n",
      "Loop 2862000 / Episode 158102 / Epsilon 0.2774 / Avg. Reward  2.592 / Avg. Length 39.878 / Loss 135.3785 \n",
      "Loop 2864000 / Episode 158143 / Epsilon 0.2770 / Avg. Reward  3.927 / Avg. Length 50.585 / Loss 134.2571 \n",
      "Loop 2866000 / Episode 158203 / Epsilon 0.2765 / Avg. Reward  1.767 / Avg. Length 32.533 / Loss 131.5132 \n",
      "Loop 2868000 / Episode 158257 / Epsilon 0.2760 / Avg. Reward  2.407 / Avg. Length 37.759 / Loss 129.7218 \n",
      "Saving model weights\n",
      "Loop 2870000 / Episode 158329 / Epsilon 0.2755 / Avg. Reward  1.181 / Avg. Length 27.514 / Loss 128.8435 \n",
      "Loop 2872000 / Episode 158379 / Epsilon 0.2751 / Avg. Reward  2.600 / Avg. Length 39.360 / Loss 135.4579 \n",
      "Loop 2874000 / Episode 158439 / Epsilon 0.2746 / Avg. Reward  1.933 / Avg. Length 34.067 / Loss 131.1534 \n",
      "Loop 2876000 / Episode 158494 / Epsilon 0.2741 / Avg. Reward  2.182 / Avg. Length 36.255 / Loss 130.8857 \n",
      "Loop 2878000 / Episode 158544 / Epsilon 0.2737 / Avg. Reward  2.720 / Avg. Length 40.260 / Loss 131.6523 \n",
      "Saving model weights\n",
      "Loop 2880000 / Episode 158591 / Epsilon 0.2732 / Avg. Reward  2.809 / Avg. Length 41.511 / Loss 130.7392 \n",
      "Loop 2882000 / Episode 158644 / Epsilon 0.2727 / Avg. Reward  2.415 / Avg. Length 37.906 / Loss 132.7470 \n",
      "Loop 2884000 / Episode 158701 / Epsilon 0.2723 / Avg. Reward  2.193 / Avg. Length 35.982 / Loss 131.6853 \n",
      "Loop 2886000 / Episode 158745 / Epsilon 0.2718 / Avg. Reward  3.182 / Avg. Length 44.432 / Loss 130.6749 \n",
      "Loop 2888000 / Episode 158797 / Epsilon 0.2713 / Avg. Reward  2.500 / Avg. Length 38.865 / Loss 126.8617 \n",
      "Saving model weights\n",
      "Loop 2890000 / Episode 158847 / Epsilon 0.2708 / Avg. Reward  2.560 / Avg. Length 39.440 / Loss 129.6353 \n",
      "Loop 2892000 / Episode 158902 / Epsilon 0.2704 / Avg. Reward  2.327 / Avg. Length 37.364 / Loss 131.6425 \n",
      "Loop 2894000 / Episode 158959 / Epsilon 0.2699 / Avg. Reward  1.930 / Avg. Length 34.105 / Loss 130.7373 \n",
      "Loop 2896000 / Episode 159006 / Epsilon 0.2694 / Avg. Reward  3.085 / Avg. Length 43.468 / Loss 129.9887 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2898000 / Episode 159062 / Epsilon 0.2690 / Avg. Reward  2.179 / Avg. Length 35.679 / Loss 129.9994 \n",
      "Saving model weights\n",
      "Loop 2900000 / Episode 159107 / Epsilon 0.2685 / Avg. Reward  2.911 / Avg. Length 42.400 / Loss 129.8286 \n",
      "Loop 2902000 / Episode 159171 / Epsilon 0.2680 / Avg. Reward  1.766 / Avg. Length 32.531 / Loss 133.1023 \n",
      "Loop 2904000 / Episode 159217 / Epsilon 0.2676 / Avg. Reward  3.000 / Avg. Length 43.043 / Loss 131.5063 \n",
      "Loop 2906000 / Episode 159263 / Epsilon 0.2671 / Avg. Reward  3.196 / Avg. Length 44.217 / Loss 129.6503 \n",
      "Loop 2908000 / Episode 159309 / Epsilon 0.2666 / Avg. Reward  3.022 / Avg. Length 43.565 / Loss 131.5609 \n",
      "Saving model weights\n",
      "Loop 2910000 / Episode 159349 / Epsilon 0.2661 / Avg. Reward  3.800 / Avg. Length 49.775 / Loss 131.6977 \n",
      "Loop 2912000 / Episode 159403 / Epsilon 0.2657 / Avg. Reward  2.333 / Avg. Length 37.222 / Loss 135.1070 \n",
      "Loop 2914000 / Episode 159460 / Epsilon 0.2652 / Avg. Reward  1.930 / Avg. Length 33.684 / Loss 131.1566 \n",
      "Loop 2916000 / Episode 159511 / Epsilon 0.2647 / Avg. Reward  2.647 / Avg. Length 39.941 / Loss 131.5452 \n",
      "Loop 2918000 / Episode 159558 / Epsilon 0.2643 / Avg. Reward  2.957 / Avg. Length 42.383 / Loss 128.2157 \n",
      "Saving model weights\n",
      "Loop 2920000 / Episode 159602 / Epsilon 0.2638 / Avg. Reward  3.386 / Avg. Length 46.227 / Loss 131.6768 \n",
      "Loop 2922000 / Episode 159659 / Epsilon 0.2633 / Avg. Reward  2.105 / Avg. Length 35.228 / Loss 130.7160 \n",
      "Loop 2924000 / Episode 159700 / Epsilon 0.2629 / Avg. Reward  3.610 / Avg. Length 47.854 / Loss 128.9433 \n",
      "Loop 2926000 / Episode 159750 / Epsilon 0.2624 / Avg. Reward  2.600 / Avg. Length 39.640 / Loss 129.6652 \n",
      "Loop 2928000 / Episode 159807 / Epsilon 0.2619 / Avg. Reward  2.123 / Avg. Length 35.526 / Loss 124.0737 \n",
      "Saving model weights\n",
      "Loop 2930000 / Episode 159842 / Epsilon 0.2614 / Avg. Reward  4.057 / Avg. Length 52.314 / Loss 125.7241 \n",
      "Loop 2932000 / Episode 159898 / Epsilon 0.2610 / Avg. Reward  2.571 / Avg. Length 39.321 / Loss 129.6939 \n",
      "Loop 2934000 / Episode 159947 / Epsilon 0.2605 / Avg. Reward  2.776 / Avg. Length 41.041 / Loss 129.1424 \n",
      "Loop 2936000 / Episode 160012 / Epsilon 0.2600 / Avg. Reward  1.569 / Avg. Length 30.815 / Loss 127.7018 \n",
      "Loop 2938000 / Episode 160063 / Epsilon 0.2596 / Avg. Reward  2.529 / Avg. Length 38.451 / Loss 128.0799 \n",
      "Saving model weights\n",
      "Loop 2940000 / Episode 160124 / Epsilon 0.2591 / Avg. Reward  1.852 / Avg. Length 33.230 / Loss 127.3608 \n",
      "Loop 2942000 / Episode 160175 / Epsilon 0.2586 / Avg. Reward  2.549 / Avg. Length 39.471 / Loss 128.0074 \n",
      "Loop 2944000 / Episode 160230 / Epsilon 0.2582 / Avg. Reward  2.145 / Avg. Length 36.109 / Loss 127.9876 \n",
      "Loop 2946000 / Episode 160284 / Epsilon 0.2577 / Avg. Reward  2.259 / Avg. Length 36.759 / Loss 127.0006 \n",
      "Loop 2948000 / Episode 160338 / Epsilon 0.2572 / Avg. Reward  2.389 / Avg. Length 37.426 / Loss 127.7749 \n",
      "Saving model weights\n",
      "Loop 2950000 / Episode 160391 / Epsilon 0.2567 / Avg. Reward  2.264 / Avg. Length 36.717 / Loss 126.2150 \n",
      "Loop 2952000 / Episode 160438 / Epsilon 0.2563 / Avg. Reward  2.915 / Avg. Length 42.255 / Loss 129.2485 \n",
      "Loop 2954000 / Episode 160490 / Epsilon 0.2558 / Avg. Reward  2.500 / Avg. Length 38.654 / Loss 129.4102 \n",
      "Loop 2956000 / Episode 160554 / Epsilon 0.2553 / Avg. Reward  1.562 / Avg. Length 30.875 / Loss 125.8722 \n",
      "Loop 2958000 / Episode 160604 / Epsilon 0.2549 / Avg. Reward  2.860 / Avg. Length 41.760 / Loss 126.3854 \n",
      "Saving model weights\n",
      "Loop 2960000 / Episode 160659 / Epsilon 0.2544 / Avg. Reward  2.182 / Avg. Length 36.200 / Loss 127.9047 \n",
      "Loop 2962000 / Episode 160706 / Epsilon 0.2539 / Avg. Reward  3.000 / Avg. Length 42.745 / Loss 133.2547 \n",
      "Loop 2964000 / Episode 160755 / Epsilon 0.2535 / Avg. Reward  2.714 / Avg. Length 40.306 / Loss 132.2809 \n",
      "Loop 2966000 / Episode 160798 / Epsilon 0.2530 / Avg. Reward  3.512 / Avg. Length 46.884 / Loss 128.8533 \n",
      "Loop 2968000 / Episode 160833 / Epsilon 0.2525 / Avg. Reward  4.657 / Avg. Length 57.457 / Loss 130.1284 \n",
      "Saving model weights\n",
      "Loop 2970000 / Episode 160886 / Epsilon 0.2520 / Avg. Reward  2.358 / Avg. Length 37.547 / Loss 130.4762 \n",
      "Loop 2972000 / Episode 160934 / Epsilon 0.2516 / Avg. Reward  2.833 / Avg. Length 41.667 / Loss 134.0968 \n",
      "Loop 2974000 / Episode 160992 / Epsilon 0.2511 / Avg. Reward  1.897 / Avg. Length 33.552 / Loss 132.5908 \n",
      "Loop 2976000 / Episode 161043 / Epsilon 0.2506 / Avg. Reward  2.588 / Avg. Length 39.412 / Loss 130.1166 \n",
      "Loop 2978000 / Episode 161095 / Epsilon 0.2502 / Avg. Reward  2.596 / Avg. Length 39.231 / Loss 131.5570 \n",
      "Saving model weights\n",
      "Loop 2980000 / Episode 161145 / Epsilon 0.2497 / Avg. Reward  2.660 / Avg. Length 40.140 / Loss 131.1221 \n",
      "Loop 2982000 / Episode 161186 / Epsilon 0.2492 / Avg. Reward  3.463 / Avg. Length 47.073 / Loss 134.4451 \n",
      "Loop 2984000 / Episode 161221 / Epsilon 0.2488 / Avg. Reward  4.914 / Avg. Length 59.286 / Loss 133.8637 \n",
      "Loop 2986000 / Episode 161270 / Epsilon 0.2483 / Avg. Reward  2.633 / Avg. Length 40.000 / Loss 133.1532 \n",
      "Loop 2988000 / Episode 161320 / Epsilon 0.2478 / Avg. Reward  2.680 / Avg. Length 40.740 / Loss 130.2340 \n",
      "Saving model weights\n",
      "Loop 2990000 / Episode 161376 / Epsilon 0.2473 / Avg. Reward  2.214 / Avg. Length 35.804 / Loss 130.0357 \n",
      "Loop 2992000 / Episode 161417 / Epsilon 0.2469 / Avg. Reward  3.683 / Avg. Length 48.561 / Loss 140.0680 \n",
      "Loop 2994000 / Episode 161459 / Epsilon 0.2464 / Avg. Reward  3.500 / Avg. Length 47.286 / Loss 136.5050 \n",
      "Loop 2996000 / Episode 161511 / Epsilon 0.2459 / Avg. Reward  2.519 / Avg. Length 38.596 / Loss 134.7508 \n",
      "Loop 2998000 / Episode 161557 / Epsilon 0.2455 / Avg. Reward  3.065 / Avg. Length 43.717 / Loss 138.7865 \n",
      "Saving model weights\n",
      "Loop 3000000 / Episode 161616 / Epsilon 0.2450 / Avg. Reward  1.983 / Avg. Length 33.949 / Loss 135.7188 \n",
      "Loop 3002000 / Episode 161660 / Epsilon 0.2445 / Avg. Reward  3.114 / Avg. Length 43.841 / Loss 141.9488 \n",
      "Loop 3004000 / Episode 161693 / Epsilon 0.2441 / Avg. Reward  4.818 / Avg. Length 58.364 / Loss 141.3768 \n",
      "Loop 3006000 / Episode 161746 / Epsilon 0.2436 / Avg. Reward  2.679 / Avg. Length 40.038 / Loss 137.5033 \n",
      "Loop 3008000 / Episode 161800 / Epsilon 0.2431 / Avg. Reward  2.278 / Avg. Length 37.019 / Loss 142.0023 \n",
      "Saving model weights\n",
      "Loop 3010000 / Episode 161855 / Epsilon 0.2426 / Avg. Reward  2.255 / Avg. Length 36.727 / Loss 140.6105 \n",
      "Loop 3012000 / Episode 161910 / Epsilon 0.2422 / Avg. Reward  2.255 / Avg. Length 36.327 / Loss 148.0855 \n",
      "Loop 3014000 / Episode 161955 / Epsilon 0.2417 / Avg. Reward  3.200 / Avg. Length 44.378 / Loss 146.5316 \n",
      "Loop 3016000 / Episode 162009 / Epsilon 0.2412 / Avg. Reward  2.259 / Avg. Length 36.556 / Loss 146.6430 \n",
      "Loop 3018000 / Episode 162052 / Epsilon 0.2408 / Avg. Reward  3.558 / Avg. Length 47.279 / Loss 143.5217 \n",
      "Saving model weights\n",
      "Loop 3020000 / Episode 162112 / Epsilon 0.2403 / Avg. Reward  1.783 / Avg. Length 32.850 / Loss 144.5057 \n",
      "Loop 3022000 / Episode 162158 / Epsilon 0.2398 / Avg. Reward  2.826 / Avg. Length 41.109 / Loss 141.7721 \n",
      "Loop 3024000 / Episode 162207 / Epsilon 0.2394 / Avg. Reward  3.061 / Avg. Length 43.367 / Loss 139.1693 \n",
      "Loop 3026000 / Episode 162249 / Epsilon 0.2389 / Avg. Reward  3.476 / Avg. Length 47.119 / Loss 140.4572 \n",
      "Loop 3028000 / Episode 162304 / Epsilon 0.2384 / Avg. Reward  2.236 / Avg. Length 36.691 / Loss 137.9276 \n",
      "Saving model weights\n",
      "Loop 3030000 / Episode 162348 / Epsilon 0.2379 / Avg. Reward  3.295 / Avg. Length 45.682 / Loss 139.2877 \n",
      "Loop 3032000 / Episode 162389 / Epsilon 0.2375 / Avg. Reward  3.732 / Avg. Length 48.854 / Loss 138.9387 \n",
      "Loop 3034000 / Episode 162440 / Epsilon 0.2370 / Avg. Reward  2.569 / Avg. Length 39.196 / Loss 137.7005 \n",
      "Loop 3036000 / Episode 162483 / Epsilon 0.2365 / Avg. Reward  3.349 / Avg. Length 46.535 / Loss 134.9701 \n",
      "Loop 3038000 / Episode 162523 / Epsilon 0.2361 / Avg. Reward  3.250 / Avg. Length 44.925 / Loss 138.2340 \n",
      "Saving model weights\n",
      "Loop 3040000 / Episode 162569 / Epsilon 0.2356 / Avg. Reward  3.500 / Avg. Length 46.978 / Loss 134.7191 \n",
      "Loop 3042000 / Episode 162623 / Epsilon 0.2351 / Avg. Reward  2.426 / Avg. Length 37.722 / Loss 142.4119 \n",
      "Loop 3044000 / Episode 162668 / Epsilon 0.2347 / Avg. Reward  3.222 / Avg. Length 44.711 / Loss 139.4756 \n",
      "Loop 3046000 / Episode 162709 / Epsilon 0.2342 / Avg. Reward  3.561 / Avg. Length 47.634 / Loss 140.2940 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3048000 / Episode 162756 / Epsilon 0.2337 / Avg. Reward  3.064 / Avg. Length 43.149 / Loss 140.5120 \n",
      "Saving model weights\n",
      "Loop 3050000 / Episode 162802 / Epsilon 0.2332 / Avg. Reward  2.978 / Avg. Length 43.022 / Loss 137.6381 \n",
      "Loop 3052000 / Episode 162853 / Epsilon 0.2328 / Avg. Reward  2.569 / Avg. Length 39.118 / Loss 143.1264 \n",
      "Loop 3054000 / Episode 162888 / Epsilon 0.2323 / Avg. Reward  4.314 / Avg. Length 54.171 / Loss 138.2970 \n",
      "Loop 3056000 / Episode 162922 / Epsilon 0.2318 / Avg. Reward  4.647 / Avg. Length 56.735 / Loss 139.6455 \n",
      "Loop 3058000 / Episode 162967 / Epsilon 0.2314 / Avg. Reward  3.733 / Avg. Length 49.044 / Loss 139.2930 \n",
      "Saving model weights\n",
      "Loop 3060000 / Episode 163007 / Epsilon 0.2309 / Avg. Reward  3.825 / Avg. Length 50.000 / Loss 136.9502 \n",
      "Loop 3062000 / Episode 163046 / Epsilon 0.2304 / Avg. Reward  4.000 / Avg. Length 51.359 / Loss 142.6460 \n",
      "Loop 3064000 / Episode 163094 / Epsilon 0.2300 / Avg. Reward  2.750 / Avg. Length 40.812 / Loss 141.6770 \n",
      "Loop 3066000 / Episode 163125 / Epsilon 0.2295 / Avg. Reward  5.484 / Avg. Length 63.903 / Loss 138.6945 \n",
      "Loop 3068000 / Episode 163172 / Epsilon 0.2290 / Avg. Reward  3.064 / Avg. Length 43.447 / Loss 138.5758 \n",
      "Saving model weights\n",
      "Loop 3070000 / Episode 163212 / Epsilon 0.2285 / Avg. Reward  3.850 / Avg. Length 50.200 / Loss 138.2828 \n",
      "Loop 3072000 / Episode 163259 / Epsilon 0.2281 / Avg. Reward  2.957 / Avg. Length 42.766 / Loss 139.5788 \n",
      "Loop 3074000 / Episode 163307 / Epsilon 0.2276 / Avg. Reward  2.812 / Avg. Length 41.542 / Loss 138.7177 \n",
      "Loop 3076000 / Episode 163346 / Epsilon 0.2271 / Avg. Reward  3.923 / Avg. Length 50.769 / Loss 135.6059 \n",
      "Loop 3078000 / Episode 163401 / Epsilon 0.2267 / Avg. Reward  2.218 / Avg. Length 36.218 / Loss 135.9772 \n",
      "Saving model weights\n",
      "Loop 3080000 / Episode 163442 / Epsilon 0.2262 / Avg. Reward  3.634 / Avg. Length 48.098 / Loss 136.8068 \n",
      "Loop 3082000 / Episode 163487 / Epsilon 0.2257 / Avg. Reward  3.289 / Avg. Length 45.578 / Loss 143.5017 \n",
      "Loop 3084000 / Episode 163536 / Epsilon 0.2253 / Avg. Reward  2.714 / Avg. Length 40.980 / Loss 144.1826 \n",
      "Loop 3086000 / Episode 163577 / Epsilon 0.2248 / Avg. Reward  3.366 / Avg. Length 45.927 / Loss 146.8715 \n",
      "Loop 3088000 / Episode 163610 / Epsilon 0.2243 / Avg. Reward  5.273 / Avg. Length 62.061 / Loss 140.4416 \n",
      "Saving model weights\n",
      "Loop 3090000 / Episode 163653 / Epsilon 0.2238 / Avg. Reward  3.465 / Avg. Length 46.953 / Loss 143.3173 \n",
      "Loop 3092000 / Episode 163708 / Epsilon 0.2234 / Avg. Reward  2.291 / Avg. Length 37.000 / Loss 139.8021 \n",
      "Loop 3094000 / Episode 163741 / Epsilon 0.2229 / Avg. Reward  5.182 / Avg. Length 61.152 / Loss 139.2895 \n",
      "Loop 3096000 / Episode 163777 / Epsilon 0.2224 / Avg. Reward  4.417 / Avg. Length 54.806 / Loss 139.4448 \n",
      "Loop 3098000 / Episode 163818 / Epsilon 0.2220 / Avg. Reward  3.780 / Avg. Length 49.561 / Loss 135.8372 \n",
      "Saving model weights\n",
      "Loop 3100000 / Episode 163858 / Epsilon 0.2215 / Avg. Reward  3.825 / Avg. Length 50.125 / Loss 136.1358 \n",
      "Loop 3102000 / Episode 163916 / Epsilon 0.2210 / Avg. Reward  1.828 / Avg. Length 32.948 / Loss 153.4726 \n",
      "Loop 3104000 / Episode 163958 / Epsilon 0.2206 / Avg. Reward  3.476 / Avg. Length 46.690 / Loss 153.2472 \n",
      "Loop 3106000 / Episode 164000 / Epsilon 0.2201 / Avg. Reward  3.905 / Avg. Length 50.643 / Loss 150.0823 \n",
      "Loop 3108000 / Episode 164027 / Epsilon 0.2196 / Avg. Reward  6.296 / Avg. Length 71.259 / Loss 148.8410 \n",
      "Saving model weights\n",
      "Loop 3110000 / Episode 164077 / Epsilon 0.2191 / Avg. Reward  2.820 / Avg. Length 41.240 / Loss 148.8602 \n",
      "Loop 3112000 / Episode 164120 / Epsilon 0.2187 / Avg. Reward  3.442 / Avg. Length 46.860 / Loss 146.6980 \n",
      "Loop 3114000 / Episode 164169 / Epsilon 0.2182 / Avg. Reward  2.694 / Avg. Length 40.490 / Loss 147.7782 \n",
      "Loop 3116000 / Episode 164216 / Epsilon 0.2177 / Avg. Reward  2.957 / Avg. Length 42.830 / Loss 146.2556 \n",
      "Loop 3118000 / Episode 164269 / Epsilon 0.2173 / Avg. Reward  2.302 / Avg. Length 37.226 / Loss 146.4356 \n",
      "Saving model weights\n",
      "Loop 3120000 / Episode 164322 / Epsilon 0.2168 / Avg. Reward  2.434 / Avg. Length 38.170 / Loss 145.8438 \n",
      "Loop 3122000 / Episode 164363 / Epsilon 0.2163 / Avg. Reward  3.707 / Avg. Length 48.756 / Loss 149.2124 \n",
      "Loop 3124000 / Episode 164403 / Epsilon 0.2159 / Avg. Reward  3.850 / Avg. Length 49.725 / Loss 144.8384 \n",
      "Loop 3126000 / Episode 164450 / Epsilon 0.2154 / Avg. Reward  2.638 / Avg. Length 40.000 / Loss 144.7168 \n",
      "Loop 3128000 / Episode 164501 / Epsilon 0.2149 / Avg. Reward  2.804 / Avg. Length 41.216 / Loss 145.5760 \n",
      "Saving model weights\n",
      "Loop 3130000 / Episode 164544 / Epsilon 0.2144 / Avg. Reward  3.349 / Avg. Length 45.767 / Loss 142.0131 \n",
      "Loop 3132000 / Episode 164581 / Epsilon 0.2140 / Avg. Reward  4.595 / Avg. Length 55.649 / Loss 144.2301 \n",
      "Loop 3134000 / Episode 164627 / Epsilon 0.2135 / Avg. Reward  2.978 / Avg. Length 42.913 / Loss 144.8139 \n",
      "Loop 3136000 / Episode 164669 / Epsilon 0.2130 / Avg. Reward  3.667 / Avg. Length 48.429 / Loss 141.4650 \n",
      "Loop 3138000 / Episode 164717 / Epsilon 0.2126 / Avg. Reward  2.854 / Avg. Length 41.521 / Loss 139.9167 \n",
      "Saving model weights\n",
      "Loop 3140000 / Episode 164759 / Epsilon 0.2121 / Avg. Reward  3.571 / Avg. Length 47.595 / Loss 140.7866 \n",
      "Loop 3142000 / Episode 164804 / Epsilon 0.2116 / Avg. Reward  3.156 / Avg. Length 44.044 / Loss 148.6374 \n",
      "Loop 3144000 / Episode 164847 / Epsilon 0.2112 / Avg. Reward  3.233 / Avg. Length 44.907 / Loss 146.0753 \n",
      "Loop 3146000 / Episode 164884 / Epsilon 0.2107 / Avg. Reward  4.514 / Avg. Length 55.676 / Loss 145.7123 \n",
      "Loop 3148000 / Episode 164932 / Epsilon 0.2102 / Avg. Reward  2.604 / Avg. Length 39.750 / Loss 148.3284 \n",
      "Saving model weights\n",
      "Loop 3150000 / Episode 164970 / Epsilon 0.2097 / Avg. Reward  4.316 / Avg. Length 54.474 / Loss 146.8077 \n",
      "Loop 3152000 / Episode 165011 / Epsilon 0.2093 / Avg. Reward  3.805 / Avg. Length 49.854 / Loss 145.7159 \n",
      "Loop 3154000 / Episode 165048 / Epsilon 0.2088 / Avg. Reward  4.351 / Avg. Length 53.946 / Loss 142.3108 \n",
      "Loop 3156000 / Episode 165089 / Epsilon 0.2083 / Avg. Reward  3.585 / Avg. Length 48.049 / Loss 139.5470 \n",
      "Loop 3158000 / Episode 165123 / Epsilon 0.2079 / Avg. Reward  4.676 / Avg. Length 56.912 / Loss 140.7040 \n",
      "Saving model weights\n",
      "Loop 3160000 / Episode 165165 / Epsilon 0.2074 / Avg. Reward  3.762 / Avg. Length 49.690 / Loss 138.3963 \n",
      "Loop 3162000 / Episode 165208 / Epsilon 0.2069 / Avg. Reward  3.395 / Avg. Length 46.488 / Loss 148.1158 \n",
      "Loop 3164000 / Episode 165245 / Epsilon 0.2065 / Avg. Reward  4.405 / Avg. Length 54.730 / Loss 142.5583 \n",
      "Loop 3166000 / Episode 165273 / Epsilon 0.2060 / Avg. Reward  6.250 / Avg. Length 70.857 / Loss 141.5422 \n",
      "Loop 3168000 / Episode 165306 / Epsilon 0.2055 / Avg. Reward  5.121 / Avg. Length 60.788 / Loss 142.2856 \n",
      "Saving model weights\n",
      "Loop 3170000 / Episode 165347 / Epsilon 0.2050 / Avg. Reward  3.439 / Avg. Length 46.878 / Loss 140.0022 \n",
      "Loop 3172000 / Episode 165389 / Epsilon 0.2046 / Avg. Reward  3.786 / Avg. Length 49.690 / Loss 144.6444 \n",
      "Loop 3174000 / Episode 165422 / Epsilon 0.2041 / Avg. Reward  5.000 / Avg. Length 59.515 / Loss 142.7364 \n",
      "Loop 3176000 / Episode 165467 / Epsilon 0.2036 / Avg. Reward  3.267 / Avg. Length 45.244 / Loss 141.3838 \n",
      "Loop 3178000 / Episode 165508 / Epsilon 0.2032 / Avg. Reward  3.512 / Avg. Length 47.317 / Loss 144.1623 \n",
      "Saving model weights\n",
      "Loop 3180000 / Episode 165551 / Epsilon 0.2027 / Avg. Reward  3.558 / Avg. Length 47.558 / Loss 139.5117 \n",
      "Loop 3182000 / Episode 165601 / Epsilon 0.2022 / Avg. Reward  2.680 / Avg. Length 40.280 / Loss 150.9970 \n",
      "Loop 3184000 / Episode 165639 / Epsilon 0.2018 / Avg. Reward  3.921 / Avg. Length 51.289 / Loss 148.1023 \n",
      "Loop 3186000 / Episode 165676 / Epsilon 0.2013 / Avg. Reward  4.405 / Avg. Length 54.432 / Loss 149.0714 \n",
      "Loop 3188000 / Episode 165707 / Epsilon 0.2008 / Avg. Reward  5.645 / Avg. Length 65.774 / Loss 144.7934 \n",
      "Saving model weights\n",
      "Loop 3190000 / Episode 165741 / Epsilon 0.2003 / Avg. Reward  4.912 / Avg. Length 58.794 / Loss 145.0362 \n",
      "Loop 3192000 / Episode 165779 / Epsilon 0.1999 / Avg. Reward  4.000 / Avg. Length 51.421 / Loss 154.1358 \n",
      "Loop 3194000 / Episode 165821 / Epsilon 0.1994 / Avg. Reward  3.571 / Avg. Length 47.548 / Loss 148.3327 \n",
      "Loop 3196000 / Episode 165865 / Epsilon 0.1989 / Avg. Reward  3.409 / Avg. Length 46.341 / Loss 147.0287 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3198000 / Episode 165897 / Epsilon 0.1985 / Avg. Reward  5.312 / Avg. Length 62.156 / Loss 147.0803 \n",
      "Saving model weights\n",
      "Loop 3200000 / Episode 165942 / Epsilon 0.1980 / Avg. Reward  3.111 / Avg. Length 43.844 / Loss 147.4139 \n",
      "Loop 3202000 / Episode 165980 / Epsilon 0.1975 / Avg. Reward  4.158 / Avg. Length 52.658 / Loss 150.3824 \n",
      "Loop 3204000 / Episode 166027 / Epsilon 0.1971 / Avg. Reward  2.872 / Avg. Length 42.085 / Loss 151.1828 \n",
      "Loop 3206000 / Episode 166068 / Epsilon 0.1966 / Avg. Reward  3.854 / Avg. Length 50.073 / Loss 149.6246 \n",
      "Loop 3208000 / Episode 166105 / Epsilon 0.1961 / Avg. Reward  4.270 / Avg. Length 54.027 / Loss 150.2820 \n",
      "Saving model weights\n",
      "Loop 3210000 / Episode 166149 / Epsilon 0.1956 / Avg. Reward  3.295 / Avg. Length 45.841 / Loss 153.1946 \n",
      "Loop 3212000 / Episode 166179 / Epsilon 0.1952 / Avg. Reward  5.433 / Avg. Length 63.733 / Loss 159.9088 \n",
      "Loop 3214000 / Episode 166224 / Epsilon 0.1947 / Avg. Reward  3.222 / Avg. Length 45.444 / Loss 157.2853 \n",
      "Loop 3216000 / Episode 166260 / Epsilon 0.1942 / Avg. Reward  4.444 / Avg. Length 55.417 / Loss 153.9176 \n",
      "Loop 3218000 / Episode 166301 / Epsilon 0.1938 / Avg. Reward  3.659 / Avg. Length 48.415 / Loss 152.9179 \n",
      "Saving model weights\n",
      "Loop 3220000 / Episode 166336 / Epsilon 0.1933 / Avg. Reward  4.771 / Avg. Length 57.714 / Loss 155.3005 \n",
      "Loop 3222000 / Episode 166378 / Epsilon 0.1928 / Avg. Reward  3.643 / Avg. Length 48.619 / Loss 156.6661 \n",
      "Loop 3224000 / Episode 166415 / Epsilon 0.1924 / Avg. Reward  4.243 / Avg. Length 53.297 / Loss 156.9477 \n",
      "Loop 3226000 / Episode 166451 / Epsilon 0.1919 / Avg. Reward  4.500 / Avg. Length 56.111 / Loss 155.6344 \n",
      "Loop 3228000 / Episode 166490 / Epsilon 0.1914 / Avg. Reward  3.923 / Avg. Length 50.949 / Loss 158.5006 \n",
      "Saving model weights\n",
      "Loop 3230000 / Episode 166531 / Epsilon 0.1909 / Avg. Reward  3.537 / Avg. Length 46.951 / Loss 155.8402 \n",
      "Loop 3232000 / Episode 166573 / Epsilon 0.1905 / Avg. Reward  3.690 / Avg. Length 48.500 / Loss 158.8847 \n",
      "Loop 3234000 / Episode 166602 / Epsilon 0.1900 / Avg. Reward  6.138 / Avg. Length 69.966 / Loss 153.8106 \n",
      "Loop 3236000 / Episode 166639 / Epsilon 0.1895 / Avg. Reward  4.108 / Avg. Length 52.811 / Loss 156.4022 \n",
      "Loop 3238000 / Episode 166670 / Epsilon 0.1891 / Avg. Reward  5.387 / Avg. Length 62.839 / Loss 153.7282 \n",
      "Saving model weights\n",
      "Loop 3240000 / Episode 166707 / Epsilon 0.1886 / Avg. Reward  4.378 / Avg. Length 54.838 / Loss 157.3198 \n",
      "Loop 3242000 / Episode 166742 / Epsilon 0.1881 / Avg. Reward  4.686 / Avg. Length 57.229 / Loss 159.4203 \n",
      "Loop 3244000 / Episode 166778 / Epsilon 0.1877 / Avg. Reward  4.806 / Avg. Length 58.028 / Loss 157.1690 \n",
      "Loop 3246000 / Episode 166808 / Epsilon 0.1872 / Avg. Reward  5.133 / Avg. Length 61.600 / Loss 158.5418 \n",
      "Loop 3248000 / Episode 166842 / Epsilon 0.1867 / Avg. Reward  5.382 / Avg. Length 63.265 / Loss 157.9678 \n",
      "Saving model weights\n",
      "Loop 3250000 / Episode 166885 / Epsilon 0.1862 / Avg. Reward  3.302 / Avg. Length 45.116 / Loss 157.7527 \n",
      "Loop 3252000 / Episode 166923 / Epsilon 0.1858 / Avg. Reward  4.395 / Avg. Length 54.263 / Loss 159.4678 \n",
      "Loop 3254000 / Episode 166961 / Epsilon 0.1853 / Avg. Reward  4.132 / Avg. Length 52.605 / Loss 156.6110 \n",
      "Loop 3256000 / Episode 166993 / Epsilon 0.1848 / Avg. Reward  5.344 / Avg. Length 62.688 / Loss 154.6029 \n",
      "Loop 3258000 / Episode 167032 / Epsilon 0.1844 / Avg. Reward  3.949 / Avg. Length 50.769 / Loss 152.5318 \n",
      "Saving model weights\n",
      "Loop 3260000 / Episode 167066 / Epsilon 0.1839 / Avg. Reward  4.735 / Avg. Length 58.000 / Loss 151.6983 \n",
      "Loop 3262000 / Episode 167106 / Epsilon 0.1834 / Avg. Reward  3.650 / Avg. Length 48.125 / Loss 156.3953 \n",
      "Loop 3264000 / Episode 167137 / Epsilon 0.1830 / Avg. Reward  5.774 / Avg. Length 66.387 / Loss 155.6588 \n",
      "Loop 3266000 / Episode 167170 / Epsilon 0.1825 / Avg. Reward  5.242 / Avg. Length 62.364 / Loss 155.7532 \n",
      "Loop 3268000 / Episode 167213 / Epsilon 0.1820 / Avg. Reward  3.186 / Avg. Length 44.721 / Loss 154.3188 \n",
      "Saving model weights\n",
      "Loop 3270000 / Episode 167258 / Epsilon 0.1815 / Avg. Reward  3.422 / Avg. Length 46.444 / Loss 157.6588 \n",
      "Loop 3272000 / Episode 167298 / Epsilon 0.1811 / Avg. Reward  3.525 / Avg. Length 47.300 / Loss 160.7069 \n",
      "Loop 3274000 / Episode 167339 / Epsilon 0.1806 / Avg. Reward  3.805 / Avg. Length 50.049 / Loss 160.2572 \n",
      "Loop 3276000 / Episode 167374 / Epsilon 0.1801 / Avg. Reward  4.829 / Avg. Length 58.086 / Loss 157.6957 \n",
      "Loop 3278000 / Episode 167413 / Epsilon 0.1797 / Avg. Reward  4.077 / Avg. Length 51.872 / Loss 155.7057 \n",
      "Saving model weights\n",
      "Loop 3280000 / Episode 167458 / Epsilon 0.1792 / Avg. Reward  3.156 / Avg. Length 44.111 / Loss 159.0731 \n",
      "Loop 3282000 / Episode 167490 / Epsilon 0.1787 / Avg. Reward  4.375 / Avg. Length 54.219 / Loss 159.5995 \n",
      "Loop 3284000 / Episode 167515 / Epsilon 0.1783 / Avg. Reward  8.080 / Avg. Length 85.280 / Loss 160.0829 \n",
      "Loop 3286000 / Episode 167546 / Epsilon 0.1778 / Avg. Reward  6.065 / Avg. Length 68.968 / Loss 158.5079 \n",
      "Loop 3288000 / Episode 167593 / Epsilon 0.1773 / Avg. Reward  2.979 / Avg. Length 42.319 / Loss 158.7214 \n",
      "Saving model weights\n",
      "Loop 3290000 / Episode 167626 / Epsilon 0.1768 / Avg. Reward  4.758 / Avg. Length 57.788 / Loss 154.8413 \n",
      "Loop 3292000 / Episode 167672 / Epsilon 0.1764 / Avg. Reward  2.913 / Avg. Length 42.261 / Loss 162.1991 \n",
      "Loop 3294000 / Episode 167708 / Epsilon 0.1759 / Avg. Reward  4.861 / Avg. Length 58.639 / Loss 159.0488 \n",
      "Loop 3296000 / Episode 167740 / Epsilon 0.1754 / Avg. Reward  5.469 / Avg. Length 64.156 / Loss 160.6110 \n",
      "Loop 3298000 / Episode 167775 / Epsilon 0.1750 / Avg. Reward  4.600 / Avg. Length 56.371 / Loss 158.7282 \n",
      "Saving model weights\n",
      "Loop 3300000 / Episode 167811 / Epsilon 0.1745 / Avg. Reward  4.389 / Avg. Length 55.194 / Loss 156.3671 \n",
      "Loop 3302000 / Episode 167843 / Epsilon 0.1740 / Avg. Reward  5.312 / Avg. Length 62.656 / Loss 166.2431 \n",
      "Loop 3304000 / Episode 167871 / Epsilon 0.1736 / Avg. Reward  5.964 / Avg. Length 67.607 / Loss 163.5956 \n",
      "Loop 3306000 / Episode 167912 / Epsilon 0.1731 / Avg. Reward  4.049 / Avg. Length 52.098 / Loss 160.0502 \n",
      "Loop 3308000 / Episode 167947 / Epsilon 0.1726 / Avg. Reward  4.600 / Avg. Length 56.800 / Loss 161.9943 \n",
      "Saving model weights\n",
      "Loop 3310000 / Episode 167975 / Epsilon 0.1721 / Avg. Reward  5.393 / Avg. Length 64.143 / Loss 163.5245 \n",
      "Loop 3312000 / Episode 168013 / Epsilon 0.1717 / Avg. Reward  4.553 / Avg. Length 56.079 / Loss 170.2125 \n",
      "Loop 3314000 / Episode 168044 / Epsilon 0.1712 / Avg. Reward  5.774 / Avg. Length 66.903 / Loss 167.9928 \n",
      "Loop 3316000 / Episode 168073 / Epsilon 0.1707 / Avg. Reward  6.000 / Avg. Length 68.310 / Loss 167.8339 \n",
      "Loop 3318000 / Episode 168103 / Epsilon 0.1703 / Avg. Reward  5.667 / Avg. Length 65.500 / Loss 163.2727 \n",
      "Saving model weights\n",
      "Loop 3320000 / Episode 168143 / Epsilon 0.1698 / Avg. Reward  3.975 / Avg. Length 51.650 / Loss 165.8017 \n",
      "Loop 3322000 / Episode 168178 / Epsilon 0.1693 / Avg. Reward  4.571 / Avg. Length 56.029 / Loss 164.7325 \n",
      "Loop 3324000 / Episode 168218 / Epsilon 0.1689 / Avg. Reward  3.875 / Avg. Length 50.475 / Loss 156.6183 \n",
      "Loop 3326000 / Episode 168246 / Epsilon 0.1684 / Avg. Reward  5.786 / Avg. Length 66.179 / Loss 157.1185 \n",
      "Loop 3328000 / Episode 168279 / Epsilon 0.1679 / Avg. Reward  5.636 / Avg. Length 65.788 / Loss 158.5007 \n",
      "Saving model weights\n",
      "Loop 3330000 / Episode 168319 / Epsilon 0.1674 / Avg. Reward  3.750 / Avg. Length 49.075 / Loss 159.9271 \n",
      "Loop 3332000 / Episode 168346 / Epsilon 0.1670 / Avg. Reward  6.296 / Avg. Length 71.481 / Loss 162.3602 \n",
      "Loop 3334000 / Episode 168379 / Epsilon 0.1665 / Avg. Reward  5.303 / Avg. Length 62.455 / Loss 162.3574 \n",
      "Loop 3336000 / Episode 168409 / Epsilon 0.1660 / Avg. Reward  5.733 / Avg. Length 66.867 / Loss 158.9490 \n",
      "Loop 3338000 / Episode 168430 / Epsilon 0.1656 / Avg. Reward  8.952 / Avg. Length 94.095 / Loss 159.3608 \n",
      "Saving model weights\n",
      "Loop 3340000 / Episode 168468 / Epsilon 0.1651 / Avg. Reward  4.316 / Avg. Length 54.421 / Loss 159.1056 \n",
      "Loop 3342000 / Episode 168502 / Epsilon 0.1646 / Avg. Reward  4.412 / Avg. Length 55.029 / Loss 166.3605 \n",
      "Loop 3344000 / Episode 168531 / Epsilon 0.1642 / Avg. Reward  6.379 / Avg. Length 72.310 / Loss 164.6875 \n",
      "Loop 3346000 / Episode 168562 / Epsilon 0.1637 / Avg. Reward  5.581 / Avg. Length 64.774 / Loss 159.3369 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3348000 / Episode 168595 / Epsilon 0.1632 / Avg. Reward  4.970 / Avg. Length 59.576 / Loss 159.3275 \n",
      "Saving model weights\n",
      "Loop 3350000 / Episode 168633 / Epsilon 0.1627 / Avg. Reward  4.184 / Avg. Length 53.263 / Loss 162.1569 \n",
      "Loop 3352000 / Episode 168663 / Epsilon 0.1623 / Avg. Reward  5.900 / Avg. Length 67.100 / Loss 167.1681 \n",
      "Loop 3354000 / Episode 168698 / Epsilon 0.1618 / Avg. Reward  4.743 / Avg. Length 57.486 / Loss 163.6308 \n",
      "Loop 3356000 / Episode 168723 / Epsilon 0.1613 / Avg. Reward  7.080 / Avg. Length 77.640 / Loss 164.4156 \n",
      "Loop 3358000 / Episode 168763 / Epsilon 0.1609 / Avg. Reward  4.050 / Avg. Length 51.600 / Loss 161.7446 \n",
      "Saving model weights\n",
      "Loop 3360000 / Episode 168805 / Epsilon 0.1604 / Avg. Reward  3.548 / Avg. Length 47.357 / Loss 163.3915 \n",
      "Loop 3362000 / Episode 168837 / Epsilon 0.1599 / Avg. Reward  4.906 / Avg. Length 58.656 / Loss 163.4999 \n",
      "Loop 3364000 / Episode 168872 / Epsilon 0.1595 / Avg. Reward  5.086 / Avg. Length 61.143 / Loss 160.6196 \n",
      "Loop 3366000 / Episode 168903 / Epsilon 0.1590 / Avg. Reward  5.323 / Avg. Length 63.161 / Loss 165.0097 \n",
      "Loop 3368000 / Episode 168933 / Epsilon 0.1585 / Avg. Reward  5.933 / Avg. Length 68.100 / Loss 164.7211 \n",
      "Saving model weights\n",
      "Loop 3370000 / Episode 168965 / Epsilon 0.1580 / Avg. Reward  5.125 / Avg. Length 60.688 / Loss 162.8274 \n",
      "Loop 3372000 / Episode 169000 / Epsilon 0.1576 / Avg. Reward  4.886 / Avg. Length 58.571 / Loss 162.4891 \n",
      "Loop 3374000 / Episode 169029 / Epsilon 0.1571 / Avg. Reward  5.897 / Avg. Length 66.966 / Loss 159.4910 \n",
      "Loop 3376000 / Episode 169055 / Epsilon 0.1566 / Avg. Reward  6.923 / Avg. Length 76.615 / Loss 161.2233 \n",
      "Loop 3378000 / Episode 169090 / Epsilon 0.1562 / Avg. Reward  4.771 / Avg. Length 58.229 / Loss 159.4446 \n",
      "Saving model weights\n",
      "Loop 3380000 / Episode 169120 / Epsilon 0.1557 / Avg. Reward  5.800 / Avg. Length 66.900 / Loss 161.3517 \n",
      "Loop 3382000 / Episode 169144 / Epsilon 0.1552 / Avg. Reward  7.083 / Avg. Length 77.125 / Loss 161.6149 \n",
      "Loop 3384000 / Episode 169175 / Epsilon 0.1548 / Avg. Reward  6.226 / Avg. Length 69.742 / Loss 161.3372 \n",
      "Loop 3386000 / Episode 169206 / Epsilon 0.1543 / Avg. Reward  5.387 / Avg. Length 63.903 / Loss 160.7669 \n",
      "Loop 3388000 / Episode 169231 / Epsilon 0.1538 / Avg. Reward  7.160 / Avg. Length 78.120 / Loss 159.2379 \n",
      "Saving model weights\n",
      "Loop 3390000 / Episode 169259 / Epsilon 0.1533 / Avg. Reward  6.607 / Avg. Length 72.786 / Loss 159.1900 \n",
      "Loop 3392000 / Episode 169288 / Epsilon 0.1529 / Avg. Reward  6.172 / Avg. Length 69.759 / Loss 160.7595 \n",
      "Loop 3394000 / Episode 169319 / Epsilon 0.1524 / Avg. Reward  5.581 / Avg. Length 64.903 / Loss 159.8401 \n",
      "Loop 3396000 / Episode 169362 / Epsilon 0.1519 / Avg. Reward  2.953 / Avg. Length 42.512 / Loss 164.0731 \n",
      "Loop 3398000 / Episode 169394 / Epsilon 0.1515 / Avg. Reward  5.688 / Avg. Length 66.812 / Loss 160.9177 \n",
      "Saving model weights\n",
      "Loop 3400000 / Episode 169422 / Epsilon 0.1510 / Avg. Reward  6.464 / Avg. Length 72.286 / Loss 160.2241 \n",
      "Loop 3402000 / Episode 169457 / Epsilon 0.1505 / Avg. Reward  4.714 / Avg. Length 57.657 / Loss 168.0756 \n",
      "Loop 3404000 / Episode 169484 / Epsilon 0.1501 / Avg. Reward  6.593 / Avg. Length 73.889 / Loss 166.7978 \n",
      "Loop 3406000 / Episode 169514 / Epsilon 0.1496 / Avg. Reward  5.633 / Avg. Length 65.533 / Loss 167.5293 \n",
      "Loop 3408000 / Episode 169541 / Epsilon 0.1491 / Avg. Reward  6.778 / Avg. Length 74.593 / Loss 165.7693 \n",
      "Saving model weights\n",
      "Loop 3410000 / Episode 169572 / Epsilon 0.1486 / Avg. Reward  5.516 / Avg. Length 64.452 / Loss 166.4921 \n",
      "Loop 3412000 / Episode 169605 / Epsilon 0.1482 / Avg. Reward  5.091 / Avg. Length 60.848 / Loss 172.0902 \n",
      "Loop 3414000 / Episode 169636 / Epsilon 0.1477 / Avg. Reward  4.871 / Avg. Length 58.484 / Loss 168.4040 \n",
      "Loop 3416000 / Episode 169658 / Epsilon 0.1472 / Avg. Reward  9.136 / Avg. Length 95.045 / Loss 162.8558 \n",
      "Loop 3418000 / Episode 169690 / Epsilon 0.1468 / Avg. Reward  5.656 / Avg. Length 65.969 / Loss 167.5787 \n",
      "Saving model weights\n",
      "Loop 3420000 / Episode 169716 / Epsilon 0.1463 / Avg. Reward  7.038 / Avg. Length 76.808 / Loss 161.9296 \n",
      "Loop 3422000 / Episode 169748 / Epsilon 0.1458 / Avg. Reward  5.156 / Avg. Length 61.906 / Loss 172.5307 \n",
      "Loop 3424000 / Episode 169774 / Epsilon 0.1454 / Avg. Reward  7.038 / Avg. Length 77.538 / Loss 175.5822 \n",
      "Loop 3426000 / Episode 169797 / Epsilon 0.1449 / Avg. Reward  8.174 / Avg. Length 86.435 / Loss 172.5427 \n",
      "Loop 3428000 / Episode 169825 / Epsilon 0.1444 / Avg. Reward  6.321 / Avg. Length 70.821 / Loss 172.4146 \n",
      "Saving model weights\n",
      "Loop 3430000 / Episode 169852 / Epsilon 0.1439 / Avg. Reward  6.778 / Avg. Length 75.444 / Loss 173.9960 \n",
      "Loop 3432000 / Episode 169877 / Epsilon 0.1435 / Avg. Reward  6.800 / Avg. Length 75.480 / Loss 174.2049 \n",
      "Loop 3434000 / Episode 169904 / Epsilon 0.1430 / Avg. Reward  7.074 / Avg. Length 77.296 / Loss 172.0531 \n",
      "Loop 3436000 / Episode 169935 / Epsilon 0.1425 / Avg. Reward  5.548 / Avg. Length 64.935 / Loss 169.6058 \n",
      "Loop 3438000 / Episode 169952 / Epsilon 0.1421 / Avg. Reward 11.294 / Avg. Length 114.176 / Loss 171.6388 \n",
      "Saving model weights\n",
      "Loop 3440000 / Episode 169978 / Epsilon 0.1416 / Avg. Reward  7.308 / Avg. Length 78.577 / Loss 170.8029 \n",
      "Loop 3442000 / Episode 170006 / Epsilon 0.1411 / Avg. Reward  6.464 / Avg. Length 72.429 / Loss 174.8528 \n",
      "Loop 3444000 / Episode 170038 / Epsilon 0.1407 / Avg. Reward  5.156 / Avg. Length 61.063 / Loss 176.0029 \n",
      "Loop 3446000 / Episode 170064 / Epsilon 0.1402 / Avg. Reward  7.038 / Avg. Length 78.192 / Loss 169.6281 \n",
      "Loop 3448000 / Episode 170092 / Epsilon 0.1397 / Avg. Reward  5.500 / Avg. Length 63.964 / Loss 169.2934 \n",
      "Saving model weights\n",
      "Loop 3450000 / Episode 170123 / Epsilon 0.1392 / Avg. Reward  6.226 / Avg. Length 70.710 / Loss 173.4235 \n",
      "Loop 3452000 / Episode 170145 / Epsilon 0.1388 / Avg. Reward  8.227 / Avg. Length 87.636 / Loss 186.2500 \n",
      "Loop 3454000 / Episode 170167 / Epsilon 0.1383 / Avg. Reward  9.091 / Avg. Length 94.273 / Loss 177.8156 \n",
      "Loop 3456000 / Episode 170198 / Epsilon 0.1378 / Avg. Reward  5.645 / Avg. Length 65.484 / Loss 178.8191 \n",
      "Loop 3458000 / Episode 170234 / Epsilon 0.1374 / Avg. Reward  4.333 / Avg. Length 54.056 / Loss 178.3222 \n",
      "Saving model weights\n",
      "Loop 3460000 / Episode 170268 / Epsilon 0.1369 / Avg. Reward  4.941 / Avg. Length 59.147 / Loss 179.5273 \n",
      "Loop 3462000 / Episode 170290 / Epsilon 0.1364 / Avg. Reward  8.455 / Avg. Length 89.909 / Loss 183.6216 \n",
      "Loop 3464000 / Episode 170314 / Epsilon 0.1360 / Avg. Reward  7.542 / Avg. Length 81.833 / Loss 180.7312 \n",
      "Loop 3466000 / Episode 170338 / Epsilon 0.1355 / Avg. Reward  8.125 / Avg. Length 86.875 / Loss 179.0129 \n",
      "Loop 3468000 / Episode 170359 / Epsilon 0.1350 / Avg. Reward  8.429 / Avg. Length 88.857 / Loss 181.5004 \n",
      "Saving model weights\n",
      "Loop 3470000 / Episode 170389 / Epsilon 0.1345 / Avg. Reward  6.200 / Avg. Length 70.467 / Loss 176.6449 \n",
      "Loop 3472000 / Episode 170420 / Epsilon 0.1341 / Avg. Reward  5.355 / Avg. Length 62.452 / Loss 180.0608 \n",
      "Loop 3474000 / Episode 170449 / Epsilon 0.1336 / Avg. Reward  6.379 / Avg. Length 71.034 / Loss 184.6808 \n",
      "Loop 3476000 / Episode 170468 / Epsilon 0.1331 / Avg. Reward  9.053 / Avg. Length 93.684 / Loss 182.8988 \n",
      "Loop 3478000 / Episode 170489 / Epsilon 0.1327 / Avg. Reward 10.571 / Avg. Length 106.762 / Loss 183.2118 \n",
      "Saving model weights\n",
      "Loop 3480000 / Episode 170521 / Epsilon 0.1322 / Avg. Reward  5.219 / Avg. Length 61.719 / Loss 179.2850 \n",
      "Loop 3482000 / Episode 170547 / Epsilon 0.1317 / Avg. Reward  7.154 / Avg. Length 78.615 / Loss 191.2449 \n",
      "Loop 3484000 / Episode 170574 / Epsilon 0.1313 / Avg. Reward  6.333 / Avg. Length 71.778 / Loss 186.8189 \n",
      "Loop 3486000 / Episode 170598 / Epsilon 0.1308 / Avg. Reward  7.542 / Avg. Length 82.458 / Loss 182.7295 \n",
      "Loop 3488000 / Episode 170630 / Epsilon 0.1303 / Avg. Reward  5.531 / Avg. Length 64.094 / Loss 183.4077 \n",
      "Saving model weights\n",
      "Loop 3490000 / Episode 170653 / Epsilon 0.1298 / Avg. Reward  8.261 / Avg. Length 87.522 / Loss 181.5516 \n",
      "Loop 3492000 / Episode 170679 / Epsilon 0.1294 / Avg. Reward  6.962 / Avg. Length 76.462 / Loss 183.5830 \n",
      "Loop 3494000 / Episode 170706 / Epsilon 0.1289 / Avg. Reward  6.630 / Avg. Length 73.444 / Loss 184.0044 \n",
      "Loop 3496000 / Episode 170729 / Epsilon 0.1284 / Avg. Reward  8.043 / Avg. Length 85.609 / Loss 176.7389 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3498000 / Episode 170760 / Epsilon 0.1280 / Avg. Reward  5.774 / Avg. Length 66.806 / Loss 180.7564 \n",
      "Saving model weights\n",
      "Loop 3500000 / Episode 170783 / Epsilon 0.1275 / Avg. Reward  7.217 / Avg. Length 78.870 / Loss 181.5934 \n",
      "Loop 3502000 / Episode 170811 / Epsilon 0.1270 / Avg. Reward  7.000 / Avg. Length 77.321 / Loss 186.2990 \n",
      "Loop 3504000 / Episode 170839 / Epsilon 0.1266 / Avg. Reward  5.929 / Avg. Length 67.429 / Loss 180.2319 \n",
      "Loop 3506000 / Episode 170868 / Epsilon 0.1261 / Avg. Reward  6.276 / Avg. Length 71.103 / Loss 184.2708 \n",
      "Loop 3508000 / Episode 170900 / Epsilon 0.1256 / Avg. Reward  5.156 / Avg. Length 61.094 / Loss 177.4814 \n",
      "Saving model weights\n",
      "Loop 3510000 / Episode 170929 / Epsilon 0.1251 / Avg. Reward  6.448 / Avg. Length 71.793 / Loss 184.9417 \n",
      "Loop 3512000 / Episode 170949 / Epsilon 0.1247 / Avg. Reward  9.350 / Avg. Length 96.750 / Loss 189.8010 \n",
      "Loop 3514000 / Episode 170971 / Epsilon 0.1242 / Avg. Reward  8.773 / Avg. Length 92.182 / Loss 188.3912 \n",
      "Loop 3516000 / Episode 170997 / Epsilon 0.1237 / Avg. Reward  7.231 / Avg. Length 78.462 / Loss 186.1338 \n",
      "Loop 3518000 / Episode 171030 / Epsilon 0.1233 / Avg. Reward  5.121 / Avg. Length 60.121 / Loss 185.7391 \n",
      "Saving model weights\n",
      "Loop 3520000 / Episode 171054 / Epsilon 0.1228 / Avg. Reward  7.792 / Avg. Length 83.375 / Loss 188.5660 \n",
      "Loop 3522000 / Episode 171076 / Epsilon 0.1223 / Avg. Reward  7.545 / Avg. Length 80.545 / Loss 192.2620 \n",
      "Loop 3524000 / Episode 171103 / Epsilon 0.1219 / Avg. Reward  7.444 / Avg. Length 80.444 / Loss 186.4179 \n",
      "Loop 3526000 / Episode 171125 / Epsilon 0.1214 / Avg. Reward  8.591 / Avg. Length 90.091 / Loss 187.0108 \n",
      "Loop 3528000 / Episode 171147 / Epsilon 0.1209 / Avg. Reward  9.091 / Avg. Length 94.682 / Loss 187.3221 \n",
      "Saving model weights\n",
      "Loop 3530000 / Episode 171175 / Epsilon 0.1204 / Avg. Reward  5.964 / Avg. Length 68.071 / Loss 181.8324 \n",
      "Loop 3532000 / Episode 171195 / Epsilon 0.1200 / Avg. Reward 10.050 / Avg. Length 103.400 / Loss 188.8455 \n",
      "Loop 3534000 / Episode 171218 / Epsilon 0.1195 / Avg. Reward  8.565 / Avg. Length 90.087 / Loss 183.1491 \n",
      "Loop 3536000 / Episode 171251 / Epsilon 0.1190 / Avg. Reward  4.394 / Avg. Length 55.212 / Loss 188.1390 \n",
      "Loop 3538000 / Episode 171280 / Epsilon 0.1186 / Avg. Reward  6.276 / Avg. Length 70.621 / Loss 187.2940 \n",
      "Saving model weights\n",
      "Loop 3540000 / Episode 171308 / Epsilon 0.1181 / Avg. Reward  6.393 / Avg. Length 71.893 / Loss 190.0170 \n",
      "Loop 3542000 / Episode 171327 / Epsilon 0.1176 / Avg. Reward 10.579 / Avg. Length 107.158 / Loss 187.5465 \n",
      "Loop 3544000 / Episode 171346 / Epsilon 0.1172 / Avg. Reward  9.684 / Avg. Length 99.474 / Loss 185.2903 \n",
      "Loop 3546000 / Episode 171367 / Epsilon 0.1167 / Avg. Reward  9.333 / Avg. Length 96.952 / Loss 185.8000 \n",
      "Loop 3548000 / Episode 171396 / Epsilon 0.1162 / Avg. Reward  6.552 / Avg. Length 72.724 / Loss 187.4056 \n",
      "Saving model weights\n",
      "Loop 3550000 / Episode 171423 / Epsilon 0.1157 / Avg. Reward  6.630 / Avg. Length 73.667 / Loss 180.9606 \n",
      "Loop 3552000 / Episode 171448 / Epsilon 0.1153 / Avg. Reward  6.920 / Avg. Length 76.480 / Loss 184.5434 \n",
      "Loop 3554000 / Episode 171467 / Epsilon 0.1148 / Avg. Reward 10.632 / Avg. Length 107.053 / Loss 179.8686 \n",
      "Loop 3556000 / Episode 171481 / Epsilon 0.1143 / Avg. Reward 15.286 / Avg. Length 145.857 / Loss 180.5920 \n",
      "Loop 3558000 / Episode 171509 / Epsilon 0.1139 / Avg. Reward  6.179 / Avg. Length 69.393 / Loss 176.4268 \n",
      "Saving model weights\n",
      "Loop 3560000 / Episode 171540 / Epsilon 0.1134 / Avg. Reward  5.968 / Avg. Length 68.161 / Loss 179.2277 \n",
      "Loop 3562000 / Episode 171558 / Epsilon 0.1129 / Avg. Reward 11.056 / Avg. Length 111.778 / Loss 182.7525 \n",
      "Loop 3564000 / Episode 171579 / Epsilon 0.1125 / Avg. Reward  8.333 / Avg. Length 88.476 / Loss 179.5001 \n",
      "Loop 3566000 / Episode 171607 / Epsilon 0.1120 / Avg. Reward  6.714 / Avg. Length 74.321 / Loss 185.0100 \n",
      "Loop 3568000 / Episode 171620 / Epsilon 0.1115 / Avg. Reward 15.692 / Avg. Length 151.308 / Loss 170.5452 \n",
      "Saving model weights\n",
      "Loop 3570000 / Episode 171646 / Epsilon 0.1110 / Avg. Reward  6.962 / Avg. Length 77.231 / Loss 178.8552 \n",
      "Loop 3572000 / Episode 171667 / Epsilon 0.1106 / Avg. Reward  9.476 / Avg. Length 97.714 / Loss 187.1295 \n",
      "Loop 3574000 / Episode 171690 / Epsilon 0.1101 / Avg. Reward  8.217 / Avg. Length 87.087 / Loss 182.6518 \n",
      "Loop 3576000 / Episode 171706 / Epsilon 0.1096 / Avg. Reward 12.875 / Avg. Length 125.938 / Loss 182.3785 \n",
      "Loop 3578000 / Episode 171728 / Epsilon 0.1092 / Avg. Reward  8.500 / Avg. Length 89.955 / Loss 181.9461 \n",
      "Saving model weights\n",
      "Loop 3580000 / Episode 171756 / Epsilon 0.1087 / Avg. Reward  6.536 / Avg. Length 72.571 / Loss 176.9494 \n",
      "Loop 3582000 / Episode 171776 / Epsilon 0.1082 / Avg. Reward  8.150 / Avg. Length 86.700 / Loss 182.7877 \n",
      "Loop 3584000 / Episode 171799 / Epsilon 0.1078 / Avg. Reward  9.565 / Avg. Length 98.130 / Loss 181.4433 \n",
      "Loop 3586000 / Episode 171825 / Epsilon 0.1073 / Avg. Reward  7.077 / Avg. Length 77.115 / Loss 184.0521 \n",
      "Loop 3588000 / Episode 171845 / Epsilon 0.1068 / Avg. Reward  7.850 / Avg. Length 84.200 / Loss 181.9574 \n",
      "Saving model weights\n",
      "Loop 3590000 / Episode 171862 / Epsilon 0.1063 / Avg. Reward 13.824 / Avg. Length 134.235 / Loss 178.3726 \n",
      "Loop 3592000 / Episode 171884 / Epsilon 0.1059 / Avg. Reward  8.409 / Avg. Length 89.364 / Loss 191.8697 \n",
      "Loop 3594000 / Episode 171906 / Epsilon 0.1054 / Avg. Reward  8.955 / Avg. Length 94.227 / Loss 189.5410 \n",
      "Loop 3596000 / Episode 171924 / Epsilon 0.1049 / Avg. Reward 11.056 / Avg. Length 111.167 / Loss 186.6757 \n",
      "Loop 3598000 / Episode 171941 / Epsilon 0.1045 / Avg. Reward 10.118 / Avg. Length 103.941 / Loss 188.0165 \n",
      "Saving model weights\n",
      "Loop 3600000 / Episode 171959 / Epsilon 0.1040 / Avg. Reward 12.389 / Avg. Length 122.278 / Loss 189.2564 \n",
      "Loop 3602000 / Episode 171972 / Epsilon 0.1035 / Avg. Reward 16.154 / Avg. Length 154.615 / Loss 191.0971 \n",
      "Loop 3604000 / Episode 171996 / Epsilon 0.1031 / Avg. Reward  7.375 / Avg. Length 80.292 / Loss 193.8463 \n",
      "Loop 3606000 / Episode 172008 / Epsilon 0.1026 / Avg. Reward 15.417 / Avg. Length 148.333 / Loss 190.8010 \n",
      "Loop 3608000 / Episode 172029 / Epsilon 0.1021 / Avg. Reward  8.429 / Avg. Length 89.762 / Loss 184.1488 \n",
      "Saving model weights\n",
      "Loop 3610000 / Episode 172048 / Epsilon 0.1016 / Avg. Reward 11.842 / Avg. Length 116.947 / Loss 185.3907 \n",
      "Loop 3612000 / Episode 172066 / Epsilon 0.1012 / Avg. Reward 12.389 / Avg. Length 121.500 / Loss 187.1030 \n",
      "Loop 3614000 / Episode 172080 / Epsilon 0.1007 / Avg. Reward 14.357 / Avg. Length 138.357 / Loss 189.1342 \n",
      "Loop 3616000 / Episode 172102 / Epsilon 0.1002 / Avg. Reward  9.000 / Avg. Length 94.045 / Loss 184.6197 \n",
      "Loop 3618000 / Episode 172121 / Epsilon 0.0998 / Avg. Reward 10.263 / Avg. Length 104.263 / Loss 177.7324 \n",
      "Saving model weights\n",
      "Loop 3620000 / Episode 172134 / Epsilon 0.0993 / Avg. Reward 16.308 / Avg. Length 154.769 / Loss 182.4019 \n",
      "Loop 3622000 / Episode 172158 / Epsilon 0.0988 / Avg. Reward  7.375 / Avg. Length 79.958 / Loss 199.8270 \n",
      "Loop 3624000 / Episode 172177 / Epsilon 0.0984 / Avg. Reward  9.895 / Avg. Length 101.895 / Loss 191.4815 \n",
      "Loop 3626000 / Episode 172199 / Epsilon 0.0979 / Avg. Reward  9.545 / Avg. Length 98.545 / Loss 187.8001 \n",
      "Loop 3628000 / Episode 172223 / Epsilon 0.0974 / Avg. Reward  7.583 / Avg. Length 81.417 / Loss 189.1343 \n",
      "Saving model weights\n",
      "Loop 3630000 / Episode 172238 / Epsilon 0.0969 / Avg. Reward 13.667 / Avg. Length 133.133 / Loss 192.9864 \n",
      "Loop 3632000 / Episode 172260 / Epsilon 0.0965 / Avg. Reward  8.818 / Avg. Length 91.909 / Loss 195.7449 \n",
      "Loop 3634000 / Episode 172284 / Epsilon 0.0960 / Avg. Reward  7.667 / Avg. Length 82.750 / Loss 187.6100 \n",
      "Loop 3636000 / Episode 172301 / Epsilon 0.0955 / Avg. Reward 11.235 / Avg. Length 113.000 / Loss 193.2321 \n",
      "Loop 3638000 / Episode 172318 / Epsilon 0.0951 / Avg. Reward 12.000 / Avg. Length 118.529 / Loss 193.0409 \n",
      "Saving model weights\n",
      "Loop 3640000 / Episode 172340 / Epsilon 0.0946 / Avg. Reward  9.227 / Avg. Length 95.136 / Loss 197.6080 \n",
      "Loop 3642000 / Episode 172361 / Epsilon 0.0941 / Avg. Reward  9.143 / Avg. Length 94.143 / Loss 197.1723 \n",
      "Loop 3644000 / Episode 172377 / Epsilon 0.0937 / Avg. Reward 12.375 / Avg. Length 121.750 / Loss 200.7197 \n",
      "Loop 3646000 / Episode 172404 / Epsilon 0.0932 / Avg. Reward  6.889 / Avg. Length 75.926 / Loss 195.9899 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3648000 / Episode 172421 / Epsilon 0.0927 / Avg. Reward 11.765 / Avg. Length 117.941 / Loss 192.8348 \n",
      "Saving model weights\n",
      "Loop 3650000 / Episode 172444 / Epsilon 0.0922 / Avg. Reward  7.391 / Avg. Length 80.217 / Loss 194.4802 \n",
      "Loop 3652000 / Episode 172461 / Epsilon 0.0918 / Avg. Reward 12.824 / Avg. Length 125.824 / Loss 200.5198 \n",
      "Loop 3654000 / Episode 172480 / Epsilon 0.0913 / Avg. Reward  9.737 / Avg. Length 99.368 / Loss 192.1170 \n",
      "Loop 3656000 / Episode 172501 / Epsilon 0.0908 / Avg. Reward  9.952 / Avg. Length 102.524 / Loss 194.9035 \n",
      "Loop 3658000 / Episode 172518 / Epsilon 0.0904 / Avg. Reward 11.647 / Avg. Length 116.882 / Loss 193.5189 \n",
      "Saving model weights\n",
      "Loop 3660000 / Episode 172539 / Epsilon 0.0899 / Avg. Reward  8.810 / Avg. Length 92.905 / Loss 191.7188 \n",
      "Loop 3662000 / Episode 172554 / Epsilon 0.0894 / Avg. Reward 14.067 / Avg. Length 137.533 / Loss 202.9002 \n",
      "Loop 3664000 / Episode 172576 / Epsilon 0.0890 / Avg. Reward  8.364 / Avg. Length 88.091 / Loss 201.2295 \n",
      "Loop 3666000 / Episode 172598 / Epsilon 0.0885 / Avg. Reward  8.545 / Avg. Length 90.500 / Loss 203.6390 \n",
      "Loop 3668000 / Episode 172617 / Epsilon 0.0880 / Avg. Reward 10.789 / Avg. Length 108.368 / Loss 198.8525 \n",
      "Saving model weights\n",
      "Loop 3670000 / Episode 172629 / Epsilon 0.0875 / Avg. Reward 17.417 / Avg. Length 165.167 / Loss 198.5414 \n",
      "Loop 3672000 / Episode 172646 / Epsilon 0.0871 / Avg. Reward 12.000 / Avg. Length 119.118 / Loss 205.9193 \n",
      "Loop 3674000 / Episode 172668 / Epsilon 0.0866 / Avg. Reward  7.818 / Avg. Length 83.818 / Loss 206.7857 \n",
      "Loop 3676000 / Episode 172683 / Epsilon 0.0861 / Avg. Reward 14.333 / Avg. Length 138.600 / Loss 202.8754 \n",
      "Loop 3678000 / Episode 172704 / Epsilon 0.0857 / Avg. Reward  9.429 / Avg. Length 96.333 / Loss 201.1496 \n",
      "Saving model weights\n",
      "Loop 3680000 / Episode 172724 / Epsilon 0.0852 / Avg. Reward 10.150 / Avg. Length 103.050 / Loss 201.1116 \n",
      "Loop 3682000 / Episode 172739 / Epsilon 0.0847 / Avg. Reward 12.800 / Avg. Length 125.333 / Loss 209.0068 \n",
      "Loop 3684000 / Episode 172754 / Epsilon 0.0843 / Avg. Reward 12.600 / Avg. Length 124.600 / Loss 205.5265 \n",
      "Loop 3686000 / Episode 172773 / Epsilon 0.0838 / Avg. Reward 11.789 / Avg. Length 117.368 / Loss 197.8272 \n",
      "Loop 3688000 / Episode 172787 / Epsilon 0.0833 / Avg. Reward 12.571 / Avg. Length 124.571 / Loss 202.5555 \n",
      "Saving model weights\n",
      "Loop 3690000 / Episode 172803 / Epsilon 0.0828 / Avg. Reward 14.438 / Avg. Length 139.312 / Loss 195.0772 \n",
      "Loop 3692000 / Episode 172820 / Epsilon 0.0824 / Avg. Reward 11.294 / Avg. Length 112.824 / Loss 208.6715 \n",
      "Loop 3694000 / Episode 172839 / Epsilon 0.0819 / Avg. Reward 10.632 / Avg. Length 107.053 / Loss 210.8982 \n",
      "Loop 3696000 / Episode 172858 / Epsilon 0.0814 / Avg. Reward 10.316 / Avg. Length 104.526 / Loss 207.9143 \n",
      "Loop 3698000 / Episode 172872 / Epsilon 0.0810 / Avg. Reward 14.643 / Avg. Length 141.429 / Loss 201.0964 \n",
      "Saving model weights\n",
      "Loop 3700000 / Episode 172882 / Epsilon 0.0805 / Avg. Reward 22.400 / Avg. Length 207.400 / Loss 203.9833 \n",
      "Loop 3702000 / Episode 172901 / Epsilon 0.0800 / Avg. Reward  8.474 / Avg. Length 89.579 / Loss 209.2196 \n",
      "Loop 3704000 / Episode 172915 / Epsilon 0.0796 / Avg. Reward 17.429 / Avg. Length 166.857 / Loss 204.0194 \n",
      "Loop 3706000 / Episode 172932 / Epsilon 0.0791 / Avg. Reward 11.824 / Avg. Length 116.824 / Loss 199.6783 \n",
      "Loop 3708000 / Episode 172942 / Epsilon 0.0786 / Avg. Reward 21.800 / Avg. Length 201.900 / Loss 198.2598 \n",
      "Saving model weights\n",
      "Loop 3710000 / Episode 172960 / Epsilon 0.0781 / Avg. Reward  9.389 / Avg. Length 97.667 / Loss 191.2215 \n",
      "Loop 3712000 / Episode 172971 / Epsilon 0.0777 / Avg. Reward 20.636 / Avg. Length 192.455 / Loss 197.2774 \n",
      "Loop 3714000 / Episode 172988 / Epsilon 0.0772 / Avg. Reward 12.235 / Avg. Length 120.647 / Loss 195.8798 \n",
      "Loop 3716000 / Episode 173004 / Epsilon 0.0767 / Avg. Reward 12.125 / Avg. Length 120.625 / Loss 199.4195 \n",
      "Loop 3718000 / Episode 173017 / Epsilon 0.0763 / Avg. Reward 16.923 / Avg. Length 162.231 / Loss 202.5158 \n",
      "Saving model weights\n",
      "Loop 3720000 / Episode 173033 / Epsilon 0.0758 / Avg. Reward 12.625 / Avg. Length 124.313 / Loss 201.8168 \n",
      "Loop 3722000 / Episode 173053 / Epsilon 0.0753 / Avg. Reward  9.250 / Avg. Length 96.500 / Loss 214.2981 \n",
      "Loop 3724000 / Episode 173074 / Epsilon 0.0749 / Avg. Reward  9.619 / Avg. Length 99.048 / Loss 208.1508 \n",
      "Loop 3726000 / Episode 173088 / Epsilon 0.0744 / Avg. Reward 14.000 / Avg. Length 136.143 / Loss 205.3421 \n",
      "Loop 3728000 / Episode 173108 / Epsilon 0.0739 / Avg. Reward 10.150 / Avg. Length 103.700 / Loss 208.1105 \n",
      "Saving model weights\n",
      "Loop 3730000 / Episode 173116 / Epsilon 0.0734 / Avg. Reward 28.125 / Avg. Length 252.000 / Loss 204.9032 \n",
      "Loop 3732000 / Episode 173132 / Epsilon 0.0730 / Avg. Reward 11.438 / Avg. Length 114.625 / Loss 206.9296 \n",
      "Loop 3734000 / Episode 173146 / Epsilon 0.0725 / Avg. Reward 14.714 / Avg. Length 141.857 / Loss 208.2166 \n",
      "Loop 3736000 / Episode 173158 / Epsilon 0.0720 / Avg. Reward 19.833 / Avg. Length 186.417 / Loss 201.2420 \n",
      "Loop 3738000 / Episode 173176 / Epsilon 0.0716 / Avg. Reward 10.833 / Avg. Length 109.056 / Loss 206.2530 \n",
      "Saving model weights\n",
      "Loop 3740000 / Episode 173186 / Epsilon 0.0711 / Avg. Reward 20.800 / Avg. Length 193.400 / Loss 205.5825 \n",
      "Loop 3742000 / Episode 173199 / Epsilon 0.0706 / Avg. Reward 15.923 / Avg. Length 152.462 / Loss 206.0702 \n",
      "Loop 3744000 / Episode 173211 / Epsilon 0.0702 / Avg. Reward 18.167 / Avg. Length 171.667 / Loss 206.6780 \n",
      "Loop 3746000 / Episode 173226 / Epsilon 0.0697 / Avg. Reward 13.533 / Avg. Length 133.533 / Loss 214.8364 \n",
      "Loop 3748000 / Episode 173239 / Epsilon 0.0692 / Avg. Reward 16.462 / Avg. Length 157.615 / Loss 199.0910 \n",
      "Saving model weights\n",
      "Loop 3750000 / Episode 173250 / Epsilon 0.0687 / Avg. Reward 18.273 / Avg. Length 173.273 / Loss 203.5342 \n",
      "Loop 3752000 / Episode 173257 / Epsilon 0.0683 / Avg. Reward 27.571 / Avg. Length 251.714 / Loss 213.9370 \n",
      "Loop 3754000 / Episode 173273 / Epsilon 0.0678 / Avg. Reward 15.188 / Avg. Length 146.125 / Loss 211.6150 \n",
      "Loop 3756000 / Episode 173294 / Epsilon 0.0673 / Avg. Reward  8.190 / Avg. Length 87.333 / Loss 204.1693 \n",
      "Loop 3758000 / Episode 173311 / Epsilon 0.0669 / Avg. Reward 12.647 / Avg. Length 125.588 / Loss 212.6034 \n",
      "Saving model weights\n",
      "Loop 3760000 / Episode 173324 / Epsilon 0.0664 / Avg. Reward 15.385 / Avg. Length 148.923 / Loss 201.7394 \n",
      "Loop 3762000 / Episode 173339 / Epsilon 0.0659 / Avg. Reward 13.200 / Avg. Length 129.467 / Loss 215.3557 \n",
      "Loop 3764000 / Episode 173354 / Epsilon 0.0655 / Avg. Reward 14.933 / Avg. Length 143.800 / Loss 211.7802 \n",
      "Loop 3766000 / Episode 173369 / Epsilon 0.0650 / Avg. Reward 12.467 / Avg. Length 122.867 / Loss 212.9770 \n",
      "Loop 3768000 / Episode 173384 / Epsilon 0.0645 / Avg. Reward 14.533 / Avg. Length 140.800 / Loss 212.9567 \n",
      "Saving model weights\n",
      "Loop 3770000 / Episode 173397 / Epsilon 0.0640 / Avg. Reward 14.077 / Avg. Length 136.538 / Loss 211.2915 \n",
      "Loop 3772000 / Episode 173407 / Epsilon 0.0636 / Avg. Reward 23.200 / Avg. Length 215.500 / Loss 222.4595 \n",
      "Loop 3774000 / Episode 173427 / Epsilon 0.0631 / Avg. Reward  9.700 / Avg. Length 100.050 / Loss 223.9270 \n",
      "Loop 3776000 / Episode 173441 / Epsilon 0.0626 / Avg. Reward 14.214 / Avg. Length 137.786 / Loss 213.8520 \n",
      "Loop 3778000 / Episode 173451 / Epsilon 0.0622 / Avg. Reward 18.400 / Avg. Length 172.400 / Loss 212.7340 \n",
      "Saving model weights\n",
      "Loop 3780000 / Episode 173464 / Epsilon 0.0617 / Avg. Reward 20.154 / Avg. Length 187.846 / Loss 215.0442 \n",
      "Loop 3782000 / Episode 173474 / Epsilon 0.0612 / Avg. Reward 20.400 / Avg. Length 190.900 / Loss 214.6708 \n",
      "Loop 3784000 / Episode 173489 / Epsilon 0.0608 / Avg. Reward 12.667 / Avg. Length 124.467 / Loss 225.9577 \n",
      "Loop 3786000 / Episode 173498 / Epsilon 0.0603 / Avg. Reward 26.222 / Avg. Length 238.889 / Loss 216.0304 \n",
      "Loop 3788000 / Episode 173510 / Epsilon 0.0598 / Avg. Reward 18.417 / Avg. Length 172.333 / Loss 221.0483 \n",
      "Saving model weights\n",
      "Loop 3790000 / Episode 173522 / Epsilon 0.0593 / Avg. Reward 15.250 / Avg. Length 146.667 / Loss 219.8771 \n",
      "Loop 3792000 / Episode 173535 / Epsilon 0.0589 / Avg. Reward 17.000 / Avg. Length 161.231 / Loss 224.4221 \n",
      "Loop 3794000 / Episode 173551 / Epsilon 0.0584 / Avg. Reward 12.875 / Avg. Length 126.063 / Loss 220.8553 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3796000 / Episode 173557 / Epsilon 0.0579 / Avg. Reward 36.000 / Avg. Length 323.000 / Loss 219.1211 \n",
      "Loop 3798000 / Episode 173571 / Epsilon 0.0575 / Avg. Reward 16.500 / Avg. Length 157.857 / Loss 222.4497 \n",
      "Saving model weights\n",
      "Loop 3800000 / Episode 173587 / Epsilon 0.0570 / Avg. Reward 12.625 / Avg. Length 124.125 / Loss 219.3792 \n",
      "Loop 3802000 / Episode 173600 / Epsilon 0.0565 / Avg. Reward 14.692 / Avg. Length 142.769 / Loss 234.6546 \n",
      "Loop 3804000 / Episode 173614 / Epsilon 0.0561 / Avg. Reward 15.071 / Avg. Length 146.214 / Loss 224.5973 \n",
      "Loop 3806000 / Episode 173630 / Epsilon 0.0556 / Avg. Reward 13.375 / Avg. Length 131.562 / Loss 222.3192 \n",
      "Loop 3808000 / Episode 173639 / Epsilon 0.0551 / Avg. Reward 22.000 / Avg. Length 203.444 / Loss 219.3355 \n",
      "Saving model weights\n",
      "Loop 3810000 / Episode 173650 / Epsilon 0.0546 / Avg. Reward 21.091 / Avg. Length 196.000 / Loss 215.5241 \n",
      "Loop 3812000 / Episode 173660 / Epsilon 0.0542 / Avg. Reward 20.400 / Avg. Length 190.900 / Loss 221.2279 \n",
      "Loop 3814000 / Episode 173667 / Epsilon 0.0537 / Avg. Reward 30.571 / Avg. Length 277.714 / Loss 214.8436 \n",
      "Loop 3816000 / Episode 173675 / Epsilon 0.0532 / Avg. Reward 29.750 / Avg. Length 271.500 / Loss 222.0789 \n",
      "Loop 3818000 / Episode 173690 / Epsilon 0.0528 / Avg. Reward 13.533 / Avg. Length 132.133 / Loss 219.4232 \n",
      "Saving model weights\n",
      "Loop 3820000 / Episode 173699 / Epsilon 0.0523 / Avg. Reward 20.444 / Avg. Length 190.222 / Loss 216.3303 \n",
      "Loop 3822000 / Episode 173711 / Epsilon 0.0518 / Avg. Reward 19.583 / Avg. Length 183.083 / Loss 223.5204 \n",
      "Loop 3824000 / Episode 173721 / Epsilon 0.0514 / Avg. Reward 20.300 / Avg. Length 189.400 / Loss 214.4466 \n",
      "Loop 3826000 / Episode 173732 / Epsilon 0.0509 / Avg. Reward 20.455 / Avg. Length 189.091 / Loss 215.4314 \n",
      "Loop 3828000 / Episode 173740 / Epsilon 0.0504 / Avg. Reward 26.125 / Avg. Length 240.750 / Loss 220.9626 \n",
      "Saving model weights\n",
      "Loop 3830000 / Episode 173760 / Epsilon 0.0499 / Avg. Reward 11.050 / Avg. Length 110.000 / Loss 219.2758 \n",
      "Loop 3832000 / Episode 173771 / Epsilon 0.0495 / Avg. Reward 19.091 / Avg. Length 179.636 / Loss 225.5759 \n",
      "Loop 3834000 / Episode 173774 / Epsilon 0.0490 / Avg. Reward 77.333 / Avg. Length 672.333 / Loss 215.4304 \n",
      "Loop 3836000 / Episode 173786 / Epsilon 0.0485 / Avg. Reward 14.417 / Avg. Length 139.083 / Loss 212.6715 \n",
      "Loop 3838000 / Episode 173793 / Epsilon 0.0481 / Avg. Reward 34.000 / Avg. Length 306.000 / Loss 205.4320 \n",
      "Saving model weights\n",
      "Loop 3840000 / Episode 173805 / Epsilon 0.0476 / Avg. Reward 16.917 / Avg. Length 161.083 / Loss 212.7295 \n",
      "Loop 3842000 / Episode 173814 / Epsilon 0.0471 / Avg. Reward 23.667 / Avg. Length 218.222 / Loss 207.0529 \n",
      "Loop 3844000 / Episode 173821 / Epsilon 0.0467 / Avg. Reward 33.143 / Avg. Length 297.000 / Loss 209.3817 \n",
      "Loop 3846000 / Episode 173829 / Epsilon 0.0462 / Avg. Reward 24.875 / Avg. Length 230.250 / Loss 211.1614 \n",
      "Loop 3848000 / Episode 173835 / Epsilon 0.0457 / Avg. Reward 36.000 / Avg. Length 321.333 / Loss 195.7930 \n",
      "Saving model weights\n",
      "Loop 3850000 / Episode 173844 / Epsilon 0.0452 / Avg. Reward 29.222 / Avg. Length 263.889 / Loss 201.3330 \n",
      "Loop 3852000 / Episode 173849 / Epsilon 0.0448 / Avg. Reward 43.400 / Avg. Length 386.000 / Loss 205.7534 \n",
      "Loop 3854000 / Episode 173861 / Epsilon 0.0443 / Avg. Reward 17.000 / Avg. Length 163.000 / Loss 210.3420 \n",
      "Loop 3856000 / Episode 173870 / Epsilon 0.0438 / Avg. Reward 24.556 / Avg. Length 226.000 / Loss 201.3793 \n",
      "Loop 3858000 / Episode 173880 / Epsilon 0.0434 / Avg. Reward 23.200 / Avg. Length 213.500 / Loss 200.7309 \n",
      "Saving model weights\n",
      "Loop 3860000 / Episode 173891 / Epsilon 0.0429 / Avg. Reward 16.182 / Avg. Length 155.091 / Loss 203.4636 \n",
      "Loop 3862000 / Episode 173903 / Epsilon 0.0424 / Avg. Reward 16.167 / Avg. Length 154.250 / Loss 218.8763 \n",
      "Loop 3864000 / Episode 173912 / Epsilon 0.0420 / Avg. Reward 28.667 / Avg. Length 260.222 / Loss 213.7831 \n",
      "Loop 3866000 / Episode 173927 / Epsilon 0.0415 / Avg. Reward 13.800 / Avg. Length 134.667 / Loss 207.7295 \n",
      "Loop 3868000 / Episode 173937 / Epsilon 0.0410 / Avg. Reward 21.800 / Avg. Length 201.400 / Loss 205.0588 \n",
      "Saving model weights\n",
      "Loop 3870000 / Episode 173947 / Epsilon 0.0405 / Avg. Reward 22.500 / Avg. Length 209.400 / Loss 209.5991 \n",
      "Loop 3872000 / Episode 173957 / Epsilon 0.0401 / Avg. Reward 17.300 / Avg. Length 162.500 / Loss 218.9888 \n",
      "Loop 3874000 / Episode 173967 / Epsilon 0.0396 / Avg. Reward 26.100 / Avg. Length 237.500 / Loss 218.7485 \n",
      "Loop 3876000 / Episode 173972 / Epsilon 0.0391 / Avg. Reward 34.600 / Avg. Length 312.000 / Loss 202.5200 \n",
      "Loop 3878000 / Episode 173978 / Epsilon 0.0387 / Avg. Reward 43.000 / Avg. Length 383.333 / Loss 198.0697 \n",
      "Saving model weights\n",
      "Loop 3880000 / Episode 173988 / Epsilon 0.0382 / Avg. Reward 21.600 / Avg. Length 201.100 / Loss 200.2906 \n",
      "Loop 3882000 / Episode 173993 / Epsilon 0.0377 / Avg. Reward 40.800 / Avg. Length 365.200 / Loss 200.3027 \n",
      "Loop 3884000 / Episode 174000 / Epsilon 0.0373 / Avg. Reward 33.429 / Avg. Length 302.286 / Loss 209.0421 \n",
      "Loop 3886000 / Episode 174010 / Epsilon 0.0368 / Avg. Reward 22.300 / Avg. Length 206.500 / Loss 203.2783 \n",
      "Loop 3888000 / Episode 174015 / Epsilon 0.0363 / Avg. Reward 24.800 / Avg. Length 225.800 / Loss 197.6180 \n",
      "Saving model weights\n",
      "Loop 3890000 / Episode 174021 / Epsilon 0.0358 / Avg. Reward 41.833 / Avg. Length 370.500 / Loss 200.1791 \n",
      "Loop 3892000 / Episode 174031 / Epsilon 0.0354 / Avg. Reward 29.300 / Avg. Length 267.200 / Loss 204.9457 \n",
      "Loop 3894000 / Episode 174041 / Epsilon 0.0349 / Avg. Reward 21.700 / Avg. Length 200.500 / Loss 212.3042 \n",
      "Loop 3896000 / Episode 174052 / Epsilon 0.0344 / Avg. Reward 16.455 / Avg. Length 155.909 / Loss 195.0055 \n",
      "Loop 3898000 / Episode 174057 / Epsilon 0.0340 / Avg. Reward 48.400 / Avg. Length 431.000 / Loss 202.7066 \n",
      "Saving model weights\n",
      "Loop 3900000 / Episode 174066 / Epsilon 0.0335 / Avg. Reward 25.444 / Avg. Length 232.889 / Loss 194.4725 \n",
      "Loop 3902000 / Episode 174077 / Epsilon 0.0330 / Avg. Reward 19.909 / Avg. Length 185.636 / Loss 212.9065 \n",
      "Loop 3904000 / Episode 174084 / Epsilon 0.0326 / Avg. Reward 33.143 / Avg. Length 296.857 / Loss 201.1872 \n",
      "Loop 3906000 / Episode 174093 / Epsilon 0.0321 / Avg. Reward 23.778 / Avg. Length 219.000 / Loss 208.1753 \n",
      "Loop 3908000 / Episode 174098 / Epsilon 0.0316 / Avg. Reward 35.400 / Avg. Length 318.800 / Loss 197.1084 \n",
      "Saving model weights\n",
      "Loop 3910000 / Episode 174107 / Epsilon 0.0311 / Avg. Reward 29.000 / Avg. Length 263.667 / Loss 199.8003 \n",
      "Loop 3912000 / Episode 174112 / Epsilon 0.0307 / Avg. Reward 46.600 / Avg. Length 413.200 / Loss 202.2969 \n",
      "Loop 3914000 / Episode 174122 / Epsilon 0.0302 / Avg. Reward 17.300 / Avg. Length 162.900 / Loss 197.9481 \n",
      "Loop 3916000 / Episode 174132 / Epsilon 0.0297 / Avg. Reward 24.300 / Avg. Length 225.500 / Loss 195.0192 \n",
      "Loop 3918000 / Episode 174142 / Epsilon 0.0293 / Avg. Reward 23.200 / Avg. Length 211.500 / Loss 187.1748 \n",
      "Saving model weights\n",
      "Loop 3920000 / Episode 174148 / Epsilon 0.0288 / Avg. Reward 36.667 / Avg. Length 325.667 / Loss 189.4540 \n",
      "Loop 3922000 / Episode 174153 / Epsilon 0.0283 / Avg. Reward 40.600 / Avg. Length 365.000 / Loss 198.1080 \n",
      "Loop 3924000 / Episode 174155 / Epsilon 0.0279 / Avg. Reward 103.000 / Avg. Length 888.500 / Loss 182.4309 \n",
      "Loop 3926000 / Episode 174162 / Epsilon 0.0274 / Avg. Reward 31.857 / Avg. Length 289.143 / Loss 182.4843 \n",
      "Loop 3928000 / Episode 174169 / Epsilon 0.0269 / Avg. Reward 37.429 / Avg. Length 336.143 / Loss 188.4043 \n",
      "Saving model weights\n",
      "Loop 3930000 / Episode 174172 / Epsilon 0.0264 / Avg. Reward 63.667 / Avg. Length 561.333 / Loss 181.2210 \n",
      "Loop 3932000 / Episode 174179 / Epsilon 0.0260 / Avg. Reward 36.714 / Avg. Length 327.429 / Loss 190.6132 \n",
      "Loop 3934000 / Episode 174187 / Epsilon 0.0255 / Avg. Reward 25.875 / Avg. Length 238.125 / Loss 190.2178 \n",
      "Loop 3936000 / Episode 174195 / Epsilon 0.0250 / Avg. Reward 29.375 / Avg. Length 264.875 / Loss 187.0096 \n",
      "Loop 3938000 / Episode 174204 / Epsilon 0.0246 / Avg. Reward 24.111 / Avg. Length 223.667 / Loss 189.2414 \n",
      "Saving model weights\n",
      "Loop 3940000 / Episode 174208 / Epsilon 0.0241 / Avg. Reward 42.750 / Avg. Length 381.750 / Loss 188.1878 \n",
      "Loop 3942000 / Episode 174215 / Epsilon 0.0236 / Avg. Reward 33.286 / Avg. Length 298.429 / Loss 186.7579 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3944000 / Episode 174219 / Epsilon 0.0232 / Avg. Reward 65.750 / Avg. Length 572.500 / Loss 177.3754 \n",
      "Loop 3946000 / Episode 174223 / Epsilon 0.0227 / Avg. Reward 58.500 / Avg. Length 513.000 / Loss 175.7493 \n",
      "Loop 3948000 / Episode 174229 / Epsilon 0.0222 / Avg. Reward 38.167 / Avg. Length 339.667 / Loss 177.9578 \n",
      "Saving model weights\n",
      "Loop 3950000 / Episode 174234 / Epsilon 0.0217 / Avg. Reward 42.200 / Avg. Length 374.800 / Loss 168.8184 \n",
      "Loop 3952000 / Episode 174240 / Epsilon 0.0213 / Avg. Reward 36.000 / Avg. Length 324.833 / Loss 171.9087 \n",
      "Loop 3954000 / Episode 174245 / Epsilon 0.0208 / Avg. Reward 31.400 / Avg. Length 287.400 / Loss 175.8589 \n",
      "Loop 3956000 / Episode 174252 / Epsilon 0.0203 / Avg. Reward 32.429 / Avg. Length 293.143 / Loss 178.6128 \n",
      "Loop 3958000 / Episode 174257 / Epsilon 0.0199 / Avg. Reward 58.800 / Avg. Length 513.200 / Loss 179.7225 \n",
      "Saving model weights\n",
      "Loop 3960000 / Episode 174262 / Epsilon 0.0194 / Avg. Reward 43.200 / Avg. Length 385.600 / Loss 163.4751 \n",
      "Loop 3962000 / Episode 174266 / Epsilon 0.0189 / Avg. Reward 40.000 / Avg. Length 354.000 / Loss 174.8953 \n",
      "Loop 3964000 / Episode 174275 / Epsilon 0.0185 / Avg. Reward 34.444 / Avg. Length 309.444 / Loss 163.6393 \n",
      "Loop 3966000 / Episode 174283 / Epsilon 0.0180 / Avg. Reward 26.750 / Avg. Length 243.375 / Loss 167.8864 \n",
      "Loop 3968000 / Episode 174290 / Epsilon 0.0175 / Avg. Reward 32.571 / Avg. Length 295.429 / Loss 157.8730 \n",
      "Saving model weights\n",
      "Loop 3970000 / Episode 174291 / Epsilon 0.0170 / Avg. Reward 132.000 / Avg. Length 1142.000 / Loss 160.6810 \n",
      "Loop 3972000 / Episode 174293 / Epsilon 0.0166 / Avg. Reward 135.000 / Avg. Length 1162.500 / Loss 161.0126 \n",
      "Loop 3974000 / Episode 174297 / Epsilon 0.0161 / Avg. Reward 64.250 / Avg. Length 562.750 / Loss 156.2765 \n",
      "Loop 3976000 / Episode 174303 / Epsilon 0.0156 / Avg. Reward 27.167 / Avg. Length 245.333 / Loss 153.4956 \n",
      "Loop 3978000 / Episode 174313 / Epsilon 0.0152 / Avg. Reward 29.300 / Avg. Length 266.300 / Loss 153.3302 \n",
      "Saving model weights\n",
      "Loop 3980000 / Episode 174315 / Epsilon 0.0147 / Avg. Reward 53.000 / Avg. Length 468.500 / Loss 134.2105 \n",
      "Loop 3982000 / Episode 174323 / Epsilon 0.0142 / Avg. Reward 43.500 / Avg. Length 387.500 / Loss 149.6025 \n",
      "Loop 3984000 / Episode 174326 / Epsilon 0.0138 / Avg. Reward 70.000 / Avg. Length 612.000 / Loss 141.4594 \n",
      "Loop 3986000 / Episode 174330 / Epsilon 0.0133 / Avg. Reward 60.000 / Avg. Length 526.500 / Loss 142.8251 \n",
      "Loop 3988000 / Episode 174332 / Epsilon 0.0128 / Avg. Reward 40.500 / Avg. Length 357.500 / Loss 141.0642 \n",
      "Saving model weights\n",
      "Loop 3990000 / Episode 174336 / Epsilon 0.0123 / Avg. Reward 89.250 / Avg. Length 775.750 / Loss 136.2541 \n",
      "Loop 3992000 / Episode 174342 / Epsilon 0.0119 / Avg. Reward 40.833 / Avg. Length 365.167 / Loss 139.1972 \n",
      "Loop 3994000 / Episode 174346 / Epsilon 0.0114 / Avg. Reward 58.750 / Avg. Length 513.000 / Loss 135.5734 \n",
      "Loop 3996000 / Episode 174349 / Epsilon 0.0109 / Avg. Reward 69.667 / Avg. Length 608.000 / Loss 135.7713 \n",
      "Loop 3998000 / Episode 174350 / Epsilon 0.0105 / Avg. Reward 170.000 / Avg. Length 1457.000 / Loss 130.4576 \n",
      "Saving model weights\n",
      "Loop 4000000 / Episode 174353 / Epsilon 0.0100 / Avg. Reward 104.000 / Avg. Length 894.333 / Loss 120.6365 \n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "target_model = build_model()\n",
    "\n",
    "train_network(model,target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life lost: reward 18.0, steps 169\n",
      "Life lost: reward 84.0, steps 733\n",
      "Life lost: reward 20.0, steps 185\n",
      "Life lost: reward 60.0, steps 526\n",
      "Life lost: reward 69.0, steps 600\n",
      "Life lost: reward 23.0, steps 214\n",
      "Life lost: reward 44.0, steps 392\n",
      "Life lost: reward 32.0, steps 282\n",
      "Life lost: reward 11.0, steps 109\n",
      "Life lost: reward 98.0, steps 842\n",
      "Life lost: reward 119.0, steps 1033\n",
      "Life lost: reward 93.0, steps 809\n",
      "Life lost: reward 94.0, steps 826\n",
      "Life lost: reward 97.0, steps 849\n",
      "Life lost: reward 71.0, steps 622\n",
      "Life lost: reward 194.0, steps 1657\n",
      "Life lost: reward 90.0, steps 792\n",
      "Life lost: reward 65.0, steps 576\n",
      "Life lost: reward 89.0, steps 768\n",
      "Life lost: reward 12.0, steps 119\n",
      "Life lost: reward 13.0, steps 124\n",
      "Life lost: reward 320.0, steps 2726\n",
      "Life lost: reward 58.0, steps 504\n",
      "Life lost: reward 59.0, steps 511\n",
      "Life lost: reward 174.0, steps 1497\n",
      "Life lost: reward 71.0, steps 623\n",
      "Life lost: reward 43.0, steps 378\n",
      "Life lost: reward 106.0, steps 917\n",
      "Life lost: reward 95.0, steps 827\n",
      "Life lost: reward 57.0, steps 500\n",
      "Life lost: reward 56.0, steps 497\n",
      "Life lost: reward 67.0, steps 588\n",
      "Life lost: reward 29.0, steps 262\n",
      "Life lost: reward 39.0, steps 352\n",
      "Life lost: reward 100.0, steps 865\n",
      "Life lost: reward 204.0, steps 1747\n",
      "Life lost: reward 4.0, steps 50\n",
      "Life lost: reward 67.0, steps 584\n",
      "Life lost: reward 32.0, steps 292\n",
      "Life lost: reward 88.0, steps 765\n",
      "Life lost: reward 336.0, steps 2882\n",
      "Life lost: reward 30.0, steps 272\n",
      "Life lost: reward 13.0, steps 128\n",
      "Life lost: reward 28.0, steps 257\n",
      "Life lost: reward 30.0, steps 276\n",
      "Life lost: reward 32.0, steps 286\n",
      "Life lost: reward 100.0, steps 869\n",
      "Life lost: reward 138.0, steps 1173\n",
      "Life lost: reward 14.0, steps 140\n",
      "Life lost: reward 45.0, steps 403\n",
      "Life lost: reward 51.0, steps 446\n",
      "Life lost: reward 279.0, steps 2403\n",
      "Life lost: reward 115.0, steps 984\n",
      "Life lost: reward 252.0, steps 2130\n",
      "Life lost: reward 226.0, steps 1920\n",
      "Life lost: reward 12.0, steps 118\n",
      "Life lost: reward 14.0, steps 136\n",
      "Life lost: reward 86.0, steps 737\n",
      "Life lost: reward 54.0, steps 475\n",
      "Life lost: reward 28.0, steps 259\n",
      "Life lost: reward 49.0, steps 430\n",
      "Life lost: reward 124.0, steps 1071\n",
      "Life lost: reward 80.0, steps 694\n",
      "Life lost: reward 78.0, steps 685\n",
      "Life lost: reward 5.0, steps 60\n",
      "Life lost: reward 44.0, steps 385\n",
      "Life lost: reward 22.0, steps 206\n",
      "Life lost: reward 5.0, steps 61\n",
      "Life lost: reward 61.0, steps 531\n",
      "Life lost: reward 17.0, steps 160\n",
      "Life lost: reward 52.0, steps 458\n",
      "Life lost: reward 65.0, steps 562\n",
      "Life lost: reward 46.0, steps 404\n",
      "Life lost: reward 50.0, steps 436\n",
      "Life lost: reward 18.0, steps 169\n",
      "Life lost: reward 122.0, steps 1058\n",
      "Life lost: reward 164.0, steps 1405\n",
      "Life lost: reward 47.0, steps 415\n",
      "Life lost: reward 67.0, steps 587\n",
      "Life lost: reward 22.0, steps 202\n",
      "Life lost: reward -1.0, steps 9\n",
      "Life lost: reward 74.0, steps 642\n",
      "Life lost: reward 23.0, steps 212\n",
      "Life lost: reward 31.0, steps 280\n",
      "Life lost: reward 163.0, steps 1402\n",
      "Life lost: reward 52.0, steps 462\n",
      "Life lost: reward 60.0, steps 524\n",
      "Life lost: reward 84.0, steps 725\n",
      "Life lost: reward 81.0, steps 705\n",
      "Life lost: reward 32.0, steps 284\n",
      "Life lost: reward 49.0, steps 430\n",
      "Life lost: reward 31.0, steps 281\n",
      "Life lost: reward 4.0, steps 51\n",
      "Life lost: reward 25.0, steps 231\n",
      "Life lost: reward 63.0, steps 550\n",
      "Life lost: reward 134.0, steps 1161\n",
      "Life lost: reward 249.0, steps 2148\n",
      "Life lost: reward 3.0, steps 43\n",
      "Life lost: reward -1.0, steps 9\n",
      "Life lost: reward 67.0, steps 590\n",
      "Life lost: reward 219.0, steps 1860\n",
      "Life lost: reward 8.0, steps 85\n",
      "Life lost: reward 1.0, steps 28\n",
      "Life lost: reward 10.0, steps 105\n",
      "Life lost: reward 13.0, steps 126\n",
      "Life lost: reward 52.0, steps 462\n",
      "Life lost: reward 45.0, steps 398\n",
      "Life lost: reward 92.0, steps 796\n",
      "Life lost: reward 69.0, steps 602\n",
      "Life lost: reward 83.0, steps 717\n",
      "Life lost: reward 69.0, steps 613\n",
      "Life lost: reward 106.0, steps 928\n",
      "Life lost: reward 234.0, steps 2000\n",
      "Life lost: reward 24.0, steps 226\n",
      "Life lost: reward 33.0, steps 295\n",
      "Life lost: reward 183.0, steps 1549\n",
      "Life lost: reward 11.0, steps 111\n",
      "Life lost: reward 167.0, steps 1443\n",
      "Life lost: reward 69.0, steps 602\n",
      "Life lost: reward 6.0, steps 66\n",
      "Life lost: reward 62.0, steps 539\n",
      "Life lost: reward 17.0, steps 167\n",
      "Life lost: reward 45.0, steps 401\n",
      "Life lost: reward 165.0, steps 1421\n",
      "Life lost: reward 12.0, steps 119\n",
      "Life lost: reward 36.0, steps 316\n",
      "Life lost: reward 172.0, steps 1482\n",
      "Life lost: reward 0.0, steps 17\n",
      "Life lost: reward 80.0, steps 691\n",
      "Life lost: reward -1.0, steps 9\n",
      "Life lost: reward 106.0, steps 916\n",
      "Life lost: reward 6.0, steps 67\n",
      "Life lost: reward 31.0, steps 282\n",
      "Life lost: reward 168.0, steps 1441\n",
      "Life lost: reward 27.0, steps 246\n",
      "Life lost: reward 12.0, steps 125\n",
      "Life lost: reward 34.0, steps 314\n",
      "Life lost: reward 33.0, steps 296\n",
      "Life lost: reward 45.0, steps 397\n",
      "Life lost: reward -1.0, steps 9\n",
      "Life lost: reward 0.0, steps 17\n",
      "Life lost: reward 1.0, steps 25\n",
      "Life lost: reward 35.0, steps 313\n",
      "Life lost: reward 60.0, steps 526\n",
      "Life lost: reward 100.0, steps 873\n",
      "Life lost: reward 73.0, steps 625\n",
      "Life lost: reward 31.0, steps 282\n",
      "Life lost: reward 4.0, steps 50\n",
      "Life lost: reward 108.0, steps 929\n",
      "Life lost: reward 18.0, steps 171\n",
      "Life lost: reward 25.0, steps 232\n",
      "Life lost: reward 41.0, steps 366\n",
      "Life lost: reward 20.0, steps 189\n",
      "Life lost: reward 32.0, steps 290\n",
      "Life lost: reward 68.0, steps 612\n",
      "Life lost: reward 7.0, steps 75\n",
      "Life lost: reward 68.0, steps 597\n",
      "Life lost: reward 73.0, steps 637\n",
      "Life lost: reward 306.0, steps 2625\n",
      "Life lost: reward 68.0, steps 594\n",
      "Life lost: reward 149.0, steps 1290\n",
      "Life lost: reward 58.0, steps 517\n",
      "Life lost: reward 50.0, steps 448\n",
      "Life lost: reward 69.0, steps 597\n",
      "Life lost: reward 47.0, steps 412\n",
      "Life lost: reward 0.0, steps 18\n",
      "Life lost: reward 24.0, steps 221\n",
      "Life lost: reward 17.0, steps 164\n",
      "Life lost: reward 49.0, steps 434\n",
      "Life lost: reward 48.0, steps 421\n",
      "Life lost: reward 24.0, steps 220\n",
      "Life lost: reward 28.0, steps 253\n",
      "Life lost: reward 50.0, steps 446\n",
      "Life lost: reward 68.0, steps 595\n",
      "Life lost: reward 95.0, steps 841\n",
      "Life lost: reward 68.0, steps 601\n",
      "Life lost: reward 90.0, steps 786\n",
      "Life lost: reward 114.0, steps 995\n",
      "Life lost: reward 3.0, steps 46\n",
      "Life lost: reward 230.0, steps 1970\n",
      "Life lost: reward 113.0, steps 970\n",
      "Life lost: reward 49.0, steps 442\n",
      "Life lost: reward 99.0, steps 858\n",
      "Life lost: reward 24.0, steps 227\n",
      "Life lost: reward 80.0, steps 700\n",
      "Life lost: reward 94.0, steps 822\n",
      "Life lost: reward 101.0, steps 871\n",
      "Life lost: reward 62.0, steps 542\n",
      "Life lost: reward 15.0, steps 149\n",
      "Life lost: reward 236.0, steps 2019\n",
      "Life lost: reward 83.0, steps 715\n",
      "Life lost: reward 201.0, steps 1727\n",
      "Life lost: reward -1.0, steps 9\n",
      "Life lost: reward 143.0, steps 1225\n",
      "Life lost: reward 207.0, steps 1773\n",
      "Life lost: reward 11.0, steps 112\n",
      "Life lost: reward 279.0, steps 2388\n",
      "Life lost: reward 23.0, steps 211\n",
      "Life lost: reward 287.0, steps 2455\n",
      "Life lost: reward 11.0, steps 113\n",
      "Life lost: reward 55.0, steps 477\n",
      "Life lost: reward 91.0, steps 796\n",
      "Life lost: reward 2.0, steps 35\n",
      "Life lost: reward 12.0, steps 119\n",
      "Life lost: reward 82.0, steps 709\n",
      "Life lost: reward 48.0, steps 430\n",
      "Life lost: reward 111.0, steps 961\n",
      "Life lost: reward 87.0, steps 763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-00eff1de68d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0maction_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mple_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jim/gym_attempts/PyGame-Learning-Environment/ple/ple.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \"\"\"\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oneStepAct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jim/gym_attempts/PyGame-Learning-Environment/ple/ple.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \"\"\"\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oneStepAct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jim/gym_attempts/PyGame-Learning-Environment/ple/ple.py\u001b[0m in \u001b[0;36m_oneStepAct\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jim/gym_attempts/PyGame-Learning-Environment/ple/ple.py\u001b[0m in \u001b[0;36m_tick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1000.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jim/gym_attempts/PyGame-Learning-Environment/ple/games/base/pygamewrapper.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, fps)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0msleeps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgame\u001b[0m \u001b[0mto\u001b[0m \u001b[0mensure\u001b[0m \u001b[0mit\u001b[0m \u001b[0mruns\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdesired\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_busy_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madjustRewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running the model\n",
    "\n",
    "inference_model = build_model()\n",
    "zString = \"catcher_training_weights/model_3000000.h5\"\n",
    "#zString = \"catcher_training_weights/model_2950000.h5\"\n",
    "inference_model.load_weights(zString)\n",
    "\n",
    "game = Catcher() # create our game\n",
    "\n",
    "fps = 30  # fps we want to run at\n",
    "frame_skip = 2\n",
    "num_steps = 2\n",
    "force_fps = False\n",
    "display_screen = True\n",
    "\n",
    "# make a PLE instance.\n",
    "ple_env = PLE(game, fps=fps, frame_skip=frame_skip, num_steps=num_steps,\n",
    "        force_fps=force_fps, display_screen=display_screen)\n",
    "\n",
    "# init agent and game.\n",
    "ple_env.init()\n",
    "ple_env.act(action_list[np.random.randint(0,2)])\n",
    "\n",
    "done_check = ple_env.lives() \n",
    "\n",
    "x_t = ple_env.getScreenGrayscale()/255. \n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "\n",
    "total_reward = 0\n",
    "total_steps = 0\n",
    "\n",
    "for f in range(1000000):\n",
    "    q = inference_model.predict(s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])) \n",
    "    max_Q = np.argmax(q)\n",
    "    action_index = max_Q\n",
    "    action_command = action_list[action_index]\n",
    "            \n",
    "    total_reward += ple_env.act(action_command)\n",
    "    total_steps += 1\n",
    "    \n",
    "    #get next state\n",
    "    x_t1 = ple_env.getScreenGrayscale()/255.\n",
    "    x_t1 = x_t1.reshape(x_t1.shape[0], x_t1.shape[1], 1) #1x64x64x1\n",
    "    s_t1 = np.append(x_t1, s_t[ :, :, :3], axis=2) #add new observation to end, drop first observation\n",
    "    \n",
    "    # if the game is over\n",
    "    if ple_env.lives() != done_check:\n",
    "        print(\"Life lost: reward {}, steps {}\".format(total_reward,total_steps))\n",
    "        ple_env.reset_game()\n",
    "        ple_env.act(action_list[np.random.randint(0,2)])\n",
    "        x_t = ple_env.getScreenGrayscale()/255. \n",
    "        s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "        total_reward = 0\n",
    "        total_steps = 0\n",
    "    else:\n",
    "        s_t = s_t1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Notes:\n",
    "* Still kind of not great considering catcher is such a simple game\n",
    "* Could use some hyperparameter adjustments\n",
    "* Does weird thing where it prefers all the way to the right then shifts left even when not needed. This could be because DQN is deterministic and a stochastic solution (like a Policy Gradients method) would lead to a better solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
